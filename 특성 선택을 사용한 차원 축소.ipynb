{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68112222, 0.18871289, 3.09550267, 0.57713289])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "iris = datasets.load_iris() #데이터를 로드\n",
    "features = iris.data # 특성과 타깃을 만듭니다\n",
    "target = iris.target\n",
    "thresholder = VarianceThreshold(threshold=.5) # 기준값을 만듭니다.\n",
    "features_high_variance = thresholder.fit_transform(features) # 기준값보다 높은 특성을 선택합니다.\n",
    "features_high_variance[0:3] # 선택한 특성을 확인\n",
    "thresholder.variances_ # 분산을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() # 특성 행렬을 표준화합니다.\n",
    "features_std = scaler.fit_transform(features)\n",
    "selector = VarianceThreshold() # 각 특성의 분산을 계산합니다.\n",
    "selector.fit(features_std).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16, 0.16, 0.24])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "features = [[0, 1, 0], # 예제 특성 행렬\n",
    "[0, 1, 1], # 특성 0: 80%가 클래스 0\n",
    "[0, 1, 0], # 특성 1: 80%가 클래스 1\n",
    "[0, 1, 1], # 특성 2: 60%가 클래스 0, 40%는 클래스 1\n",
    "[1, 0, 0]]\n",
    "# 분산을 기준으로 선택합니다.\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1 - .75)))\n",
    "thresholder.fit_transform(features)\n",
    "thresholder.variances_\n",
    "import numpy as np\n",
    "np.var(features, axis=0) #넘파이 var 함수를 사용하여 분산을 계산합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 상관관계가 큰 두 개의 특성을 가진 특성 행렬을 만듭니다.\n",
    "features = np.array([[1, 1, 1], [2, 2, 0], [3, 3, 1], [4, 4, 0], [5, 5, 1],\n",
    "[6, 6, 0], [7, 7, 1], [8, 7, 0], [9, 7, 1]])\n",
    "dataframe = pd.DataFrame(features) # 특성 행렬을 DataFrame으로 변환\n",
    "corr_matrix = dataframe.corr().abs() # 상관관계 행렬을 만듭니다.\n",
    "# 상관관계 행렬의 상삼각(upper triangle) 행렬을 선택합니다.\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# 상관 계수가 0.95보다 큰 특성 열의 인덱스를 찾습니다.\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  2\n",
       "0  1  1\n",
       "1  2  0\n",
       "2  3  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.drop(dataframe.columns[to_drop], axis=1).head(3) # 특성을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2\n",
       "0 NaN  0.976103  0.000000\n",
       "1 NaN       NaN  0.034503\n",
       "2 NaN       NaN       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.corr() #상관관계 행렬\n",
    "upper #상관관계 행렬의 상삼각 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.97610336,  0.        ],\n",
       "       [ 0.97610336,  1.        , -0.03450328],\n",
       "       [ 0.        , -0.03450328,  1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(features, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.triu(np.ones((4, 4)), k=2)\n",
    "np.tril(np.ones((4, 4)), k=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 작업에 관련 없는 특성 삭제\n",
    "- 범주형 타깃 벡터에서 관련 없는 특성을 삭제하기 위해 타깃 벡터 사이의 카이제곱 통계를 계산합니다.\n",
    "\n",
    "- 카이제곱 통계는 두 범주형 벡터의 독립성을 평가합니다.\n",
    "\n",
    "- 카이제곱 통계는 범주형 특성의 각 클래스별 샘플 빈도와 이 특성이 타깃 벡터와 독립적이라면 기대할 수 있는 값\n",
    "  사이의 차이입니다\n",
    "\n",
    "- 카이제곱 특성은 관찰 빈도와 전혀 관계가 없다고 기대하는 빈도 사이에 얼마나 큰 차이가 있는지 알려주는 하나\n",
    "   의 숫자입니다.\n",
    "-  특성과 타깃 벡터 사이의 카이제곱 통계를 계산하면 둘 사이의 독립성을 측정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "iris = load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "features = features.astype(int) # 범주형 데이터를 정수형으로 변환\n",
    "chi2_selector = SelectKBest(chi2, k=2) # 카이제곱 통계값이 가장 큰 특성 두 개를 선택\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 확인\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 2\n",
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 3\n"
     ]
    }
   ],
   "source": [
    "# F-값이 가장 높은 특성 두 개를 선택합니다.\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 확인\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])\n",
    "# 특정 특성 개수를 선택하는 대신 Selectpercentile를 사용하여 특성의 상위 n 퍼센트를 선택할 수 있습니다.\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "# 가장 큰 F-값의 상위 75% 특성을 선택합니다.\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 선택\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.28712871,   5.02267003, 133.06854839,  74.27906977])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target\n",
    "#특성 행렬의 차원을 (3, 50, 4)로 바꾸어 클래스별 합을 구합니다.\n",
    "observed = np.sum(features.reshape(3, 50, 4), axis=1)\n",
    "observed\n",
    "#특성 타깃과 전혀 관계없다면 기대 빈도는 전체 합을 클래스 개수 3으로 나눈 값이 됩니다.\n",
    "expected = features.sum(axis=0) / 3\n",
    "expected\n",
    "#카이제곱 공식에 위에서 구한 observed와 expected를 대입합니다.\n",
    "np.sum((observed - expected)**2 / expected, axis=0)\n",
    "#카이제곱 값이 큰 세 번째, 네 번째 특성이 선택됩니다. chi2_selector객체의 scores_속성에 저장\n",
    "chi2_selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6 , 3.04, 1.  , 0.  ],\n",
       "       [5.48, 2.32, 3.82, 1.  ],\n",
       "       [6.08, 2.58, 5.1 , 1.58]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##전체 평균과 클래스 평균을 계산\n",
    "total_mean = np.mean(features, axis=0)\n",
    "total_mean\n",
    "class_mean = np.mean(features.reshape(3, 50, 4), axis=1)\n",
    "class_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105.57333333,  42.27333333, 467.89333333,  76.06      ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ss_total 계산\n",
    "ss_between = np.sum(50 * (class_mean - total_mean)**2, axis=0)\n",
    "ss_between\n",
    "ss_total = np.sum((features - total_mean)**2, axis=0)\n",
    "ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  81.19715 ,   33.715004, 1160.0116  ,  385.483   ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ss_beteen과 ss_tatal을 F-값 공식에 대입\n",
    "f = (ss_between/(3-1)) / ((ss_total-ss_between)/(150-3))\n",
    "f\n",
    "fvalue_selector.scores_ #F-값 scores_속성에서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "# 특성 행렬과 타깃 벡터를 생성합니다.\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                n_features = 100,\n",
    "                                n_informative = 2,\n",
    "                                random_state = 1)\n",
    "# 선형 회귀 모델을 만듭니다.\n",
    "ols = linear_model.LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00850799,  0.7031277 ],\n",
       "       [-1.07500204,  2.56148527],\n",
       "       [ 1.37940721, -1.77039484],\n",
       "       ...,\n",
       "       [-0.80331656, -1.60648007],\n",
       "       [ 0.39508844, -1.34564911],\n",
       "       [-0.55383035,  0.82880112]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재귀적으로 특성을 제거합니다.\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82, 84, 74, 33, 81,  1, 18, 46, 57, 67, 45,  7, 58, 52, 78,  8,  5,\n",
       "       73, 31, 11, 43, 14, 34, 83, 21, 96, 20, 41, 94, 90, 71, 47, 30, 27,\n",
       "       89, 50, 25, 69, 86,  1, 76, 19, 97, 88,  9, 16, 23, 80, 75, 54, 91,\n",
       "       12, 65, 59, 24, 32,  4, 26, 10, 42, 72,  2, 87, 40, 66,  3, 92, 17,\n",
       "       39, 35, 13, 79, 38,  6, 53, 60, 22, 61, 28, 95, 93, 36, 99, 48, 51,\n",
       "       68, 37, 70, 15, 98, 56, 29, 44, 63, 49, 64, 77, 85, 55, 62])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.n_features_ # 최선의 특성 개수\n",
    "rfecv.support_ # 선택된 특성이 표시된 불리언 마스크\n",
    "rfecv.ranking_ # 특성의 순위: 최고(1)에서 최악(96)까지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00850799,  0.7031277 , -1.16432076],\n",
       "       [-1.07500204,  2.56148527, -1.3936433 ],\n",
       "       [ 1.37940721, -1.77039484,  1.02058188],\n",
       "       ...,\n",
       "       [-0.80331656, -1.60648007, -0.64067478],\n",
       "       [ 0.39508844, -1.34564911, -1.91468325],\n",
       "       [-0.55383035,  0.82880112,  0.27936745]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(estimator=ols, n_features_to_select=3)\n",
    "rfe.fit(features, target)\n",
    "rfe.transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(rfe.support_ == rfecv.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
