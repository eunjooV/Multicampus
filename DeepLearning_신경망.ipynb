{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########신경망 학습에서 발생하는 과적합 제거 및 감소##############\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "df = pd.read_csv('./dataset/sonar.csv',  header=None)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype(float)\n",
    "y = dataset[:,60]\n",
    " \n",
    "\n",
    "le =preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "Y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.2463 - accuracy: 0.5172\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.2440 - accuracy: 0.5379\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.2420 - accuracy: 0.5310\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 323us/step - loss: 0.2398 - accuracy: 0.5448\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.2382 - accuracy: 0.5517\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.2340 - accuracy: 0.5448\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.2302 - accuracy: 0.5586\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 365us/step - loss: 0.2209 - accuracy: 0.6483\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 0s 351us/step - loss: 0.2127 - accuracy: 0.6552\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 426us/step - loss: 0.2080 - accuracy: 0.6690\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 420us/step - loss: 0.2015 - accuracy: 0.7172\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 323us/step - loss: 0.1892 - accuracy: 0.7310\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 296us/step - loss: 0.1787 - accuracy: 0.7448\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.1721 - accuracy: 0.7448\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.1659 - accuracy: 0.7793\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 296us/step - loss: 0.1613 - accuracy: 0.7655\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.1566 - accuracy: 0.7655\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 296us/step - loss: 0.1549 - accuracy: 0.7862\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.1498 - accuracy: 0.7724\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 371us/step - loss: 0.1506 - accuracy: 0.8069\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 0s 309us/step - loss: 0.1454 - accuracy: 0.8069\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.1446 - accuracy: 0.7931\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 0s 302us/step - loss: 0.1380 - accuracy: 0.8276\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 392us/step - loss: 0.1372 - accuracy: 0.8276\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 392us/step - loss: 0.1365 - accuracy: 0.8276\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 0s 420us/step - loss: 0.1326 - accuracy: 0.8483\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 392us/step - loss: 0.1370 - accuracy: 0.8138\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 378us/step - loss: 0.1296 - accuracy: 0.8345\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 365us/step - loss: 0.1366 - accuracy: 0.8207\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.1277 - accuracy: 0.8345\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 385us/step - loss: 0.1284 - accuracy: 0.8276\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.1226 - accuracy: 0.8621\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 0s 344us/step - loss: 0.1222 - accuracy: 0.8690\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.1211 - accuracy: 0.8690\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.1232 - accuracy: 0.8483\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.1228 - accuracy: 0.8276\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.1131 - accuracy: 0.8621\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.1155 - accuracy: 0.8552\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.1131 - accuracy: 0.8552\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.1129 - accuracy: 0.8621\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.1106 - accuracy: 0.8414\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.1107 - accuracy: 0.8552\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.1092 - accuracy: 0.8621\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.1092 - accuracy: 0.8414\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.1103 - accuracy: 0.8483\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.1080 - accuracy: 0.8552\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.1040 - accuracy: 0.8690\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.1047 - accuracy: 0.8552\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.1069 - accuracy: 0.8483\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.1020 - accuracy: 0.8690\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.1039 - accuracy: 0.8621\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 0s 323us/step - loss: 0.0981 - accuracy: 0.8828\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.0983 - accuracy: 0.8759\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0973 - accuracy: 0.8897\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 296us/step - loss: 0.0970 - accuracy: 0.8828\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.0947 - accuracy: 0.8759\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.0926 - accuracy: 0.8828\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 302us/step - loss: 0.0950 - accuracy: 0.8690\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.0932 - accuracy: 0.8759\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0890 - accuracy: 0.8759\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 0s 309us/step - loss: 0.0895 - accuracy: 0.8828\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 323us/step - loss: 0.0959 - accuracy: 0.8759\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0911 - accuracy: 0.8897\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0911 - accuracy: 0.8759\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.0895 - accuracy: 0.8897\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0855 - accuracy: 0.8828\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 309us/step - loss: 0.0844 - accuracy: 0.8966\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0821 - accuracy: 0.9103\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 296us/step - loss: 0.0821 - accuracy: 0.9034\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.0791 - accuracy: 0.8966\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 303us/step - loss: 0.0834 - accuracy: 0.8897\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.0781 - accuracy: 0.9172\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.0815 - accuracy: 0.8897\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.0782 - accuracy: 0.8966\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 316us/step - loss: 0.0768 - accuracy: 0.9103\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.0740 - accuracy: 0.9172\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.0745 - accuracy: 0.8966\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 0s 268us/step - loss: 0.0727 - accuracy: 0.8966\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0722 - accuracy: 0.9034\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0713 - accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0674 - accuracy: 0.9103\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0690 - accuracy: 0.9241\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 310us/step - loss: 0.0650 - accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 282us/step - loss: 0.0649 - accuracy: 0.9379\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0646 - accuracy: 0.9172\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0625 - accuracy: 0.9241\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0619 - accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 254us/step - loss: 0.0584 - accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 261us/step - loss: 0.0586 - accuracy: 0.9517\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 296us/step - loss: 0.0651 - accuracy: 0.9034\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 268us/step - loss: 0.0571 - accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0566 - accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 275us/step - loss: 0.0537 - accuracy: 0.9517\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 289us/step - loss: 0.0532 - accuracy: 0.9448\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 337us/step - loss: 0.0529 - accuracy: 0.9448\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.0492 - accuracy: 0.9586\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 330us/step - loss: 0.0479 - accuracy: 0.9517\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 358us/step - loss: 0.0474 - accuracy: 0.9724\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 344us/step - loss: 0.0483 - accuracy: 0.9586\n",
      "63/63 [==============================] - 0s 364us/step\n",
      "\n",
      " Accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "#첫번재 은닉층 (출력뉴런수 24, 활성화함수 relu)\n",
    "#두번재 은닉층 (출력뉴런수 10, 활성화함수 relu)\n",
    "#출력층 (출력뉴런수 1, 활성화함수 sigmoid)\n",
    "#epochs =200\n",
    "#batch_size=5\n",
    "#오차함수 : 평균 제곱 오차계산함수\n",
    "#최적화함수 : adam\n",
    "#측정지표 : accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=5)\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 950us/sample - loss: 0.1429 - accuracy: 0.8413\n",
      "\n",
      " Accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "#학습 결과 모델을 저장후 새로운 데이터에 대해서 예측할때 저장된 모델을 불러와 사용합니다.\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('sonar_model.h5')\n",
    "\n",
    " \n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('sonar_model.h5')\n",
    " \n",
    "print(\"\\n Accuracy: %.4f\" % (model2.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 799us/step - loss: 0.2492 - accuracy: 0.5422\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.2363 - accuracy: 0.6024\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.2289 - accuracy: 0.6205\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.2185 - accuracy: 0.6325\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.2099 - accuracy: 0.6747\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.1947 - accuracy: 0.7229\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 283us/step - loss: 0.1870 - accuracy: 0.7530\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 325us/step - loss: 0.1804 - accuracy: 0.7229\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.1695 - accuracy: 0.7590\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1599 - accuracy: 0.7711\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 343us/step - loss: 0.1569 - accuracy: 0.7831\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 397us/step - loss: 0.1494 - accuracy: 0.8012\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 391us/step - loss: 0.1493 - accuracy: 0.7892\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 451us/step - loss: 0.1474 - accuracy: 0.7892\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1448 - accuracy: 0.7771\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.1363 - accuracy: 0.8253\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 366us/step - loss: 0.1358 - accuracy: 0.8072\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 354us/step - loss: 0.1274 - accuracy: 0.8253\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 331us/step - loss: 0.1276 - accuracy: 0.8072\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.1255 - accuracy: 0.8373\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1230 - accuracy: 0.8554\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.1170 - accuracy: 0.8494\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1162 - accuracy: 0.8313\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1129 - accuracy: 0.8795\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.1089 - accuracy: 0.8614\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1185 - accuracy: 0.8253\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 361us/step - loss: 0.1169 - accuracy: 0.8735\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 354us/step - loss: 0.1048 - accuracy: 0.8675\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 330us/step - loss: 0.1060 - accuracy: 0.8494\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.1032 - accuracy: 0.8735\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 391us/step - loss: 0.0990 - accuracy: 0.8855\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 385us/step - loss: 0.0974 - accuracy: 0.8916\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 385us/step - loss: 0.0945 - accuracy: 0.8916\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 433us/step - loss: 0.0989 - accuracy: 0.8795\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 403us/step - loss: 0.0926 - accuracy: 0.8976\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 366us/step - loss: 0.0915 - accuracy: 0.8675\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 342us/step - loss: 0.0879 - accuracy: 0.8916\n",
      "Epoch 38/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0883 - accuracy: 0.8855\n",
      "Epoch 39/100\n",
      "166/166 [==============================] - 0s 319us/step - loss: 0.0878 - accuracy: 0.8976\n",
      "Epoch 40/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0903 - accuracy: 0.8855\n",
      "Epoch 41/100\n",
      "166/166 [==============================] - 0s 342us/step - loss: 0.0808 - accuracy: 0.8916\n",
      "Epoch 42/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0825 - accuracy: 0.8855\n",
      "Epoch 43/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0848 - accuracy: 0.8916\n",
      "Epoch 44/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0803 - accuracy: 0.8976\n",
      "Epoch 45/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0790 - accuracy: 0.8916\n",
      "Epoch 46/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0793 - accuracy: 0.8916\n",
      "Epoch 47/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0727 - accuracy: 0.9217\n",
      "Epoch 48/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0767 - accuracy: 0.9036\n",
      "Epoch 49/100\n",
      "166/166 [==============================] - 0s 360us/step - loss: 0.0711 - accuracy: 0.9096\n",
      "Epoch 50/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0691 - accuracy: 0.9277\n",
      "Epoch 51/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0652 - accuracy: 0.9277\n",
      "Epoch 52/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0683 - accuracy: 0.9157\n",
      "Epoch 53/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0669 - accuracy: 0.9157\n",
      "Epoch 54/100\n",
      "166/166 [==============================] - 0s 373us/step - loss: 0.0632 - accuracy: 0.9337\n",
      "Epoch 55/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0601 - accuracy: 0.9337\n",
      "Epoch 56/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0590 - accuracy: 0.9458\n",
      "Epoch 57/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0596 - accuracy: 0.9518\n",
      "Epoch 58/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0562 - accuracy: 0.9398\n",
      "Epoch 59/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0574 - accuracy: 0.9337\n",
      "Epoch 60/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0520 - accuracy: 0.9518\n",
      "Epoch 61/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0519 - accuracy: 0.9518\n",
      "Epoch 62/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0516 - accuracy: 0.9398\n",
      "Epoch 63/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0503 - accuracy: 0.9518\n",
      "Epoch 64/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0488 - accuracy: 0.9639\n",
      "Epoch 65/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0480 - accuracy: 0.9398\n",
      "Epoch 66/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0464 - accuracy: 0.9578\n",
      "Epoch 67/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0468 - accuracy: 0.9398\n",
      "Epoch 68/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0420 - accuracy: 0.9699\n",
      "Epoch 69/100\n",
      "166/166 [==============================] - 0s 258us/step - loss: 0.0384 - accuracy: 0.9699\n",
      "Epoch 70/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0377 - accuracy: 0.9699\n",
      "Epoch 71/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0423 - accuracy: 0.9518\n",
      "Epoch 72/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0364 - accuracy: 0.9819\n",
      "Epoch 73/100\n",
      "166/166 [==============================] - 0s 270us/step - loss: 0.0379 - accuracy: 0.9759\n",
      "Epoch 74/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0419 - accuracy: 0.9578\n",
      "Epoch 75/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0323 - accuracy: 0.9578\n",
      "Epoch 76/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0339 - accuracy: 0.9699\n",
      "Epoch 77/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0302 - accuracy: 0.9819\n",
      "Epoch 78/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0328 - accuracy: 0.9699\n",
      "Epoch 79/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0297 - accuracy: 0.9819\n",
      "Epoch 80/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0260 - accuracy: 0.9819\n",
      "Epoch 81/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0253 - accuracy: 0.9880\n",
      "Epoch 82/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0256 - accuracy: 0.9880\n",
      "Epoch 83/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0239 - accuracy: 0.9880\n",
      "Epoch 84/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0301 - accuracy: 0.9759\n",
      "Epoch 85/100\n",
      "166/166 [==============================] - 0s 270us/step - loss: 0.0264 - accuracy: 0.9759\n",
      "Epoch 86/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0243 - accuracy: 0.9880\n",
      "Epoch 87/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0263 - accuracy: 0.9699\n",
      "Epoch 88/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0233 - accuracy: 0.9940\n",
      "Epoch 89/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0255 - accuracy: 0.9819\n",
      "Epoch 90/100\n",
      "166/166 [==============================] - 0s 270us/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 92/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "166/166 [==============================] - 0s 367us/step - loss: 0.0187 - accuracy: 0.9940\n",
      "Epoch 94/100\n",
      "166/166 [==============================] - 0s 379us/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "166/166 [==============================] - 0s 487us/step - loss: 0.0207 - accuracy: 0.9819\n",
      "Epoch 96/100\n",
      "166/166 [==============================] - 0s 475us/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "166/166 [==============================] - 0s 427us/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "166/166 [==============================] - 0s 373us/step - loss: 0.0155 - accuracy: 0.9940\n",
      "Epoch 99/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0143 - accuracy: 0.9940\n",
      "Epoch 100/100\n",
      "166/166 [==============================] - 0s 342us/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 823us/step - loss: 0.2528 - accuracy: 0.5120\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.2359 - accuracy: 0.5904\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.2245 - accuracy: 0.6506\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.2124 - accuracy: 0.7048\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.2029 - accuracy: 0.7229\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.1956 - accuracy: 0.6988\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1890 - accuracy: 0.7169\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1803 - accuracy: 0.7349\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.1766 - accuracy: 0.7470\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1707 - accuracy: 0.7711\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 342us/step - loss: 0.1635 - accuracy: 0.7711\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 313us/step - loss: 0.1591 - accuracy: 0.8012\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.1560 - accuracy: 0.7771\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1492 - accuracy: 0.7952\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1490 - accuracy: 0.8012\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 330us/step - loss: 0.1424 - accuracy: 0.8193\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1419 - accuracy: 0.8253\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.1319 - accuracy: 0.8313\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 354us/step - loss: 0.1337 - accuracy: 0.8253\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.1302 - accuracy: 0.8253\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1267 - accuracy: 0.8373\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.1213 - accuracy: 0.8554\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1206 - accuracy: 0.8434\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.1151 - accuracy: 0.8675\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 270us/step - loss: 0.1262 - accuracy: 0.8193\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1153 - accuracy: 0.8614\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.1172 - accuracy: 0.8253\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.1118 - accuracy: 0.8675\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1089 - accuracy: 0.8494\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1240 - accuracy: 0.8133\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1057 - accuracy: 0.8675\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1088 - accuracy: 0.8675\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.1008 - accuracy: 0.8795\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.1047 - accuracy: 0.8554\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0969 - accuracy: 0.8795\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0973 - accuracy: 0.8675\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 360us/step - loss: 0.1085 - accuracy: 0.8675\n",
      "Epoch 38/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.0886 - accuracy: 0.8976\n",
      "Epoch 39/100\n",
      "166/166 [==============================] - 0s 349us/step - loss: 0.0948 - accuracy: 0.8554\n",
      "Epoch 40/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0898 - accuracy: 0.8675\n",
      "Epoch 41/100\n",
      "166/166 [==============================] - 0s 373us/step - loss: 0.0896 - accuracy: 0.8916\n",
      "Epoch 42/100\n",
      "166/166 [==============================] - 0s 354us/step - loss: 0.0840 - accuracy: 0.9157\n",
      "Epoch 43/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.0885 - accuracy: 0.8855\n",
      "Epoch 44/100\n",
      "166/166 [==============================] - 0s 366us/step - loss: 0.0830 - accuracy: 0.8976\n",
      "Epoch 45/100\n",
      "166/166 [==============================] - 0s 372us/step - loss: 0.0817 - accuracy: 0.9096\n",
      "Epoch 46/100\n",
      "166/166 [==============================] - 0s 397us/step - loss: 0.0799 - accuracy: 0.9036\n",
      "Epoch 47/100\n",
      "166/166 [==============================] - 0s 360us/step - loss: 0.0807 - accuracy: 0.8795\n",
      "Epoch 48/100\n",
      "166/166 [==============================] - 0s 385us/step - loss: 0.0777 - accuracy: 0.9096\n",
      "Epoch 49/100\n",
      "166/166 [==============================] - 0s 433us/step - loss: 0.0735 - accuracy: 0.9157\n",
      "Epoch 50/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.0747 - accuracy: 0.9277\n",
      "Epoch 51/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0734 - accuracy: 0.9217\n",
      "Epoch 52/100\n",
      "166/166 [==============================] - 0s 421us/step - loss: 0.0718 - accuracy: 0.9217\n",
      "Epoch 53/100\n",
      "166/166 [==============================] - 0s 397us/step - loss: 0.0713 - accuracy: 0.9217\n",
      "Epoch 54/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0652 - accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "166/166 [==============================] - 0s 385us/step - loss: 0.0656 - accuracy: 0.9337\n",
      "Epoch 56/100\n",
      "166/166 [==============================] - 0s 354us/step - loss: 0.0624 - accuracy: 0.9398\n",
      "Epoch 57/100\n",
      "166/166 [==============================] - 0s 348us/step - loss: 0.0616 - accuracy: 0.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "166/166 [==============================] - 0s 379us/step - loss: 0.0675 - accuracy: 0.9458\n",
      "Epoch 59/100\n",
      "166/166 [==============================] - 0s 373us/step - loss: 0.0669 - accuracy: 0.9096\n",
      "Epoch 60/100\n",
      "166/166 [==============================] - 0s 372us/step - loss: 0.0601 - accuracy: 0.9337\n",
      "Epoch 61/100\n",
      "166/166 [==============================] - 0s 342us/step - loss: 0.0577 - accuracy: 0.9458\n",
      "Epoch 62/100\n",
      "166/166 [==============================] - 0s 379us/step - loss: 0.0541 - accuracy: 0.9518\n",
      "Epoch 63/100\n",
      "166/166 [==============================] - 0s 366us/step - loss: 0.0563 - accuracy: 0.9217\n",
      "Epoch 64/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0678 - accuracy: 0.8916\n",
      "Epoch 65/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0632 - accuracy: 0.9217\n",
      "Epoch 66/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0528 - accuracy: 0.9458\n",
      "Epoch 67/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0503 - accuracy: 0.9458\n",
      "Epoch 68/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0486 - accuracy: 0.9518\n",
      "Epoch 69/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0464 - accuracy: 0.9578\n",
      "Epoch 70/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0465 - accuracy: 0.9578\n",
      "Epoch 71/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0499 - accuracy: 0.9578\n",
      "Epoch 72/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0426 - accuracy: 0.9639\n",
      "Epoch 73/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0473 - accuracy: 0.9518\n",
      "Epoch 74/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0487 - accuracy: 0.9639\n",
      "Epoch 75/100\n",
      "166/166 [==============================] - 0s 295us/step - loss: 0.0462 - accuracy: 0.9518\n",
      "Epoch 76/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0526 - accuracy: 0.9277\n",
      "Epoch 77/100\n",
      "166/166 [==============================] - 0s 276us/step - loss: 0.0377 - accuracy: 0.9518\n",
      "Epoch 78/100\n",
      "166/166 [==============================] - 0s 283us/step - loss: 0.0388 - accuracy: 0.9578\n",
      "Epoch 79/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0351 - accuracy: 0.9639\n",
      "Epoch 80/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0349 - accuracy: 0.9699\n",
      "Epoch 81/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0317 - accuracy: 0.9759\n",
      "Epoch 82/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0326 - accuracy: 0.9880\n",
      "Epoch 83/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0324 - accuracy: 0.9759\n",
      "Epoch 84/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0307 - accuracy: 0.9819\n",
      "Epoch 85/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0348 - accuracy: 0.9639\n",
      "Epoch 86/100\n",
      "166/166 [==============================] - 0s 270us/step - loss: 0.0286 - accuracy: 0.9819\n",
      "Epoch 87/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0295 - accuracy: 0.9819\n",
      "Epoch 88/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0287 - accuracy: 0.9759\n",
      "Epoch 89/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0252 - accuracy: 0.9819\n",
      "Epoch 90/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0254 - accuracy: 0.9819\n",
      "Epoch 91/100\n",
      "166/166 [==============================] - 0s 307us/step - loss: 0.0279 - accuracy: 0.9759\n",
      "Epoch 92/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0302 - accuracy: 0.9819\n",
      "Epoch 93/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0236 - accuracy: 0.9880\n",
      "Epoch 94/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0211 - accuracy: 0.9819\n",
      "Epoch 95/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0211 - accuracy: 0.9940\n",
      "Epoch 96/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0210 - accuracy: 0.9880\n",
      "Epoch 97/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 98/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0219 - accuracy: 0.9819\n",
      "Epoch 99/100\n",
      "166/166 [==============================] - 0s 313us/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0219 - accuracy: 0.9880\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 901us/step - loss: 0.2402 - accuracy: 0.5964\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.2244 - accuracy: 0.6988\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.2160 - accuracy: 0.7410\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 330us/step - loss: 0.2072 - accuracy: 0.7349\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1956 - accuracy: 0.7651\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1897 - accuracy: 0.7771\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1832 - accuracy: 0.7590\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.1746 - accuracy: 0.8012\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1716 - accuracy: 0.7771\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1603 - accuracy: 0.8072\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1527 - accuracy: 0.8434\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 307us/step - loss: 0.1540 - accuracy: 0.7952\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 295us/step - loss: 0.1432 - accuracy: 0.8373\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1415 - accuracy: 0.8133\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1356 - accuracy: 0.8434\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.1298 - accuracy: 0.8494\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1284 - accuracy: 0.8434\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1258 - accuracy: 0.8434\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1251 - accuracy: 0.8313\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1241 - accuracy: 0.8554\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1157 - accuracy: 0.8675\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 330us/step - loss: 0.1169 - accuracy: 0.8313\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1154 - accuracy: 0.8373\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1133 - accuracy: 0.8494\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1133 - accuracy: 0.8253\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.1129 - accuracy: 0.8313\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.1163 - accuracy: 0.8494\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.1077 - accuracy: 0.8614\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1050 - accuracy: 0.8494\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.1106 - accuracy: 0.8554\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.1057 - accuracy: 0.8494\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0976 - accuracy: 0.8614\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0993 - accuracy: 0.8795\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0956 - accuracy: 0.8795\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0982 - accuracy: 0.9036\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 295us/step - loss: 0.0922 - accuracy: 0.8855\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0894 - accuracy: 0.8916\n",
      "Epoch 38/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0892 - accuracy: 0.8916\n",
      "Epoch 39/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0887 - accuracy: 0.8976\n",
      "Epoch 40/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0899 - accuracy: 0.8795\n",
      "Epoch 41/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0863 - accuracy: 0.8916\n",
      "Epoch 42/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0866 - accuracy: 0.8916\n",
      "Epoch 43/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0819 - accuracy: 0.8916\n",
      "Epoch 44/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0827 - accuracy: 0.8916\n",
      "Epoch 45/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0795 - accuracy: 0.8976\n",
      "Epoch 46/100\n",
      "166/166 [==============================] - 0s 319us/step - loss: 0.0808 - accuracy: 0.9036\n",
      "Epoch 47/100\n",
      "166/166 [==============================] - 0s 264us/step - loss: 0.0815 - accuracy: 0.8976\n",
      "Epoch 48/100\n",
      "166/166 [==============================] - 0s 246us/step - loss: 0.0757 - accuracy: 0.9096\n",
      "Epoch 49/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0771 - accuracy: 0.9036\n",
      "Epoch 50/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0725 - accuracy: 0.9217\n",
      "Epoch 51/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0717 - accuracy: 0.9096\n",
      "Epoch 52/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0713 - accuracy: 0.9217\n",
      "Epoch 53/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0710 - accuracy: 0.9217\n",
      "Epoch 54/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0693 - accuracy: 0.9217\n",
      "Epoch 55/100\n",
      "166/166 [==============================] - 0s 307us/step - loss: 0.0718 - accuracy: 0.9036\n",
      "Epoch 56/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0666 - accuracy: 0.9217\n",
      "Epoch 57/100\n",
      "166/166 [==============================] - 0s 355us/step - loss: 0.0655 - accuracy: 0.9277\n",
      "Epoch 58/100\n",
      "166/166 [==============================] - 0s 391us/step - loss: 0.0662 - accuracy: 0.9096\n",
      "Epoch 59/100\n",
      "166/166 [==============================] - 0s 360us/step - loss: 0.0700 - accuracy: 0.9036\n",
      "Epoch 60/100\n",
      "166/166 [==============================] - 0s 384us/step - loss: 0.0680 - accuracy: 0.9157\n",
      "Epoch 61/100\n",
      "166/166 [==============================] - 0s 433us/step - loss: 0.0609 - accuracy: 0.9398\n",
      "Epoch 62/100\n",
      "166/166 [==============================] - 0s 354us/step - loss: 0.0662 - accuracy: 0.9157\n",
      "Epoch 63/100\n",
      "166/166 [==============================] - 0s 330us/step - loss: 0.0598 - accuracy: 0.9337\n",
      "Epoch 64/100\n",
      "166/166 [==============================] - 0s 385us/step - loss: 0.0586 - accuracy: 0.9277\n",
      "Epoch 65/100\n",
      "166/166 [==============================] - 0s 397us/step - loss: 0.0574 - accuracy: 0.9337\n",
      "Epoch 66/100\n",
      "166/166 [==============================] - 0s 415us/step - loss: 0.0576 - accuracy: 0.9458\n",
      "Epoch 67/100\n",
      "166/166 [==============================] - 0s 433us/step - loss: 0.0541 - accuracy: 0.9458\n",
      "Epoch 68/100\n",
      "166/166 [==============================] - 0s 342us/step - loss: 0.0542 - accuracy: 0.9518\n",
      "Epoch 69/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0530 - accuracy: 0.9578\n",
      "Epoch 70/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0518 - accuracy: 0.9578\n",
      "Epoch 71/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.93 - 0s 330us/step - loss: 0.0524 - accuracy: 0.9398\n",
      "Epoch 72/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0549 - accuracy: 0.9277\n",
      "Epoch 73/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0497 - accuracy: 0.9639\n",
      "Epoch 74/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0494 - accuracy: 0.9578\n",
      "Epoch 75/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0456 - accuracy: 0.9699\n",
      "Epoch 76/100\n",
      "166/166 [==============================] - 0s 276us/step - loss: 0.0497 - accuracy: 0.9518\n",
      "Epoch 77/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0456 - accuracy: 0.9639\n",
      "Epoch 78/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0521 - accuracy: 0.9518\n",
      "Epoch 79/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0457 - accuracy: 0.9699\n",
      "Epoch 80/100\n",
      "166/166 [==============================] - 0s 324us/step - loss: 0.0429 - accuracy: 0.9699\n",
      "Epoch 81/100\n",
      "166/166 [==============================] - 0s 288us/step - loss: 0.0419 - accuracy: 0.9759\n",
      "Epoch 82/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0419 - accuracy: 0.9699\n",
      "Epoch 83/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0465 - accuracy: 0.9578\n",
      "Epoch 84/100\n",
      "166/166 [==============================] - 0s 306us/step - loss: 0.0426 - accuracy: 0.9639\n",
      "Epoch 85/100\n",
      "166/166 [==============================] - 0s 336us/step - loss: 0.0391 - accuracy: 0.9759\n",
      "Epoch 86/100\n",
      "166/166 [==============================] - 0s 312us/step - loss: 0.0407 - accuracy: 0.9699\n",
      "Epoch 87/100\n",
      "166/166 [==============================] - 0s 307us/step - loss: 0.0364 - accuracy: 0.9759\n",
      "Epoch 88/100\n",
      "166/166 [==============================] - 0s 270us/step - loss: 0.0354 - accuracy: 0.9759\n",
      "Epoch 89/100\n",
      "166/166 [==============================] - 0s 276us/step - loss: 0.0432 - accuracy: 0.9518\n",
      "Epoch 90/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0382 - accuracy: 0.9699\n",
      "Epoch 91/100\n",
      "166/166 [==============================] - 0s 319us/step - loss: 0.0382 - accuracy: 0.9639\n",
      "Epoch 92/100\n",
      "166/166 [==============================] - 0s 343us/step - loss: 0.0326 - accuracy: 0.9819\n",
      "Epoch 93/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0345 - accuracy: 0.9759\n",
      "Epoch 94/100\n",
      "166/166 [==============================] - 0s 276us/step - loss: 0.0345 - accuracy: 0.9759\n",
      "Epoch 95/100\n",
      "166/166 [==============================] - 0s 276us/step - loss: 0.0321 - accuracy: 0.9819\n",
      "Epoch 96/100\n",
      "166/166 [==============================] - 0s 282us/step - loss: 0.0327 - accuracy: 0.9819\n",
      "Epoch 97/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0315 - accuracy: 0.9819\n",
      "Epoch 98/100\n",
      "166/166 [==============================] - 0s 318us/step - loss: 0.0310 - accuracy: 0.9759\n",
      "Epoch 99/100\n",
      "166/166 [==============================] - 0s 300us/step - loss: 0.0323 - accuracy: 0.9759\n",
      "Epoch 100/100\n",
      "166/166 [==============================] - 0s 294us/step - loss: 0.0345 - accuracy: 0.9578\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 0s 794us/step - loss: 0.2591 - accuracy: 0.4731\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.2461 - accuracy: 0.6467\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.2432 - accuracy: 0.6587\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.2392 - accuracy: 0.6826\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.2357 - accuracy: 0.6647\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.2321 - accuracy: 0.7006\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.2271 - accuracy: 0.7006\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 286us/step - loss: 0.2221 - accuracy: 0.7305\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 364us/step - loss: 0.2173 - accuracy: 0.7186\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.2088 - accuracy: 0.7784\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 346us/step - loss: 0.2008 - accuracy: 0.7365\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.1941 - accuracy: 0.7545\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.1859 - accuracy: 0.8024\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 287us/step - loss: 0.1794 - accuracy: 0.8024\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1726 - accuracy: 0.7784\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1667 - accuracy: 0.7904\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1611 - accuracy: 0.8144\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.1552 - accuracy: 0.8084\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.1460 - accuracy: 0.8204\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.1533 - accuracy: 0.7784\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1394 - accuracy: 0.8144\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1325 - accuracy: 0.8204\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1313 - accuracy: 0.8263\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 323us/step - loss: 0.1281 - accuracy: 0.8383\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.1221 - accuracy: 0.8204\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1199 - accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.1191 - accuracy: 0.8204\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1101 - accuracy: 0.8503\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1089 - accuracy: 0.8563\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1088 - accuracy: 0.8623\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.1018 - accuracy: 0.8743\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.1074 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 304us/step - loss: 0.0970 - accuracy: 0.8982\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 0s 322us/step - loss: 0.0984 - accuracy: 0.8862\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0936 - accuracy: 0.8862\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 0s 263us/step - loss: 0.0924 - accuracy: 0.8922\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0902 - accuracy: 0.8862\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0888 - accuracy: 0.8922\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0899 - accuracy: 0.8802\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0885 - accuracy: 0.8743\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.0795 - accuracy: 0.8982\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0815 - accuracy: 0.9042\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0882 - accuracy: 0.8623\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0832 - accuracy: 0.9102\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 0s 280us/step - loss: 0.0766 - accuracy: 0.9222\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0755 - accuracy: 0.9222\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0792 - accuracy: 0.8922\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0819 - accuracy: 0.8982\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0707 - accuracy: 0.9042\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0712 - accuracy: 0.9162\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0628 - accuracy: 0.9401\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0622 - accuracy: 0.9341\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0596 - accuracy: 0.9401\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0579 - accuracy: 0.9521\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0556 - accuracy: 0.9401\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0540 - accuracy: 0.9521\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0556 - accuracy: 0.9521\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0548 - accuracy: 0.9521\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0555 - accuracy: 0.9461\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 0s 298us/step - loss: 0.0527 - accuracy: 0.9521\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 0s 322us/step - loss: 0.0475 - accuracy: 0.9521\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 0s 298us/step - loss: 0.0473 - accuracy: 0.9461\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 0s 286us/step - loss: 0.0512 - accuracy: 0.9401\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0480 - accuracy: 0.9701\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 0s 286us/step - loss: 0.0420 - accuracy: 0.9760\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0416 - accuracy: 0.9701\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 0s 400us/step - loss: 0.0392 - accuracy: 0.9641\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0414 - accuracy: 0.9701\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.0416 - accuracy: 0.9701\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0353 - accuracy: 0.9701\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 0s 352us/step - loss: 0.0342 - accuracy: 0.9820\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 0s 388us/step - loss: 0.0361 - accuracy: 0.9521\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.0352 - accuracy: 0.9701\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 0s 352us/step - loss: 0.0356 - accuracy: 0.9581\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 0s 358us/step - loss: 0.0306 - accuracy: 0.9880\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 0s 352us/step - loss: 0.0302 - accuracy: 0.9760\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0374 - accuracy: 0.9581\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0264 - accuracy: 0.9880\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0280 - accuracy: 0.9760\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0255 - accuracy: 0.9820\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0265 - accuracy: 0.9820\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0253 - accuracy: 0.9820\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 0s 298us/step - loss: 0.0253 - accuracy: 0.9820\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0244 - accuracy: 0.9940\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.0226 - accuracy: 0.9880\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0251 - accuracy: 0.9820\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0217 - accuracy: 0.9940\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 0s 292us/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0193 - accuracy: 0.9880\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0172 - accuracy: 0.9880\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.0195 - accuracy: 0.9880\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 0s 322us/step - loss: 0.0171 - accuracy: 0.9940\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0160 - accuracy: 0.9880\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 0s 304us/step - loss: 0.0163 - accuracy: 0.9940\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.0158 - accuracy: 0.9940\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0200 - accuracy: 0.9940\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 0s 310us/step - loss: 0.0145 - accuracy: 0.9940\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 0s 866us/step - loss: 0.2539 - accuracy: 0.4970\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.2365 - accuracy: 0.6168\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 364us/step - loss: 0.2278 - accuracy: 0.6647\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 340us/step - loss: 0.2217 - accuracy: 0.6946\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.2140 - accuracy: 0.7006\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.2084 - accuracy: 0.7066\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1996 - accuracy: 0.7186\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1945 - accuracy: 0.7126\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.1916 - accuracy: 0.7485\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.1813 - accuracy: 0.7545\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.1763 - accuracy: 0.7665\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.1704 - accuracy: 0.7545\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.1666 - accuracy: 0.7725\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 286us/step - loss: 0.1591 - accuracy: 0.7784\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.1567 - accuracy: 0.7904\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1572 - accuracy: 0.7784\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.1527 - accuracy: 0.8084\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.1447 - accuracy: 0.8144\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 280us/step - loss: 0.1426 - accuracy: 0.8144\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 292us/step - loss: 0.1394 - accuracy: 0.8144\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 268us/step - loss: 0.1347 - accuracy: 0.8263\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 280us/step - loss: 0.1352 - accuracy: 0.8323\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.1301 - accuracy: 0.8503\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.1285 - accuracy: 0.8443\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 340us/step - loss: 0.1264 - accuracy: 0.8383\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.1280 - accuracy: 0.8323\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.1235 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 382us/step - loss: 0.1231 - accuracy: 0.8323\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 0s 358us/step - loss: 0.1178 - accuracy: 0.8503\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 0s 376us/step - loss: 0.1188 - accuracy: 0.8563\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1178 - accuracy: 0.8323\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 0s 280us/step - loss: 0.1164 - accuracy: 0.8443\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 310us/step - loss: 0.1116 - accuracy: 0.8743\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.1095 - accuracy: 0.8563\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 334us/step - loss: 0.1090 - accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.1147 - accuracy: 0.8623\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 322us/step - loss: 0.1086 - accuracy: 0.8503\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.1059 - accuracy: 0.8563\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.1045 - accuracy: 0.8623\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.1061 - accuracy: 0.8623\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1154 - accuracy: 0.8204\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.1022 - accuracy: 0.8802\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.1050 - accuracy: 0.8563\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 0s 316us/step - loss: 0.0994 - accuracy: 0.8563\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.1008 - accuracy: 0.8683\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0942 - accuracy: 0.8982\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.0952 - accuracy: 0.8802\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0920 - accuracy: 0.8862\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0927 - accuracy: 0.8862\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0921 - accuracy: 0.8743\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0934 - accuracy: 0.8743\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0904 - accuracy: 0.8683\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0878 - accuracy: 0.8802\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0860 - accuracy: 0.8862\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0849 - accuracy: 0.9162\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 0s 304us/step - loss: 0.0835 - accuracy: 0.9042\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 0s 340us/step - loss: 0.0820 - accuracy: 0.8862\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0829 - accuracy: 0.8982\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0806 - accuracy: 0.9102\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 0s 334us/step - loss: 0.0804 - accuracy: 0.9102\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0785 - accuracy: 0.9102\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0784 - accuracy: 0.8862\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0793 - accuracy: 0.9042\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 0s 328us/step - loss: 0.0772 - accuracy: 0.8922\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0747 - accuracy: 0.9042\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0756 - accuracy: 0.9162\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0825 - accuracy: 0.8922\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0713 - accuracy: 0.9162\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0786 - accuracy: 0.9102\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0699 - accuracy: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.0675 - accuracy: 0.9281\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 0s 317us/step - loss: 0.0667 - accuracy: 0.9341\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0637 - accuracy: 0.9281\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 0s 323us/step - loss: 0.0645 - accuracy: 0.9281\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0668 - accuracy: 0.9281\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0644 - accuracy: 0.9222\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0657 - accuracy: 0.9222\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0614 - accuracy: 0.9341\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 0s 328us/step - loss: 0.0599 - accuracy: 0.9281\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0622 - accuracy: 0.9281\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 0s 287us/step - loss: 0.0610 - accuracy: 0.9341\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0590 - accuracy: 0.9341\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0567 - accuracy: 0.9641\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 0s 299us/step - loss: 0.0572 - accuracy: 0.9341\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 0s 298us/step - loss: 0.0548 - accuracy: 0.9521\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 0s 281us/step - loss: 0.0527 - accuracy: 0.9641\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 0s 305us/step - loss: 0.0505 - accuracy: 0.9760\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 0s 370us/step - loss: 0.0492 - accuracy: 0.9701\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 0s 382us/step - loss: 0.0511 - accuracy: 0.9581\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 0s 394us/step - loss: 0.0507 - accuracy: 0.9581\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 0s 388us/step - loss: 0.0478 - accuracy: 0.9701\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 0s 388us/step - loss: 0.0483 - accuracy: 0.9641\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 0s 352us/step - loss: 0.0469 - accuracy: 0.9760\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0461 - accuracy: 0.9760\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 0s 334us/step - loss: 0.0446 - accuracy: 0.9760\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 0s 269us/step - loss: 0.0498 - accuracy: 0.9641\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 0s 311us/step - loss: 0.0460 - accuracy: 0.9701\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 0s 275us/step - loss: 0.0480 - accuracy: 0.9581\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 0s 298us/step - loss: 0.0428 - accuracy: 0.9760\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 0s 293us/step - loss: 0.0415 - accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "#####데이터셋 크기가 작은 경우 K겹 교차 검증으로 학습##################\n",
    "#전체 데이터셋을 K개의 부분 데이터셋으로 나눠서 학습시에 한번씩 테스트 셋으로 \n",
    "#전체 데이터를 테스트 셋으로 활용\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_fold=5\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "\n",
    "for train , test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24,  input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 와인 데이터 셋으로 신경망 학습 #######\n",
    "# 은닉층 4개 30,12,8,1\n",
    "# 오차함수 binary_crossentropy\n",
    "# 전체 샘플이 200회 반복 입력 실행\n",
    "# 정확도 출력\n",
    "\n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "df_pre = pd.read_csv('./dataset/wine.csv', header=None)\n",
    "df = df_pre.sample(frac=1)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,:12]\n",
    "Y = dataset[:,12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 저장할 때 모델과 함께 epochs마다 모델의 정확도 함께 저장\n",
    "# 케라스 내부에서 테스트 오차는 val_loss, 학습 정확도는 acc, 테스트 정확도는 val_acc, 학습셋 오차는 loss로 거듭됨\n",
    "# verbose 1이면 진행 사항 출력, 0이면 출력\n",
    "# save_best_only = True는 저장된 모델보다 성능이 좋아졌을때만 저장\n",
    "\n",
    "import os \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_dir = './model/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33252, saving model to ./model/01-0.3325.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33252 to 0.26954, saving model to ./model/02-0.2695.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26954 to 0.23056, saving model to ./model/03-0.2306.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23056 to 0.21170, saving model to ./model/04-0.2117.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21170 to 0.20292, saving model to ./model/05-0.2029.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20292 to 0.19886, saving model to ./model/06-0.1989.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19886 to 0.19421, saving model to ./model/07-0.1942.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19421 to 0.18860, saving model to ./model/08-0.1886.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18860 to 0.18633, saving model to ./model/09-0.1863.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18633 to 0.18411, saving model to ./model/10-0.1841.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18411 to 0.18176, saving model to ./model/11-0.1818.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18176 to 0.18171, saving model to ./model/12-0.1817.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18171\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18171 to 0.17790, saving model to ./model/14-0.1779.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17790 to 0.17243, saving model to ./model/15-0.1724.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17243 to 0.17050, saving model to ./model/16-0.1705.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.17050 to 0.16772, saving model to ./model/17-0.1677.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.16772 to 0.16680, saving model to ./model/18-0.1668.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16680 to 0.16594, saving model to ./model/19-0.1659.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.16594 to 0.15981, saving model to ./model/20-0.1598.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15981 to 0.15657, saving model to ./model/21-0.1566.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15657\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15657 to 0.14920, saving model to ./model/23-0.1492.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14920 to 0.14832, saving model to ./model/24-0.1483.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14832 to 0.14497, saving model to ./model/25-0.1450.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14497\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14497\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14497 to 0.13641, saving model to ./model/28-0.1364.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13641 to 0.13401, saving model to ./model/29-0.1340.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13401 to 0.12898, saving model to ./model/30-0.1290.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12898\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12898 to 0.12435, saving model to ./model/32-0.1244.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12435 to 0.11893, saving model to ./model/33-0.1189.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11893 to 0.11845, saving model to ./model/34-0.1184.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11845\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11845 to 0.11383, saving model to ./model/36-0.1138.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11383 to 0.10876, saving model to ./model/37-0.1088.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.10876 to 0.10496, saving model to ./model/39-0.1050.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.10496 to 0.10034, saving model to ./model/40-0.1003.hdf5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10034\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10034 to 0.09622, saving model to ./model/42-0.0962.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09622 to 0.09537, saving model to ./model/43-0.0954.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.09537\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09537\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.09537 to 0.09452, saving model to ./model/46-0.0945.hdf5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09452\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.09452 to 0.09038, saving model to ./model/48-0.0904.hdf5\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.09038 to 0.08892, saving model to ./model/49-0.0889.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08892 to 0.08398, saving model to ./model/50-0.0840.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08398\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08398 to 0.07999, saving model to ./model/52-0.0800.hdf5\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07999\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07999\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.07999 to 0.07904, saving model to ./model/55-0.0790.hdf5\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.07904\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07904 to 0.07668, saving model to ./model/57-0.0767.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07668\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.07668\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07668 to 0.07333, saving model to ./model/60-0.0733.hdf5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07333\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.07333 to 0.06975, saving model to ./model/62-0.0697.hdf5\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06975\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.06975 to 0.06802, saving model to ./model/64-0.0680.hdf5\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06802 to 0.06771, saving model to ./model/65-0.0677.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06771 to 0.06666, saving model to ./model/66-0.0667.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.06666 to 0.06472, saving model to ./model/67-0.0647.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06472\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06472 to 0.06373, saving model to ./model/69-0.0637.hdf5\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06373 to 0.06365, saving model to ./model/70-0.0636.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06365 to 0.06145, saving model to ./model/71-0.0614.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06145\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06145 to 0.06117, saving model to ./model/73-0.0612.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06117 to 0.05989, saving model to ./model/74-0.0599.hdf5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05989\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05989\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05989\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05989\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05989\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05989 to 0.05885, saving model to ./model/80-0.0588.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05885 to 0.05779, saving model to ./model/81-0.0578.hdf5\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05779\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05779 to 0.05776, saving model to ./model/83-0.0578.hdf5\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05776\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05776 to 0.05732, saving model to ./model/85-0.0573.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05732 to 0.05593, saving model to ./model/86-0.0559.hdf5\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05593 to 0.05544, saving model to ./model/89-0.0554.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05544\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05544\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05544\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05544\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05544\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05544\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05544 to 0.05401, saving model to ./model/96-0.0540.hdf5\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05401\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05401\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05401 to 0.05261, saving model to ./model/99-0.0526.hdf5\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05261\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05261\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05261\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05261 to 0.05249, saving model to ./model/103-0.0525.hdf5\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05249\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05249 to 0.05165, saving model to ./model/105-0.0517.hdf5\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05165\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.05165 to 0.05123, saving model to ./model/115-0.0512.hdf5\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.05123 to 0.05112, saving model to ./model/116-0.0511.hdf5\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.05112\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05112\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05112\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05112\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.05112 to 0.05039, saving model to ./model/121-0.0504.hdf5\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05039\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05039\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.05039 to 0.04902, saving model to ./model/124-0.0490.hdf5\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04902\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.04902 to 0.04891, saving model to ./model/144-0.0489.hdf5\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04891\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.04891 to 0.04850, saving model to ./model/146-0.0485.hdf5\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04850\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.04850 to 0.04795, saving model to ./model/156-0.0479.hdf5\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04795\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04795\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04795\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04795\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.04795 to 0.04781, saving model to ./model/161-0.0478.hdf5\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04781\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.04781\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.04781\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.04781 to 0.04738, saving model to ./model/165-0.0474.hdf5\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04738\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.04738 to 0.04713, saving model to ./model/184-0.0471.hdf5\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.04713\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04713\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04713\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04713\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.04713\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04713\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.04713 to 0.04711, saving model to ./model/191-0.0471.hdf5\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.04711 to 0.04703, saving model to ./model/192-0.0470.hdf5\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.04703 to 0.04690, saving model to ./model/193-0.0469.hdf5\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04690\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04690\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04690\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04690\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04690\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.04690\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b6c4608f08>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12,   activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    " \n",
    "model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4547 samples, validate on 1950 samples\n",
      "Epoch 1/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0483 - val_accuracy: 0.9892\n",
      "Epoch 2/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.0894 - val_accuracy: 0.9821\n",
      "Epoch 3/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0411 - val_accuracy: 0.9918\n",
      "Epoch 4/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
      "Epoch 5/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0566 - val_accuracy: 0.9892\n",
      "Epoch 6/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.0586 - val_accuracy: 0.9872\n",
      "Epoch 7/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0444 - val_accuracy: 0.9903\n",
      "Epoch 8/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.0497 - val_accuracy: 0.9872\n",
      "Epoch 9/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0494 - val_accuracy: 0.9903\n",
      "Epoch 10/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.0468 - val_accuracy: 0.9897\n",
      "Epoch 11/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0537 - val_accuracy: 0.9887\n",
      "Epoch 12/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0458 - val_accuracy: 0.9897\n",
      "Epoch 13/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0422 - val_accuracy: 0.9913\n",
      "Epoch 14/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0519 - val_accuracy: 0.9897\n",
      "Epoch 15/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.0495 - val_accuracy: 0.9897\n",
      "Epoch 16/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.0661 - val_accuracy: 0.9862\n",
      "Epoch 17/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.0566 - val_accuracy: 0.9892\n",
      "Epoch 18/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0460 - val_accuracy: 0.9913\n",
      "Epoch 19/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0794 - val_accuracy: 0.9856\n",
      "Epoch 20/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0676 - val_accuracy: 0.9862\n",
      "Epoch 21/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0668 - val_accuracy: 0.9872\n",
      "Epoch 22/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0253 - accuracy: 0.9934 - val_loss: 0.0835 - val_accuracy: 0.9826\n",
      "Epoch 23/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.0654 - val_accuracy: 0.9867\n",
      "Epoch 24/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.0523 - val_accuracy: 0.9887\n",
      "Epoch 25/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0410 - val_accuracy: 0.9918\n",
      "Epoch 26/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0375 - val_accuracy: 0.9913\n",
      "Epoch 27/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0402 - val_accuracy: 0.9903\n",
      "Epoch 28/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "Epoch 29/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.0593 - val_accuracy: 0.9862\n",
      "Epoch 30/3000\n",
      "4547/4547 [==============================] - 0s 45us/sample - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0441 - val_accuracy: 0.9908\n",
      "Epoch 31/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0462 - val_accuracy: 0.9908\n",
      "Epoch 32/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.0483 - val_accuracy: 0.9882\n",
      "Epoch 33/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.0460 - val_accuracy: 0.9918\n",
      "Epoch 34/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0581 - val_accuracy: 0.9887\n",
      "Epoch 35/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.0427 - val_accuracy: 0.9903\n",
      "Epoch 36/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.0494 - val_accuracy: 0.9913\n",
      "Epoch 37/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0467 - val_accuracy: 0.9882\n",
      "Epoch 38/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0442 - val_accuracy: 0.9897\n",
      "Epoch 39/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.0548 - val_accuracy: 0.9882\n",
      "Epoch 40/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0641 - val_accuracy: 0.9862\n",
      "Epoch 41/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0556 - val_accuracy: 0.9872\n",
      "Epoch 42/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0590 - val_accuracy: 0.9892\n",
      "Epoch 43/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0493 - val_accuracy: 0.9872\n",
      "Epoch 44/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0616 - val_accuracy: 0.9892\n",
      "Epoch 45/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.0559 - val_accuracy: 0.9862\n",
      "Epoch 46/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0505 - val_accuracy: 0.9892\n",
      "Epoch 47/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0446 - val_accuracy: 0.9892\n",
      "Epoch 48/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0508 - val_accuracy: 0.9897\n",
      "Epoch 49/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0673 - val_accuracy: 0.9826\n",
      "Epoch 50/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0496 - val_accuracy: 0.9887\n",
      "Epoch 51/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0568 - val_accuracy: 0.9887\n",
      "Epoch 52/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.0615 - val_accuracy: 0.9872\n",
      "Epoch 53/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0532 - val_accuracy: 0.9903\n",
      "Epoch 54/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0466 - val_accuracy: 0.9913\n",
      "Epoch 55/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0638 - val_accuracy: 0.9851\n",
      "Epoch 56/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0665 - val_accuracy: 0.9882\n",
      "Epoch 57/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0494 - val_accuracy: 0.9903\n",
      "Epoch 58/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0170 - accuracy: 0.9934 - val_loss: 0.0565 - val_accuracy: 0.9882\n",
      "Epoch 59/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0624 - val_accuracy: 0.9887\n",
      "Epoch 60/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0738 - val_accuracy: 0.9862\n",
      "Epoch 61/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.0613 - val_accuracy: 0.9851\n",
      "Epoch 62/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.0497 - val_accuracy: 0.9892\n",
      "Epoch 63/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0430 - val_accuracy: 0.9903\n",
      "Epoch 64/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0403 - val_accuracy: 0.9923\n",
      "Epoch 65/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0490 - val_accuracy: 0.9892\n",
      "Epoch 66/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0388 - val_accuracy: 0.9913\n",
      "Epoch 67/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.0664 - val_accuracy: 0.9903\n",
      "Epoch 68/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0477 - val_accuracy: 0.9882\n",
      "Epoch 69/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0495 - val_accuracy: 0.9882\n",
      "Epoch 70/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0423 - val_accuracy: 0.9913\n",
      "Epoch 71/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0584 - val_accuracy: 0.9913\n",
      "Epoch 72/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0556 - val_accuracy: 0.9887\n",
      "Epoch 73/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0476 - val_accuracy: 0.9882\n",
      "Epoch 74/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0582 - val_accuracy: 0.9877\n",
      "Epoch 75/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0517 - val_accuracy: 0.9867\n",
      "Epoch 76/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0271 - accuracy: 0.9925 - val_loss: 0.0872 - val_accuracy: 0.9872\n",
      "Epoch 77/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.0515 - val_accuracy: 0.9903\n",
      "Epoch 78/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9903\n",
      "Epoch 79/3000\n",
      "4547/4547 [==============================] - 0s 41us/sample - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.0409 - val_accuracy: 0.9903\n",
      "Epoch 80/3000\n",
      "4547/4547 [==============================] - 0s 39us/sample - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0399 - val_accuracy: 0.9913\n",
      "Epoch 81/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0382 - val_accuracy: 0.9923\n",
      "Epoch 82/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0405 - val_accuracy: 0.9913\n",
      "Epoch 83/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.0461 - val_accuracy: 0.9892\n",
      "Epoch 84/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0503 - val_accuracy: 0.9887\n",
      "Epoch 85/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.0463 - val_accuracy: 0.9882\n",
      "Epoch 86/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.0511 - val_accuracy: 0.9856\n",
      "Epoch 87/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.0402 - val_accuracy: 0.9913\n",
      "Epoch 88/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0463 - val_accuracy: 0.9887\n",
      "Epoch 89/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0394 - val_accuracy: 0.9897\n",
      "Epoch 90/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0443 - val_accuracy: 0.9897\n",
      "Epoch 91/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0412 - val_accuracy: 0.9913\n",
      "Epoch 92/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0422 - val_accuracy: 0.9908\n",
      "Epoch 93/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0414 - val_accuracy: 0.9913\n",
      "Epoch 94/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.0437 - val_accuracy: 0.9903\n",
      "Epoch 95/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.0428 - val_accuracy: 0.9892\n",
      "Epoch 96/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.0580 - val_accuracy: 0.9821\n",
      "Epoch 97/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0252 - accuracy: 0.9910 - val_loss: 0.0330 - val_accuracy: 0.9918\n",
      "Epoch 98/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.0422 - val_accuracy: 0.9908\n",
      "Epoch 99/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0382 - val_accuracy: 0.9923\n",
      "Epoch 100/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 101/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 102/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.0441 - val_accuracy: 0.9892\n",
      "Epoch 103/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0619 - val_accuracy: 0.9856\n",
      "Epoch 104/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.0421 - val_accuracy: 0.9908\n",
      "Epoch 105/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0198 - accuracy: 0.9925 - val_loss: 0.0407 - val_accuracy: 0.9897\n",
      "Epoch 106/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0396 - val_accuracy: 0.9928\n",
      "Epoch 107/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0424 - val_accuracy: 0.9908\n",
      "Epoch 108/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0549 - val_accuracy: 0.9877\n",
      "Epoch 109/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0444 - val_accuracy: 0.9897\n",
      "Epoch 110/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0200 - accuracy: 0.9925 - val_loss: 0.0576 - val_accuracy: 0.9882\n",
      "Epoch 111/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0599 - val_accuracy: 0.9887\n",
      "Epoch 112/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0177 - accuracy: 0.9930 - val_loss: 0.0442 - val_accuracy: 0.9897\n",
      "Epoch 113/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0463 - val_accuracy: 0.9897\n",
      "Epoch 114/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 115/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.0737 - val_accuracy: 0.9851\n",
      "Epoch 116/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0492 - val_accuracy: 0.9908\n",
      "Epoch 117/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.0497 - val_accuracy: 0.9897\n",
      "Epoch 118/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0459 - val_accuracy: 0.9882\n",
      "Epoch 119/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0594 - val_accuracy: 0.9897\n",
      "Epoch 120/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.0475 - val_accuracy: 0.9908\n",
      "Epoch 121/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.0458 - val_accuracy: 0.9913\n",
      "Epoch 122/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0556 - val_accuracy: 0.9892\n",
      "Epoch 123/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0587 - val_accuracy: 0.9872\n",
      "Epoch 124/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.0693 - val_accuracy: 0.9851\n",
      "Epoch 125/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0525 - val_accuracy: 0.9897\n",
      "Epoch 126/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0473 - val_accuracy: 0.9897\n",
      "Epoch 127/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0439 - val_accuracy: 0.9887\n",
      "Epoch 128/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0622 - val_accuracy: 0.9872\n",
      "Epoch 129/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.0499 - val_accuracy: 0.9903\n",
      "Epoch 130/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0795 - val_accuracy: 0.9856\n",
      "Epoch 131/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.0409 - val_accuracy: 0.9903\n",
      "Epoch 132/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0191 - accuracy: 0.9925 - val_loss: 0.0428 - val_accuracy: 0.9897\n",
      "Epoch 133/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.0478 - val_accuracy: 0.9877\n",
      "Epoch 134/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
      "Epoch 135/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0234 - accuracy: 0.9905 - val_loss: 0.0516 - val_accuracy: 0.9903\n",
      "Epoch 136/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0414 - val_accuracy: 0.9887\n",
      "Epoch 137/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0412 - val_accuracy: 0.9897\n",
      "Epoch 138/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0358 - val_accuracy: 0.9923\n",
      "Epoch 139/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.0388 - val_accuracy: 0.9903\n",
      "Epoch 140/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.0363 - val_accuracy: 0.9923\n",
      "Epoch 141/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0372 - val_accuracy: 0.9903\n",
      "Epoch 142/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.0393 - val_accuracy: 0.9897\n",
      "Epoch 143/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0210 - accuracy: 0.9919 - val_loss: 0.0564 - val_accuracy: 0.9856\n",
      "Epoch 144/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0514 - val_accuracy: 0.9867\n",
      "Epoch 145/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0378 - val_accuracy: 0.9913\n",
      "Epoch 146/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0752 - val_accuracy: 0.9790\n",
      "Epoch 147/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0407 - val_accuracy: 0.9908\n",
      "Epoch 148/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.0349 - val_accuracy: 0.9928\n",
      "Epoch 149/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0363 - val_accuracy: 0.9918\n",
      "Epoch 150/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0408 - val_accuracy: 0.9903\n",
      "Epoch 151/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.0426 - val_accuracy: 0.9887\n",
      "Epoch 152/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0362 - val_accuracy: 0.9918\n",
      "Epoch 153/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0371 - val_accuracy: 0.9913\n",
      "Epoch 154/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.9941 - val_loss: 0.0341 - val_accuracy: 0.9933\n",
      "Epoch 155/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0391 - val_accuracy: 0.9903\n",
      "Epoch 156/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0445 - val_accuracy: 0.9882\n",
      "Epoch 157/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0366 - val_accuracy: 0.9918\n",
      "Epoch 158/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.0348 - val_accuracy: 0.9903\n",
      "Epoch 159/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0454 - val_accuracy: 0.9903\n",
      "Epoch 160/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0374 - val_accuracy: 0.9923\n",
      "Epoch 161/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0444 - val_accuracy: 0.9892\n",
      "Epoch 162/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.0451 - val_accuracy: 0.9877\n",
      "Epoch 163/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
      "Epoch 164/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0479 - val_accuracy: 0.9877\n",
      "Epoch 165/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 166/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0440 - val_accuracy: 0.9913\n",
      "Epoch 167/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.0465 - val_accuracy: 0.9903\n",
      "Epoch 168/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0471 - val_accuracy: 0.9903\n",
      "Epoch 169/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0455 - val_accuracy: 0.9908\n",
      "Epoch 170/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0462 - val_accuracy: 0.9908\n",
      "Epoch 171/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0550 - val_accuracy: 0.9892\n",
      "Epoch 172/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0395 - val_accuracy: 0.9908\n",
      "Epoch 173/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.0449 - val_accuracy: 0.9903\n",
      "Epoch 174/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0428 - val_accuracy: 0.9908\n",
      "Epoch 175/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.0479 - val_accuracy: 0.9867\n",
      "Epoch 176/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0403 - val_accuracy: 0.9908\n",
      "Epoch 177/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0263 - accuracy: 0.9914 - val_loss: 0.0523 - val_accuracy: 0.9897\n",
      "Epoch 178/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0423 - val_accuracy: 0.9918\n",
      "Epoch 179/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0187 - accuracy: 0.9934 - val_loss: 0.0387 - val_accuracy: 0.9923\n",
      "Epoch 180/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0475 - val_accuracy: 0.9892\n",
      "Epoch 181/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.0416 - val_accuracy: 0.9923\n",
      "Epoch 182/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0408 - val_accuracy: 0.9913\n",
      "Epoch 183/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0422 - val_accuracy: 0.9918\n",
      "Epoch 184/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0435 - val_accuracy: 0.9892\n",
      "Epoch 185/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0418 - val_accuracy: 0.9908\n",
      "Epoch 186/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0162 - accuracy: 0.9941 - val_loss: 0.0488 - val_accuracy: 0.9897\n",
      "Epoch 187/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.0447 - val_accuracy: 0.9908\n",
      "Epoch 188/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0479 - val_accuracy: 0.9897\n",
      "Epoch 189/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0444 - val_accuracy: 0.9892\n",
      "Epoch 190/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0494 - val_accuracy: 0.9897\n",
      "Epoch 191/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0404 - val_accuracy: 0.9923\n",
      "Epoch 192/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0495 - val_accuracy: 0.9903\n",
      "Epoch 193/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0544 - val_accuracy: 0.9908\n",
      "Epoch 194/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0468 - val_accuracy: 0.9913\n",
      "Epoch 195/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0660 - val_accuracy: 0.9856\n",
      "Epoch 196/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0614 - val_accuracy: 0.9887\n",
      "Epoch 197/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0641 - val_accuracy: 0.9892\n",
      "Epoch 198/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0528 - val_accuracy: 0.9877\n",
      "Epoch 199/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0428 - val_accuracy: 0.9892\n",
      "Epoch 200/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0409 - val_accuracy: 0.9918\n",
      "Epoch 201/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0391 - val_accuracy: 0.9903\n",
      "Epoch 202/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0932 - val_accuracy: 0.9795\n",
      "Epoch 203/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.0423 - val_accuracy: 0.9892\n",
      "Epoch 204/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0497 - val_accuracy: 0.9903\n",
      "Epoch 205/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0201 - accuracy: 0.9925 - val_loss: 0.0515 - val_accuracy: 0.9887\n",
      "Epoch 206/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0631 - val_accuracy: 0.9856\n",
      "Epoch 207/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0430 - val_accuracy: 0.9887\n",
      "Epoch 208/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0473 - val_accuracy: 0.9908\n",
      "Epoch 209/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
      "Epoch 210/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0191 - accuracy: 0.9930 - val_loss: 0.0790 - val_accuracy: 0.9841\n",
      "Epoch 211/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0478 - val_accuracy: 0.9897\n",
      "Epoch 212/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0715 - val_accuracy: 0.9872\n",
      "Epoch 213/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.0474 - val_accuracy: 0.9882\n",
      "Epoch 214/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.0685 - val_accuracy: 0.9887\n",
      "Epoch 215/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0600 - val_accuracy: 0.9892\n",
      "Epoch 216/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.0787 - val_accuracy: 0.9841\n",
      "Epoch 217/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.0585 - val_accuracy: 0.9887\n",
      "Epoch 218/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.0504 - val_accuracy: 0.9908\n",
      "Epoch 219/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0692 - val_accuracy: 0.9851\n",
      "Epoch 220/3000\n",
      "4547/4547 [==============================] - 0s 40us/sample - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0543 - val_accuracy: 0.9913\n",
      "Epoch 221/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0651 - val_accuracy: 0.9862\n",
      "Epoch 222/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0202 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9913\n",
      "Epoch 223/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0555 - val_accuracy: 0.9903\n",
      "Epoch 224/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0532 - val_accuracy: 0.9908\n",
      "Epoch 225/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0595 - val_accuracy: 0.9897\n",
      "Epoch 226/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.0765 - val_accuracy: 0.9846\n",
      "Epoch 227/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0349 - val_accuracy: 0.9908\n",
      "Epoch 228/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0367 - val_accuracy: 0.9903\n",
      "Epoch 229/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0425 - val_accuracy: 0.9908\n",
      "Epoch 230/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0379 - val_accuracy: 0.9908\n",
      "Epoch 231/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0433 - val_accuracy: 0.9913\n",
      "Epoch 232/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
      "Epoch 233/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.0520 - val_accuracy: 0.9892\n",
      "Epoch 234/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.0438 - val_accuracy: 0.9913\n",
      "Epoch 235/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.0410 - val_accuracy: 0.9918\n",
      "Epoch 236/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0645 - val_accuracy: 0.9856\n",
      "Epoch 237/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0452 - val_accuracy: 0.9918\n",
      "Epoch 238/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0619 - val_accuracy: 0.9892\n",
      "Epoch 239/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0732 - val_accuracy: 0.9841\n",
      "Epoch 240/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0518 - val_accuracy: 0.9897\n",
      "Epoch 241/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0495 - val_accuracy: 0.9908\n",
      "Epoch 242/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0484 - val_accuracy: 0.9897\n",
      "Epoch 243/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0665 - val_accuracy: 0.9856\n",
      "Epoch 244/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.0547 - val_accuracy: 0.9892\n",
      "Epoch 245/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0517 - val_accuracy: 0.9908\n",
      "Epoch 246/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0476 - val_accuracy: 0.9913\n",
      "Epoch 247/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.0541 - val_accuracy: 0.9887\n",
      "Epoch 248/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.0631 - val_accuracy: 0.9892\n",
      "Epoch 249/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0549 - val_accuracy: 0.9908\n",
      "Epoch 250/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0551 - val_accuracy: 0.9903\n",
      "Epoch 251/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.0618 - val_accuracy: 0.9908\n",
      "Epoch 252/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0691 - val_accuracy: 0.9887\n",
      "Epoch 253/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0495 - val_accuracy: 0.9851\n",
      "Epoch 254/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.0478 - val_accuracy: 0.9897\n",
      "Epoch 255/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0521 - val_accuracy: 0.9892\n",
      "Epoch 256/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0555 - val_accuracy: 0.9903\n",
      "Epoch 257/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0501 - val_accuracy: 0.9903\n",
      "Epoch 258/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0564 - val_accuracy: 0.9903\n",
      "Epoch 259/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0532 - val_accuracy: 0.9918\n",
      "Epoch 260/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0553 - val_accuracy: 0.9882\n",
      "Epoch 261/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0553 - val_accuracy: 0.9903\n",
      "Epoch 262/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.0672 - val_accuracy: 0.9908\n",
      "Epoch 263/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0689 - val_accuracy: 0.9892\n",
      "Epoch 264/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.0483 - val_accuracy: 0.9913\n",
      "Epoch 265/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0670 - val_accuracy: 0.9892\n",
      "Epoch 266/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.0527 - val_accuracy: 0.9908\n",
      "Epoch 267/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0546 - val_accuracy: 0.9897\n",
      "Epoch 268/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0897 - val_accuracy: 0.9826\n",
      "Epoch 269/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0523 - val_accuracy: 0.9908\n",
      "Epoch 270/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.1416 - val_accuracy: 0.9662\n",
      "Epoch 271/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0563 - val_accuracy: 0.9897\n",
      "Epoch 272/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0526 - val_accuracy: 0.9897\n",
      "Epoch 273/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0644 - val_accuracy: 0.9887\n",
      "Epoch 274/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0961 - val_accuracy: 0.9841\n",
      "Epoch 275/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0593 - val_accuracy: 0.9892\n",
      "Epoch 276/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0596 - val_accuracy: 0.9903\n",
      "Epoch 277/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.0407 - val_accuracy: 0.9887\n",
      "Epoch 278/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0526 - val_accuracy: 0.9851\n",
      "Epoch 279/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0171 - accuracy: 0.9936 - val_loss: 0.0744 - val_accuracy: 0.9851\n",
      "Epoch 280/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.0516 - val_accuracy: 0.9903\n",
      "Epoch 281/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0575 - val_accuracy: 0.9903\n",
      "Epoch 282/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0610 - val_accuracy: 0.9903\n",
      "Epoch 283/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0168 - accuracy: 0.9941 - val_loss: 0.0449 - val_accuracy: 0.9923\n",
      "Epoch 284/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0643 - val_accuracy: 0.9872\n",
      "Epoch 285/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0679 - val_accuracy: 0.9887\n",
      "Epoch 286/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0665 - val_accuracy: 0.9892\n",
      "Epoch 287/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0559 - val_accuracy: 0.9913\n",
      "Epoch 288/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0695 - val_accuracy: 0.9908\n",
      "Epoch 289/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0513 - val_accuracy: 0.9908\n",
      "Epoch 290/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0629 - val_accuracy: 0.9846\n",
      "Epoch 291/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0571 - val_accuracy: 0.9897\n",
      "Epoch 292/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0472 - val_accuracy: 0.9887\n",
      "Epoch 293/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0579 - val_accuracy: 0.9903\n",
      "Epoch 294/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0556 - val_accuracy: 0.9903\n",
      "Epoch 295/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0596 - val_accuracy: 0.9882\n",
      "Epoch 296/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0566 - val_accuracy: 0.9897\n",
      "Epoch 297/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.0892 - val_accuracy: 0.9882\n",
      "Epoch 298/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0745 - val_accuracy: 0.9867\n",
      "Epoch 299/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0838 - val_accuracy: 0.9856\n",
      "Epoch 300/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0704 - val_accuracy: 0.9872\n",
      "Epoch 301/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.0687 - val_accuracy: 0.9897\n",
      "Epoch 302/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0782 - val_accuracy: 0.9867\n",
      "Epoch 303/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.0739 - val_accuracy: 0.9897\n",
      "Epoch 304/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0498 - val_accuracy: 0.9872\n",
      "Epoch 305/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0482 - val_accuracy: 0.9872\n",
      "Epoch 306/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0405 - val_accuracy: 0.9903\n",
      "Epoch 307/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0590 - val_accuracy: 0.9903\n",
      "Epoch 308/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0779 - val_accuracy: 0.9877\n",
      "Epoch 309/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0607 - val_accuracy: 0.9892\n",
      "Epoch 310/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0177 - accuracy: 0.9927 - val_loss: 0.0690 - val_accuracy: 0.9882\n",
      "Epoch 311/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0626 - val_accuracy: 0.9903\n",
      "Epoch 312/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0811 - val_accuracy: 0.9892\n",
      "Epoch 313/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0700 - val_accuracy: 0.9892\n",
      "Epoch 314/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0720 - val_accuracy: 0.9887\n",
      "Epoch 315/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0622 - val_accuracy: 0.9903\n",
      "Epoch 316/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0842 - val_accuracy: 0.9887\n",
      "Epoch 317/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0444 - val_accuracy: 0.9918\n",
      "Epoch 318/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 319/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0576 - val_accuracy: 0.9897\n",
      "Epoch 320/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0621 - val_accuracy: 0.9897\n",
      "Epoch 321/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0733 - val_accuracy: 0.9882\n",
      "Epoch 322/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0567 - val_accuracy: 0.9908\n",
      "Epoch 323/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0729 - val_accuracy: 0.9872\n",
      "Epoch 324/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.0569 - val_accuracy: 0.9908\n",
      "Epoch 325/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0813 - val_accuracy: 0.9892\n",
      "Epoch 326/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0644 - val_accuracy: 0.9887\n",
      "Epoch 327/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0591 - val_accuracy: 0.9897\n",
      "Epoch 328/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0191 - accuracy: 0.9925 - val_loss: 0.0572 - val_accuracy: 0.9892\n",
      "Epoch 329/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0685 - val_accuracy: 0.9805\n",
      "Epoch 330/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0208 - accuracy: 0.9912 - val_loss: 0.0736 - val_accuracy: 0.9887\n",
      "Epoch 331/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0673 - val_accuracy: 0.9872\n",
      "Epoch 332/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.0544 - val_accuracy: 0.9882\n",
      "Epoch 333/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0678 - val_accuracy: 0.9892\n",
      "Epoch 334/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0686 - val_accuracy: 0.9897\n",
      "Epoch 335/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0718 - val_accuracy: 0.9897\n",
      "Epoch 336/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0526 - val_accuracy: 0.9903\n",
      "Epoch 337/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0608 - val_accuracy: 0.9836\n",
      "Epoch 338/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.0599 - val_accuracy: 0.9897\n",
      "Epoch 339/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0672 - val_accuracy: 0.9897\n",
      "Epoch 340/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0771 - val_accuracy: 0.9877\n",
      "Epoch 341/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0919 - val_accuracy: 0.9877\n",
      "Epoch 342/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0437 - val_accuracy: 0.9887\n",
      "Epoch 343/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0433 - val_accuracy: 0.9892\n",
      "Epoch 344/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0607 - val_accuracy: 0.9872\n",
      "Epoch 345/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.0399 - val_accuracy: 0.9923\n",
      "Epoch 346/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0948 - val_accuracy: 0.9810\n",
      "Epoch 347/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0639 - val_accuracy: 0.9903\n",
      "Epoch 348/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0593 - val_accuracy: 0.9903\n",
      "Epoch 349/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0570 - val_accuracy: 0.9897\n",
      "Epoch 350/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0548 - val_accuracy: 0.9882\n",
      "Epoch 351/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.0760 - val_accuracy: 0.9867\n",
      "Epoch 352/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0767 - val_accuracy: 0.9887\n",
      "Epoch 353/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.0622 - val_accuracy: 0.9892\n",
      "Epoch 354/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0748 - val_accuracy: 0.9877\n",
      "Epoch 355/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0541 - val_accuracy: 0.9908\n",
      "Epoch 356/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0745 - val_accuracy: 0.9897\n",
      "Epoch 357/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0794 - val_accuracy: 0.9877\n",
      "Epoch 358/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
      "Epoch 359/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0721 - val_accuracy: 0.9892\n",
      "Epoch 360/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0731 - val_accuracy: 0.9867\n",
      "Epoch 361/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0803 - val_accuracy: 0.9887\n",
      "Epoch 362/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9897\n",
      "Epoch 363/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0723 - val_accuracy: 0.9892\n",
      "Epoch 364/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0706 - val_accuracy: 0.9887\n",
      "Epoch 365/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.0707 - val_accuracy: 0.9887\n",
      "Epoch 366/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0781 - val_accuracy: 0.9887\n",
      "Epoch 367/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0566 - val_accuracy: 0.9887\n",
      "Epoch 368/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0602 - val_accuracy: 0.9908\n",
      "Epoch 369/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0562 - val_accuracy: 0.9892\n",
      "Epoch 370/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0390 - val_accuracy: 0.9913\n",
      "Epoch 371/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0633 - val_accuracy: 0.9856\n",
      "Epoch 372/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0425 - val_accuracy: 0.9913\n",
      "Epoch 373/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0521 - val_accuracy: 0.9882\n",
      "Epoch 374/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0574 - val_accuracy: 0.9903\n",
      "Epoch 375/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0228 - accuracy: 0.9914 - val_loss: 0.0575 - val_accuracy: 0.9903\n",
      "Epoch 376/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0525 - val_accuracy: 0.9887\n",
      "Epoch 377/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0459 - val_accuracy: 0.9867\n",
      "Epoch 378/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0600 - val_accuracy: 0.9897\n",
      "Epoch 379/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0629 - val_accuracy: 0.9882\n",
      "Epoch 380/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0714 - val_accuracy: 0.9867\n",
      "Epoch 381/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0616 - val_accuracy: 0.9903\n",
      "Epoch 382/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0705 - val_accuracy: 0.9851\n",
      "Epoch 383/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0579 - val_accuracy: 0.9908\n",
      "Epoch 384/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0834 - val_accuracy: 0.9872\n",
      "Epoch 385/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0756 - val_accuracy: 0.9887\n",
      "Epoch 386/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0662 - val_accuracy: 0.9897\n",
      "Epoch 387/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0810 - val_accuracy: 0.9882\n",
      "Epoch 388/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0433 - val_accuracy: 0.9908\n",
      "Epoch 389/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0440 - val_accuracy: 0.9903\n",
      "Epoch 390/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0149 - accuracy: 0.9943 - val_loss: 0.0423 - val_accuracy: 0.9903\n",
      "Epoch 391/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0792 - val_accuracy: 0.9872\n",
      "Epoch 392/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.0637 - val_accuracy: 0.9892\n",
      "Epoch 393/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0811 - val_accuracy: 0.9877\n",
      "Epoch 394/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0665 - val_accuracy: 0.9903\n",
      "Epoch 395/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0635 - val_accuracy: 0.9897\n",
      "Epoch 396/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0855 - val_accuracy: 0.9897\n",
      "Epoch 397/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0661 - val_accuracy: 0.9897\n",
      "Epoch 398/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0772 - val_accuracy: 0.9887\n",
      "Epoch 399/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0756 - val_accuracy: 0.9882\n",
      "Epoch 400/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0565 - val_accuracy: 0.9892\n",
      "Epoch 401/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.0631 - val_accuracy: 0.9908\n",
      "Epoch 402/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "Epoch 403/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0556 - val_accuracy: 0.9908\n",
      "Epoch 404/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.0753 - val_accuracy: 0.9897\n",
      "Epoch 405/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0467 - val_accuracy: 0.9908\n",
      "Epoch 406/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0700 - val_accuracy: 0.9892\n",
      "Epoch 407/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0639 - val_accuracy: 0.9872\n",
      "Epoch 408/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0616 - val_accuracy: 0.9908\n",
      "Epoch 409/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0749 - val_accuracy: 0.9892\n",
      "Epoch 410/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0714 - val_accuracy: 0.9882\n",
      "Epoch 411/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0937 - val_accuracy: 0.9877\n",
      "Epoch 412/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0459 - val_accuracy: 0.9908\n",
      "Epoch 413/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0182 - accuracy: 0.9921 - val_loss: 0.0514 - val_accuracy: 0.9856\n",
      "Epoch 414/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.0452 - val_accuracy: 0.9908\n",
      "Epoch 415/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0569 - val_accuracy: 0.9882\n",
      "Epoch 416/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0483 - val_accuracy: 0.9897\n",
      "Epoch 417/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0651 - val_accuracy: 0.9887\n",
      "Epoch 418/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0551 - val_accuracy: 0.9867\n",
      "Epoch 419/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0509 - val_accuracy: 0.9903\n",
      "Epoch 420/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0813 - val_accuracy: 0.9856\n",
      "Epoch 421/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0531 - val_accuracy: 0.9913\n",
      "Epoch 422/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0761 - val_accuracy: 0.9892\n",
      "Epoch 423/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0752 - val_accuracy: 0.9882\n",
      "Epoch 424/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0746 - val_accuracy: 0.9892\n",
      "Epoch 425/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0544 - val_accuracy: 0.9897\n",
      "Epoch 426/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0562 - val_accuracy: 0.9897\n",
      "Epoch 427/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0579 - val_accuracy: 0.9908\n",
      "Epoch 428/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0659 - val_accuracy: 0.9897\n",
      "Epoch 429/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0760 - val_accuracy: 0.9887\n",
      "Epoch 430/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0648 - val_accuracy: 0.9887\n",
      "Epoch 431/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0746 - val_accuracy: 0.9877\n",
      "Epoch 432/3000\n",
      "4547/4547 [==============================] - 0s 41us/sample - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "Epoch 433/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0600 - val_accuracy: 0.9872\n",
      "Epoch 434/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.0716 - val_accuracy: 0.9882\n",
      "Epoch 435/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0700 - val_accuracy: 0.9892\n",
      "Epoch 436/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0738 - val_accuracy: 0.9903\n",
      "Epoch 437/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0886 - val_accuracy: 0.9821\n",
      "Epoch 438/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.0477 - val_accuracy: 0.9887\n",
      "Epoch 439/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0452 - val_accuracy: 0.9877\n",
      "Epoch 440/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.0372 - val_accuracy: 0.9923\n",
      "Epoch 441/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0344 - val_accuracy: 0.9923\n",
      "Epoch 442/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0332 - val_accuracy: 0.9933\n",
      "Epoch 443/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0481 - val_accuracy: 0.9892\n",
      "Epoch 444/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0340 - val_accuracy: 0.9928\n",
      "Epoch 445/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
      "Epoch 446/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0364 - val_accuracy: 0.9913\n",
      "Epoch 447/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0322 - val_accuracy: 0.9918\n",
      "Epoch 448/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.0350 - val_accuracy: 0.9908\n",
      "Epoch 449/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0357 - val_accuracy: 0.9923\n",
      "Epoch 450/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0420 - val_accuracy: 0.9892\n",
      "Epoch 451/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0343 - val_accuracy: 0.9903\n",
      "Epoch 452/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0352 - val_accuracy: 0.9923\n",
      "Epoch 453/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0367 - val_accuracy: 0.9923\n",
      "Epoch 454/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0634 - val_accuracy: 0.9862\n",
      "Epoch 455/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0354 - val_accuracy: 0.9928\n",
      "Epoch 456/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0449 - val_accuracy: 0.9897\n",
      "Epoch 457/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0373 - val_accuracy: 0.9923\n",
      "Epoch 458/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0755 - val_accuracy: 0.9800\n",
      "Epoch 459/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.0491 - val_accuracy: 0.9887\n",
      "Epoch 460/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0407 - val_accuracy: 0.9897\n",
      "Epoch 461/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0785 - val_accuracy: 0.9862\n",
      "Epoch 462/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0537 - val_accuracy: 0.9897\n",
      "Epoch 463/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0530 - val_accuracy: 0.9892\n",
      "Epoch 464/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0496 - val_accuracy: 0.9862\n",
      "Epoch 465/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0517 - val_accuracy: 0.9903\n",
      "Epoch 466/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0812 - val_accuracy: 0.9867\n",
      "Epoch 467/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0151 - accuracy: 0.9941 - val_loss: 0.0607 - val_accuracy: 0.9897\n",
      "Epoch 468/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0226 - accuracy: 0.9903 - val_loss: 0.0956 - val_accuracy: 0.9826\n",
      "Epoch 469/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0722 - val_accuracy: 0.9882\n",
      "Epoch 470/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9897\n",
      "Epoch 471/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.0647 - val_accuracy: 0.9897\n",
      "Epoch 472/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.0748 - val_accuracy: 0.9897\n",
      "Epoch 473/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0602 - val_accuracy: 0.9903\n",
      "Epoch 474/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0634 - val_accuracy: 0.9877\n",
      "Epoch 475/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0490 - val_accuracy: 0.9903\n",
      "Epoch 476/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0513 - val_accuracy: 0.9903\n",
      "Epoch 477/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0809 - val_accuracy: 0.9867\n",
      "Epoch 478/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0782 - val_accuracy: 0.9856\n",
      "Epoch 479/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.9941 - val_loss: 0.0558 - val_accuracy: 0.9892\n",
      "Epoch 480/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0587 - val_accuracy: 0.9892\n",
      "Epoch 481/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0598 - val_accuracy: 0.9903\n",
      "Epoch 482/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0691 - val_accuracy: 0.9897\n",
      "Epoch 483/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "Epoch 484/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.9936 - val_loss: 0.0654 - val_accuracy: 0.9872\n",
      "Epoch 485/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
      "Epoch 486/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0665 - val_accuracy: 0.9887\n",
      "Epoch 487/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0563 - val_accuracy: 0.9887\n",
      "Epoch 488/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0527 - val_accuracy: 0.9887\n",
      "Epoch 489/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0612 - val_accuracy: 0.9887\n",
      "Epoch 490/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0531 - val_accuracy: 0.9903\n",
      "Epoch 491/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0683 - val_accuracy: 0.9892\n",
      "Epoch 492/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0680 - val_accuracy: 0.9882\n",
      "Epoch 493/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0591 - val_accuracy: 0.9887\n",
      "Epoch 494/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0589 - val_accuracy: 0.9903\n",
      "Epoch 495/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0544 - val_accuracy: 0.9892\n",
      "Epoch 496/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.0578 - val_accuracy: 0.9903\n",
      "Epoch 497/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0639 - val_accuracy: 0.9897\n",
      "Epoch 498/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0560 - val_accuracy: 0.9897\n",
      "Epoch 499/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.0522 - val_accuracy: 0.9892\n",
      "Epoch 500/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.0493 - val_accuracy: 0.9897\n",
      "Epoch 501/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0163 - accuracy: 0.9938 - val_loss: 0.0627 - val_accuracy: 0.9892\n",
      "Epoch 502/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0363 - val_accuracy: 0.9892\n",
      "Epoch 503/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0405 - val_accuracy: 0.9908\n",
      "Epoch 504/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0404 - val_accuracy: 0.9918\n",
      "Epoch 505/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.0360 - val_accuracy: 0.9923\n",
      "Epoch 506/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0358 - val_accuracy: 0.9923\n",
      "Epoch 507/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0348 - val_accuracy: 0.9923\n",
      "Epoch 508/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0441 - val_accuracy: 0.9887\n",
      "Epoch 509/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 510/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0361 - val_accuracy: 0.9908\n",
      "Epoch 511/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 512/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
      "Epoch 513/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.0456 - val_accuracy: 0.9887\n",
      "Epoch 514/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0533 - val_accuracy: 0.9892\n",
      "Epoch 515/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0615 - val_accuracy: 0.9887\n",
      "Epoch 516/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0357 - val_accuracy: 0.9923\n",
      "Epoch 517/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.0725 - val_accuracy: 0.9862\n",
      "Epoch 518/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0534 - val_accuracy: 0.9882\n",
      "Epoch 519/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.0385 - val_accuracy: 0.9913\n",
      "Epoch 520/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 521/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0555 - val_accuracy: 0.9836\n",
      "Epoch 522/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0953 - val_accuracy: 0.9790\n",
      "Epoch 523/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0463 - val_accuracy: 0.9913\n",
      "Epoch 524/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.0541 - val_accuracy: 0.9892\n",
      "Epoch 525/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0466 - val_accuracy: 0.9892\n",
      "Epoch 526/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0700 - val_accuracy: 0.9882\n",
      "Epoch 527/3000\n",
      "4547/4547 [==============================] - 0s 39us/sample - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0532 - val_accuracy: 0.9918\n",
      "Epoch 528/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0709 - val_accuracy: 0.9882\n",
      "Epoch 529/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9903\n",
      "Epoch 530/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0542 - val_accuracy: 0.9887\n",
      "Epoch 531/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0716 - val_accuracy: 0.9877\n",
      "Epoch 532/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0593 - val_accuracy: 0.9846\n",
      "Epoch 533/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0569 - val_accuracy: 0.9903\n",
      "Epoch 534/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0533 - val_accuracy: 0.9908\n",
      "Epoch 535/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0562 - val_accuracy: 0.9908\n",
      "Epoch 536/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0566 - val_accuracy: 0.9897\n",
      "Epoch 537/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0507 - val_accuracy: 0.9897\n",
      "Epoch 538/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0550 - val_accuracy: 0.9908\n",
      "Epoch 539/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0218 - accuracy: 0.9910 - val_loss: 0.0480 - val_accuracy: 0.9908\n",
      "Epoch 540/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0202 - accuracy: 0.9923 - val_loss: 0.0620 - val_accuracy: 0.9903\n",
      "Epoch 541/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0562 - val_accuracy: 0.9897\n",
      "Epoch 542/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0544 - val_accuracy: 0.9903\n",
      "Epoch 543/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0653 - val_accuracy: 0.9908\n",
      "Epoch 544/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0597 - val_accuracy: 0.9903\n",
      "Epoch 545/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0528 - val_accuracy: 0.9897\n",
      "Epoch 546/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0535 - val_accuracy: 0.9903\n",
      "Epoch 547/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0734 - val_accuracy: 0.9867\n",
      "Epoch 548/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0825 - val_accuracy: 0.9795\n",
      "Epoch 549/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0513 - val_accuracy: 0.9903\n",
      "Epoch 550/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0697 - val_accuracy: 0.9908\n",
      "Epoch 551/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0642 - val_accuracy: 0.9892\n",
      "Epoch 552/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0728 - val_accuracy: 0.9897\n",
      "Epoch 553/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0231 - accuracy: 0.9945 - val_loss: 0.1038 - val_accuracy: 0.9846\n",
      "Epoch 554/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0522 - val_accuracy: 0.9897\n",
      "Epoch 555/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0507 - val_accuracy: 0.9897\n",
      "Epoch 556/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0496 - val_accuracy: 0.9903\n",
      "Epoch 557/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0816 - val_accuracy: 0.9892\n",
      "Epoch 558/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0590 - val_accuracy: 0.9903\n",
      "Epoch 559/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0675 - val_accuracy: 0.9903\n",
      "Epoch 560/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0622 - val_accuracy: 0.9897\n",
      "Epoch 561/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0638 - val_accuracy: 0.9908\n",
      "Epoch 562/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0783 - val_accuracy: 0.9872\n",
      "Epoch 563/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0514 - val_accuracy: 0.9856\n",
      "Epoch 564/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0500 - val_accuracy: 0.9897\n",
      "Epoch 565/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0669 - val_accuracy: 0.9882\n",
      "Epoch 566/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0723 - val_accuracy: 0.9903\n",
      "Epoch 567/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.0692 - val_accuracy: 0.9903\n",
      "Epoch 568/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0589 - val_accuracy: 0.9892\n",
      "Epoch 569/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0436 - val_accuracy: 0.9903\n",
      "Epoch 570/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0433 - val_accuracy: 0.9903\n",
      "Epoch 571/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0472 - val_accuracy: 0.9897\n",
      "Epoch 572/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0630 - val_accuracy: 0.9882\n",
      "Epoch 573/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0564 - val_accuracy: 0.9882\n",
      "Epoch 574/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0471 - val_accuracy: 0.9903\n",
      "Epoch 575/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0631 - val_accuracy: 0.9877\n",
      "Epoch 576/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.0478 - val_accuracy: 0.9903\n",
      "Epoch 577/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0507 - val_accuracy: 0.9903\n",
      "Epoch 578/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9908\n",
      "Epoch 579/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0599 - val_accuracy: 0.9887\n",
      "Epoch 580/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0507 - val_accuracy: 0.9903\n",
      "Epoch 581/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9892\n",
      "Epoch 582/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0554 - val_accuracy: 0.9892\n",
      "Epoch 583/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.0564 - val_accuracy: 0.9887\n",
      "Epoch 584/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0620 - val_accuracy: 0.9887\n",
      "Epoch 585/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0632 - val_accuracy: 0.9903\n",
      "Epoch 586/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.0567 - val_accuracy: 0.9872\n",
      "Epoch 587/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0628 - val_accuracy: 0.9872\n",
      "Epoch 588/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0559 - val_accuracy: 0.9897\n",
      "Epoch 589/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0482 - val_accuracy: 0.9903\n",
      "Epoch 590/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0771 - val_accuracy: 0.9887\n",
      "Epoch 591/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0698 - val_accuracy: 0.9892\n",
      "Epoch 592/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0800 - val_accuracy: 0.9862\n",
      "Epoch 593/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0705 - val_accuracy: 0.9897\n",
      "Epoch 594/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0538 - val_accuracy: 0.9903\n",
      "Epoch 595/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0472 - val_accuracy: 0.9897\n",
      "Epoch 596/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.0720 - val_accuracy: 0.9846\n",
      "Epoch 597/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0584 - val_accuracy: 0.9903\n",
      "Epoch 598/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0732 - val_accuracy: 0.9882\n",
      "Epoch 599/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0593 - val_accuracy: 0.9903\n",
      "Epoch 600/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0439 - val_accuracy: 0.9913\n",
      "Epoch 601/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0463 - val_accuracy: 0.9908\n",
      "Epoch 602/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0607 - val_accuracy: 0.9892\n",
      "Epoch 603/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0592 - val_accuracy: 0.9897\n",
      "Epoch 604/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0502 - val_accuracy: 0.9887\n",
      "Epoch 605/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0506 - val_accuracy: 0.9872\n",
      "Epoch 606/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0570 - val_accuracy: 0.9897\n",
      "Epoch 607/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0773 - val_accuracy: 0.9877\n",
      "Epoch 608/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0689 - val_accuracy: 0.9877\n",
      "Epoch 609/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0677 - val_accuracy: 0.9887\n",
      "Epoch 610/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0475 - val_accuracy: 0.9908\n",
      "Epoch 611/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0775 - val_accuracy: 0.9882\n",
      "Epoch 612/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0531 - val_accuracy: 0.9897\n",
      "Epoch 613/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0647 - val_accuracy: 0.9897\n",
      "Epoch 614/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0801 - val_accuracy: 0.9841\n",
      "Epoch 615/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0704 - val_accuracy: 0.9897\n",
      "Epoch 616/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0743 - val_accuracy: 0.9795\n",
      "Epoch 617/3000\n",
      "4547/4547 [==============================] - 0s 42us/sample - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0672 - val_accuracy: 0.9887\n",
      "Epoch 618/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0630 - val_accuracy: 0.9903\n",
      "Epoch 619/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0743 - val_accuracy: 0.9897\n",
      "Epoch 620/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0724 - val_accuracy: 0.9877\n",
      "Epoch 621/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0188 - accuracy: 0.9925 - val_loss: 0.0696 - val_accuracy: 0.9908\n",
      "Epoch 622/3000\n",
      "4547/4547 [==============================] - 0s 41us/sample - loss: 0.0143 - accuracy: 0.9943 - val_loss: 0.0476 - val_accuracy: 0.9903\n",
      "Epoch 623/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0541 - val_accuracy: 0.9908\n",
      "Epoch 624/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.0345 - val_accuracy: 0.9918\n",
      "Epoch 625/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.0431 - val_accuracy: 0.9913\n",
      "Epoch 626/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.0516 - val_accuracy: 0.9903\n",
      "Epoch 627/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0456 - val_accuracy: 0.9903\n",
      "Epoch 628/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.0544 - val_accuracy: 0.9903\n",
      "Epoch 629/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0750 - val_accuracy: 0.9841\n",
      "Epoch 630/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0547 - val_accuracy: 0.9908\n",
      "Epoch 631/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0638 - val_accuracy: 0.9892\n",
      "Epoch 632/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.0605 - val_accuracy: 0.9903\n",
      "Epoch 633/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0501 - val_accuracy: 0.9908\n",
      "Epoch 634/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0559 - val_accuracy: 0.9913\n",
      "Epoch 635/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.0542 - val_accuracy: 0.9908\n",
      "Epoch 636/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.0582 - val_accuracy: 0.9908\n",
      "Epoch 637/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0699 - val_accuracy: 0.9887\n",
      "Epoch 638/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0628 - val_accuracy: 0.9908\n",
      "Epoch 639/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0598 - val_accuracy: 0.9913\n",
      "Epoch 640/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0790 - val_accuracy: 0.9872\n",
      "Epoch 641/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0749 - val_accuracy: 0.9877\n",
      "Epoch 642/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0450 - val_accuracy: 0.9897\n",
      "Epoch 643/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0552 - val_accuracy: 0.9903\n",
      "Epoch 644/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0532 - val_accuracy: 0.9918\n",
      "Epoch 645/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0525 - val_accuracy: 0.9903\n",
      "Epoch 646/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0493 - val_accuracy: 0.9918\n",
      "Epoch 647/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.0465 - val_accuracy: 0.9897\n",
      "Epoch 648/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0419 - val_accuracy: 0.9913\n",
      "Epoch 649/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0486 - val_accuracy: 0.9918\n",
      "Epoch 650/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.0885 - val_accuracy: 0.9790\n",
      "Epoch 651/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0515 - val_accuracy: 0.9908\n",
      "Epoch 652/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0499 - val_accuracy: 0.9913\n",
      "Epoch 653/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.0485 - val_accuracy: 0.9908\n",
      "Epoch 654/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0555 - val_accuracy: 0.9908\n",
      "Epoch 655/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0530 - val_accuracy: 0.9913\n",
      "Epoch 656/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0561 - val_accuracy: 0.9913\n",
      "Epoch 657/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0811 - val_accuracy: 0.9841\n",
      "Epoch 658/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.0457 - val_accuracy: 0.9908\n",
      "Epoch 659/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0579 - val_accuracy: 0.9892\n",
      "Epoch 660/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0647 - val_accuracy: 0.9882\n",
      "Epoch 661/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0415 - val_accuracy: 0.9897\n",
      "Epoch 662/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0562 - val_accuracy: 0.9897\n",
      "Epoch 663/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.0446 - val_accuracy: 0.9892\n",
      "Epoch 664/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0494 - val_accuracy: 0.9897\n",
      "Epoch 665/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0445 - val_accuracy: 0.9918\n",
      "Epoch 666/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0644 - val_accuracy: 0.9862\n",
      "Epoch 667/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0769 - val_accuracy: 0.9867\n",
      "Epoch 668/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0515 - val_accuracy: 0.9892\n",
      "Epoch 669/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.0634 - val_accuracy: 0.9882\n",
      "Epoch 670/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0437 - val_accuracy: 0.9918\n",
      "Epoch 671/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 672/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0625 - val_accuracy: 0.9872\n",
      "Epoch 673/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0676 - val_accuracy: 0.9862\n",
      "Epoch 674/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0582 - val_accuracy: 0.9887\n",
      "Epoch 675/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0630 - val_accuracy: 0.9836\n",
      "Epoch 676/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.1237 - val_accuracy: 0.9836\n",
      "Epoch 677/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0416 - val_accuracy: 0.9903\n",
      "Epoch 678/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0398 - val_accuracy: 0.9923\n",
      "Epoch 679/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0426 - val_accuracy: 0.9913\n",
      "Epoch 680/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0340 - val_accuracy: 0.9933\n",
      "Epoch 681/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0361 - val_accuracy: 0.9923\n",
      "Epoch 682/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0391 - val_accuracy: 0.9923\n",
      "Epoch 683/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0442 - val_accuracy: 0.9872\n",
      "Epoch 684/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 685/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0505 - val_accuracy: 0.9867\n",
      "Epoch 686/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0472 - val_accuracy: 0.9872\n",
      "Epoch 687/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0416 - val_accuracy: 0.9897\n",
      "Epoch 688/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0389 - val_accuracy: 0.9913\n",
      "Epoch 689/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0379 - val_accuracy: 0.9897\n",
      "Epoch 690/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0381 - val_accuracy: 0.9923\n",
      "Epoch 691/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0546 - val_accuracy: 0.9908\n",
      "Epoch 692/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9913\n",
      "Epoch 693/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0524 - val_accuracy: 0.9887\n",
      "Epoch 694/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.0407 - val_accuracy: 0.9892\n",
      "Epoch 695/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0524 - val_accuracy: 0.9903\n",
      "Epoch 696/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.0604 - val_accuracy: 0.9882\n",
      "Epoch 697/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.0399 - val_accuracy: 0.9913\n",
      "Epoch 698/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0810 - val_accuracy: 0.9831\n",
      "Epoch 699/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0261 - accuracy: 0.9910 - val_loss: 0.0330 - val_accuracy: 0.9913\n",
      "Epoch 700/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0444 - val_accuracy: 0.9892\n",
      "Epoch 701/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0732 - val_accuracy: 0.9897\n",
      "Epoch 702/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0324 - val_accuracy: 0.9928\n",
      "Epoch 703/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0381 - val_accuracy: 0.9928\n",
      "Epoch 704/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0391 - val_accuracy: 0.9913\n",
      "Epoch 705/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0349 - val_accuracy: 0.9923\n",
      "Epoch 706/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0401 - val_accuracy: 0.9897\n",
      "Epoch 707/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0512 - val_accuracy: 0.9872\n",
      "Epoch 708/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0399 - val_accuracy: 0.9903\n",
      "Epoch 709/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0406 - val_accuracy: 0.9918\n",
      "Epoch 710/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0454 - val_accuracy: 0.9913\n",
      "Epoch 711/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0458 - val_accuracy: 0.9913\n",
      "Epoch 712/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0412 - val_accuracy: 0.9897\n",
      "Epoch 713/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0444 - val_accuracy: 0.9913\n",
      "Epoch 714/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 715/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0519 - val_accuracy: 0.9908\n",
      "Epoch 716/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0496 - val_accuracy: 0.9908\n",
      "Epoch 717/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0411 - val_accuracy: 0.9908\n",
      "Epoch 718/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0465 - val_accuracy: 0.9908\n",
      "Epoch 719/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.0581 - val_accuracy: 0.9892\n",
      "Epoch 720/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0463 - val_accuracy: 0.9908\n",
      "Epoch 721/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0530 - val_accuracy: 0.9913\n",
      "Epoch 722/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0521 - val_accuracy: 0.9908\n",
      "Epoch 723/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.0493 - val_accuracy: 0.9913\n",
      "Epoch 724/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0637 - val_accuracy: 0.9877\n",
      "Epoch 725/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0476 - val_accuracy: 0.9918\n",
      "Epoch 726/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0728 - val_accuracy: 0.9872\n",
      "Epoch 727/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0400 - val_accuracy: 0.9928\n",
      "Epoch 728/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0385 - val_accuracy: 0.9897\n",
      "Epoch 729/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0467 - val_accuracy: 0.9913\n",
      "Epoch 730/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0396 - val_accuracy: 0.9913\n",
      "Epoch 731/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0391 - val_accuracy: 0.9923\n",
      "Epoch 732/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 733/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0518 - val_accuracy: 0.9918\n",
      "Epoch 734/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0427 - val_accuracy: 0.9908\n",
      "Epoch 735/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0722 - val_accuracy: 0.9867\n",
      "Epoch 736/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0525 - val_accuracy: 0.9913\n",
      "Epoch 737/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0501 - val_accuracy: 0.9903\n",
      "Epoch 738/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0515 - val_accuracy: 0.9892\n",
      "Epoch 739/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0435 - val_accuracy: 0.9897\n",
      "Epoch 740/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0401 - val_accuracy: 0.9913\n",
      "Epoch 741/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0495 - val_accuracy: 0.9903\n",
      "Epoch 742/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0870 - val_accuracy: 0.9826\n",
      "Epoch 743/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0512 - val_accuracy: 0.9892\n",
      "Epoch 744/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0792 - val_accuracy: 0.9856\n",
      "Epoch 745/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0543 - val_accuracy: 0.9908\n",
      "Epoch 746/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0806 - val_accuracy: 0.9795\n",
      "Epoch 747/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.0602 - val_accuracy: 0.9851\n",
      "Epoch 748/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0556 - val_accuracy: 0.9892\n",
      "Epoch 749/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0476 - val_accuracy: 0.9872\n",
      "Epoch 750/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0652 - val_accuracy: 0.9882\n",
      "Epoch 751/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0567 - val_accuracy: 0.9908\n",
      "Epoch 752/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0718 - val_accuracy: 0.9856\n",
      "Epoch 753/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "Epoch 754/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0484 - val_accuracy: 0.9867\n",
      "Epoch 755/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0630 - val_accuracy: 0.9867\n",
      "Epoch 756/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
      "Epoch 757/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0520 - val_accuracy: 0.9903\n",
      "Epoch 758/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0619 - val_accuracy: 0.9908\n",
      "Epoch 759/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.0454 - val_accuracy: 0.9913\n",
      "Epoch 760/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.0545 - val_accuracy: 0.9897\n",
      "Epoch 761/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0717 - val_accuracy: 0.9887\n",
      "Epoch 762/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0661 - val_accuracy: 0.9877\n",
      "Epoch 763/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0573 - val_accuracy: 0.9897\n",
      "Epoch 764/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0714 - val_accuracy: 0.9887\n",
      "Epoch 765/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0565 - val_accuracy: 0.9887\n",
      "Epoch 766/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0522 - val_accuracy: 0.9897\n",
      "Epoch 767/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0593 - val_accuracy: 0.9897\n",
      "Epoch 768/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0685 - val_accuracy: 0.9897\n",
      "Epoch 769/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0611 - val_accuracy: 0.9897\n",
      "Epoch 770/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0861 - val_accuracy: 0.9851\n",
      "Epoch 771/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0503 - val_accuracy: 0.9908\n",
      "Epoch 772/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0161 - accuracy: 0.9932 - val_loss: 0.0618 - val_accuracy: 0.9826\n",
      "Epoch 773/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0427 - val_accuracy: 0.9903\n",
      "Epoch 774/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0486 - val_accuracy: 0.9897\n",
      "Epoch 775/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0474 - val_accuracy: 0.9908\n",
      "Epoch 776/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0612 - val_accuracy: 0.9887\n",
      "Epoch 777/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0664 - val_accuracy: 0.9897\n",
      "Epoch 778/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0548 - val_accuracy: 0.9887\n",
      "Epoch 779/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0809 - val_accuracy: 0.9882\n",
      "Epoch 780/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0741 - val_accuracy: 0.9882\n",
      "Epoch 781/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0533 - val_accuracy: 0.9903\n",
      "Epoch 782/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0559 - val_accuracy: 0.9892\n",
      "Epoch 783/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0463 - val_accuracy: 0.9897\n",
      "Epoch 784/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0591 - val_accuracy: 0.9892\n",
      "Epoch 785/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0645 - val_accuracy: 0.9903\n",
      "Epoch 786/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0689 - val_accuracy: 0.9892\n",
      "Epoch 787/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0535 - val_accuracy: 0.9918\n",
      "Epoch 788/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9872\n",
      "Epoch 789/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0632 - val_accuracy: 0.9908\n",
      "Epoch 790/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0513 - val_accuracy: 0.9887\n",
      "Epoch 791/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0480 - val_accuracy: 0.9892\n",
      "Epoch 792/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0525 - val_accuracy: 0.9908\n",
      "Epoch 793/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0515 - val_accuracy: 0.9892\n",
      "Epoch 794/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0774 - val_accuracy: 0.9908\n",
      "Epoch 795/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0496 - val_accuracy: 0.9903\n",
      "Epoch 796/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0536 - val_accuracy: 0.9908\n",
      "Epoch 797/3000\n",
      "4547/4547 [==============================] - 0s 39us/sample - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0555 - val_accuracy: 0.9892\n",
      "Epoch 798/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0738 - val_accuracy: 0.9872\n",
      "Epoch 799/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0567 - val_accuracy: 0.9897\n",
      "Epoch 800/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0720 - val_accuracy: 0.9892\n",
      "Epoch 801/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0516 - val_accuracy: 0.9913\n",
      "Epoch 802/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0559 - val_accuracy: 0.9892\n",
      "Epoch 803/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.0445 - val_accuracy: 0.9897\n",
      "Epoch 804/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0558 - val_accuracy: 0.9887\n",
      "Epoch 805/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0537 - val_accuracy: 0.9892\n",
      "Epoch 806/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0617 - val_accuracy: 0.9887\n",
      "Epoch 807/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.0772 - val_accuracy: 0.9877\n",
      "Epoch 808/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.0661 - val_accuracy: 0.9897\n",
      "Epoch 809/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0682 - val_accuracy: 0.9897\n",
      "Epoch 810/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0596 - val_accuracy: 0.9897\n",
      "Epoch 811/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0604 - val_accuracy: 0.9897\n",
      "Epoch 812/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0658 - val_accuracy: 0.9882\n",
      "Epoch 813/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0628 - val_accuracy: 0.9908\n",
      "Epoch 814/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0488 - val_accuracy: 0.9913\n",
      "Epoch 815/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0459 - val_accuracy: 0.9908\n",
      "Epoch 816/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0569 - val_accuracy: 0.9892\n",
      "Epoch 817/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0492 - val_accuracy: 0.9903\n",
      "Epoch 818/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.99 - 0s 27us/sample - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0782 - val_accuracy: 0.9872\n",
      "Epoch 819/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0473 - val_accuracy: 0.9923\n",
      "Epoch 820/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0529 - val_accuracy: 0.9913\n",
      "Epoch 821/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0479 - val_accuracy: 0.9913\n",
      "Epoch 822/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0423 - val_accuracy: 0.9913\n",
      "Epoch 823/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0483 - val_accuracy: 0.9913\n",
      "Epoch 824/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0443 - val_accuracy: 0.9903\n",
      "Epoch 825/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0457 - val_accuracy: 0.9892\n",
      "Epoch 826/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0727 - val_accuracy: 0.9887\n",
      "Epoch 827/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0544 - val_accuracy: 0.9882\n",
      "Epoch 828/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0739 - val_accuracy: 0.9887\n",
      "Epoch 829/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.0544 - val_accuracy: 0.9903\n",
      "Epoch 830/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0732 - val_accuracy: 0.9872\n",
      "Epoch 831/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0586 - val_accuracy: 0.9887\n",
      "Epoch 832/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0604 - val_accuracy: 0.9887\n",
      "Epoch 833/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0888 - val_accuracy: 0.9851\n",
      "Epoch 834/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0554 - val_accuracy: 0.9892\n",
      "Epoch 835/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0562 - val_accuracy: 0.9897\n",
      "Epoch 836/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.0678 - val_accuracy: 0.9892\n",
      "Epoch 837/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0695 - val_accuracy: 0.9897\n",
      "Epoch 838/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0607 - val_accuracy: 0.9903\n",
      "Epoch 839/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0519 - val_accuracy: 0.9903\n",
      "Epoch 840/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0543 - val_accuracy: 0.9897\n",
      "Epoch 841/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0741 - val_accuracy: 0.9821\n",
      "Epoch 842/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0604 - val_accuracy: 0.9908\n",
      "Epoch 843/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0594 - val_accuracy: 0.9903\n",
      "Epoch 844/3000\n",
      "4547/4547 [==============================] - 0s 39us/sample - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.0514 - val_accuracy: 0.9903\n",
      "Epoch 845/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0628 - val_accuracy: 0.9908\n",
      "Epoch 846/3000\n",
      "4547/4547 [==============================] - 0s 41us/sample - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9872\n",
      "Epoch 847/3000\n",
      "4547/4547 [==============================] - 0s 46us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0610 - val_accuracy: 0.9903\n",
      "Epoch 848/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0537 - val_accuracy: 0.9903\n",
      "Epoch 849/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0624 - val_accuracy: 0.9856\n",
      "Epoch 850/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0490 - val_accuracy: 0.9908\n",
      "Epoch 851/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0614 - val_accuracy: 0.9877\n",
      "Epoch 852/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0581 - val_accuracy: 0.9882\n",
      "Epoch 853/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0793 - val_accuracy: 0.9887\n",
      "Epoch 854/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0612 - val_accuracy: 0.9897\n",
      "Epoch 855/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0542 - val_accuracy: 0.9892\n",
      "Epoch 856/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0826 - val_accuracy: 0.9841\n",
      "Epoch 857/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0755 - val_accuracy: 0.9877\n",
      "Epoch 858/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0439 - val_accuracy: 0.9908\n",
      "Epoch 859/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0605 - val_accuracy: 0.9908\n",
      "Epoch 860/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0583 - val_accuracy: 0.9887\n",
      "Epoch 861/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0579 - val_accuracy: 0.9903\n",
      "Epoch 862/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0565 - val_accuracy: 0.9903\n",
      "Epoch 863/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0476 - val_accuracy: 0.9897\n",
      "Epoch 864/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0849 - val_accuracy: 0.9856\n",
      "Epoch 865/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0617 - val_accuracy: 0.9897\n",
      "Epoch 866/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.0493 - val_accuracy: 0.9908\n",
      "Epoch 867/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0652 - val_accuracy: 0.9903\n",
      "Epoch 868/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0583 - val_accuracy: 0.9882\n",
      "Epoch 869/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0510 - val_accuracy: 0.9892\n",
      "Epoch 870/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0592 - val_accuracy: 0.9862\n",
      "Epoch 871/3000\n",
      "4547/4547 [==============================] - 0s 43us/sample - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0587 - val_accuracy: 0.9908\n",
      "Epoch 872/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0704 - val_accuracy: 0.9841\n",
      "Epoch 873/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0557 - val_accuracy: 0.9908\n",
      "Epoch 874/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0597 - val_accuracy: 0.9897\n",
      "Epoch 875/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0540 - val_accuracy: 0.9903\n",
      "Epoch 876/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0504 - val_accuracy: 0.9908\n",
      "Epoch 877/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0519 - val_accuracy: 0.9913\n",
      "Epoch 878/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0519 - val_accuracy: 0.9913\n",
      "Epoch 879/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0714 - val_accuracy: 0.9887\n",
      "Epoch 880/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0743 - val_accuracy: 0.9867\n",
      "Epoch 881/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0496 - val_accuracy: 0.9908\n",
      "Epoch 882/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0529 - val_accuracy: 0.9913\n",
      "Epoch 883/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0497 - val_accuracy: 0.9913\n",
      "Epoch 884/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0607 - val_accuracy: 0.9903\n",
      "Epoch 885/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0550 - val_accuracy: 0.9892\n",
      "Epoch 886/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0588 - val_accuracy: 0.9892\n",
      "Epoch 887/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.0796 - val_accuracy: 0.9882\n",
      "Epoch 888/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0460 - val_accuracy: 0.9897\n",
      "Epoch 889/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0478 - val_accuracy: 0.9913\n",
      "Epoch 890/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0692 - val_accuracy: 0.9897\n",
      "Epoch 891/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0554 - val_accuracy: 0.9913\n",
      "Epoch 892/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0432 - val_accuracy: 0.9903\n",
      "Epoch 893/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0529 - val_accuracy: 0.9908\n",
      "Epoch 894/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0431 - val_accuracy: 0.9928\n",
      "Epoch 895/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0541 - val_accuracy: 0.9897\n",
      "Epoch 896/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0472 - val_accuracy: 0.9923\n",
      "Epoch 897/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0667 - val_accuracy: 0.9877\n",
      "Epoch 898/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0464 - val_accuracy: 0.9908\n",
      "Epoch 899/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.0510 - val_accuracy: 0.9903\n",
      "Epoch 900/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0510 - val_accuracy: 0.9908\n",
      "Epoch 901/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0750 - val_accuracy: 0.9862\n",
      "Epoch 902/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0447 - val_accuracy: 0.9918\n",
      "Epoch 903/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0469 - val_accuracy: 0.9918\n",
      "Epoch 904/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0598 - val_accuracy: 0.9903\n",
      "Epoch 905/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0627 - val_accuracy: 0.9887\n",
      "Epoch 906/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.0567 - val_accuracy: 0.9877\n",
      "Epoch 907/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0732 - val_accuracy: 0.9872\n",
      "Epoch 908/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0581 - val_accuracy: 0.9908\n",
      "Epoch 909/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0626 - val_accuracy: 0.9908\n",
      "Epoch 910/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0557 - val_accuracy: 0.9913\n",
      "Epoch 911/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0582 - val_accuracy: 0.9908\n",
      "Epoch 912/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0462 - val_accuracy: 0.9908\n",
      "Epoch 913/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0529 - val_accuracy: 0.9887\n",
      "Epoch 914/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0730 - val_accuracy: 0.9897\n",
      "Epoch 915/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0458 - val_accuracy: 0.9923\n",
      "Epoch 916/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0525 - val_accuracy: 0.9908\n",
      "Epoch 917/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0533 - val_accuracy: 0.9856\n",
      "Epoch 918/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0467 - val_accuracy: 0.9918\n",
      "Epoch 919/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0465 - val_accuracy: 0.9918\n",
      "Epoch 920/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0487 - val_accuracy: 0.9913\n",
      "Epoch 921/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0463 - val_accuracy: 0.9908\n",
      "Epoch 922/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0672 - val_accuracy: 0.9877\n",
      "Epoch 923/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9941 - val_loss: 0.0470 - val_accuracy: 0.9903\n",
      "Epoch 924/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0566 - val_accuracy: 0.9892\n",
      "Epoch 925/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0748 - val_accuracy: 0.9862\n",
      "Epoch 926/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0999 - val_accuracy: 0.9800\n",
      "Epoch 927/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0485 - val_accuracy: 0.9903\n",
      "Epoch 928/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0555 - val_accuracy: 0.9903\n",
      "Epoch 929/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.0539 - val_accuracy: 0.9903\n",
      "Epoch 930/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0501 - val_accuracy: 0.9908\n",
      "Epoch 931/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0610 - val_accuracy: 0.9887\n",
      "Epoch 932/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0576 - val_accuracy: 0.9908\n",
      "Epoch 933/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9892\n",
      "Epoch 934/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0658 - val_accuracy: 0.9882\n",
      "Epoch 935/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0569 - val_accuracy: 0.9908\n",
      "Epoch 936/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0442 - val_accuracy: 0.9913\n",
      "Epoch 937/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0452 - val_accuracy: 0.9918\n",
      "Epoch 938/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0613 - val_accuracy: 0.9862\n",
      "Epoch 939/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0577 - val_accuracy: 0.9887\n",
      "Epoch 940/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0475 - val_accuracy: 0.9913\n",
      "Epoch 941/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0473 - val_accuracy: 0.9908\n",
      "Epoch 942/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0696 - val_accuracy: 0.9887\n",
      "Epoch 943/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0479 - val_accuracy: 0.9913\n",
      "Epoch 944/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0564 - val_accuracy: 0.9918\n",
      "Epoch 945/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0410 - val_accuracy: 0.9913\n",
      "Epoch 946/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.0637 - val_accuracy: 0.9872\n",
      "Epoch 947/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0489 - val_accuracy: 0.9892\n",
      "Epoch 948/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0412 - val_accuracy: 0.9933\n",
      "Epoch 949/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0729 - val_accuracy: 0.9851\n",
      "Epoch 950/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0569 - val_accuracy: 0.9897\n",
      "Epoch 951/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0448 - val_accuracy: 0.9913\n",
      "Epoch 952/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0469 - val_accuracy: 0.9903\n",
      "Epoch 953/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0470 - val_accuracy: 0.9908\n",
      "Epoch 954/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0432 - val_accuracy: 0.9903\n",
      "Epoch 955/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0562 - val_accuracy: 0.9882\n",
      "Epoch 956/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0543 - val_accuracy: 0.9913\n",
      "Epoch 957/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0451 - val_accuracy: 0.9908\n",
      "Epoch 958/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.0581 - val_accuracy: 0.9897\n",
      "Epoch 959/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0508 - val_accuracy: 0.9918\n",
      "Epoch 960/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0548 - val_accuracy: 0.9918\n",
      "Epoch 961/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0485 - val_accuracy: 0.9918\n",
      "Epoch 962/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0670 - val_accuracy: 0.9877\n",
      "Epoch 963/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0484 - val_accuracy: 0.9923\n",
      "Epoch 964/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0706 - val_accuracy: 0.9897\n",
      "Epoch 965/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0151 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9892\n",
      "Epoch 966/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0411 - val_accuracy: 0.9923\n",
      "Epoch 967/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0579 - val_accuracy: 0.9903\n",
      "Epoch 968/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0654 - val_accuracy: 0.9892\n",
      "Epoch 969/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0736 - val_accuracy: 0.9841\n",
      "Epoch 970/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0482 - val_accuracy: 0.9908\n",
      "Epoch 971/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0703 - val_accuracy: 0.9872\n",
      "Epoch 972/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0504 - val_accuracy: 0.9903\n",
      "Epoch 973/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0696 - val_accuracy: 0.9877\n",
      "Epoch 974/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0578 - val_accuracy: 0.9897\n",
      "Epoch 975/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0532 - val_accuracy: 0.9908\n",
      "Epoch 976/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0624 - val_accuracy: 0.9903\n",
      "Epoch 977/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0532 - val_accuracy: 0.9908\n",
      "Epoch 978/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0676 - val_accuracy: 0.9882\n",
      "Epoch 979/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.0597 - val_accuracy: 0.9887\n",
      "Epoch 980/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0681 - val_accuracy: 0.9872\n",
      "Epoch 981/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0135 - accuracy: 0.9967 - val_loss: 0.0623 - val_accuracy: 0.9903\n",
      "Epoch 982/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0677 - val_accuracy: 0.9897\n",
      "Epoch 983/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.0875 - val_accuracy: 0.9846\n",
      "Epoch 984/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0378 - accuracy: 0.9901 - val_loss: 0.0663 - val_accuracy: 0.9897\n",
      "Epoch 985/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0220 - accuracy: 0.9943 - val_loss: 0.0530 - val_accuracy: 0.9908\n",
      "Epoch 986/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0653 - val_accuracy: 0.9892\n",
      "Epoch 987/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.0483 - val_accuracy: 0.9882\n",
      "Epoch 988/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0410 - val_accuracy: 0.9923\n",
      "Epoch 989/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0409 - val_accuracy: 0.9928\n",
      "Epoch 990/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0597 - val_accuracy: 0.9867\n",
      "Epoch 991/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0525 - val_accuracy: 0.9892\n",
      "Epoch 992/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0464 - val_accuracy: 0.9897\n",
      "Epoch 993/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0502 - val_accuracy: 0.9903\n",
      "Epoch 994/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0484 - val_accuracy: 0.9897\n",
      "Epoch 995/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0472 - val_accuracy: 0.9897\n",
      "Epoch 996/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0516 - val_accuracy: 0.9908\n",
      "Epoch 997/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0470 - val_accuracy: 0.9913\n",
      "Epoch 998/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0506 - val_accuracy: 0.9908\n",
      "Epoch 999/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0801 - val_accuracy: 0.9851\n",
      "Epoch 1000/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.0557 - val_accuracy: 0.9908\n",
      "Epoch 1001/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0561 - val_accuracy: 0.9892\n",
      "Epoch 1002/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.0818 - val_accuracy: 0.9841\n",
      "Epoch 1003/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0494 - val_accuracy: 0.9908\n",
      "Epoch 1004/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0443 - val_accuracy: 0.9897\n",
      "Epoch 1005/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0664 - val_accuracy: 0.9872\n",
      "Epoch 1006/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0532 - val_accuracy: 0.9882\n",
      "Epoch 1007/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0579 - val_accuracy: 0.9826\n",
      "Epoch 1008/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0725 - val_accuracy: 0.9882\n",
      "Epoch 1009/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0538 - val_accuracy: 0.9913\n",
      "Epoch 1010/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0668 - val_accuracy: 0.9892\n",
      "Epoch 1011/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0532 - val_accuracy: 0.9903\n",
      "Epoch 1012/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.0693 - val_accuracy: 0.9882\n",
      "Epoch 1013/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.0639 - val_accuracy: 0.9903\n",
      "Epoch 1014/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0518 - val_accuracy: 0.9897\n",
      "Epoch 1015/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0468 - val_accuracy: 0.9908\n",
      "Epoch 1016/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0478 - val_accuracy: 0.9897\n",
      "Epoch 1017/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0598 - val_accuracy: 0.9908\n",
      "Epoch 1018/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0493 - val_accuracy: 0.9918\n",
      "Epoch 1019/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0615 - val_accuracy: 0.9903\n",
      "Epoch 1020/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0464 - val_accuracy: 0.9908\n",
      "Epoch 1021/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0704 - val_accuracy: 0.9882\n",
      "Epoch 1022/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0534 - val_accuracy: 0.9918\n",
      "Epoch 1023/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0662 - val_accuracy: 0.9877\n",
      "Epoch 1024/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0645 - val_accuracy: 0.9892\n",
      "Epoch 1025/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0615 - val_accuracy: 0.9892\n",
      "Epoch 1026/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0507 - val_accuracy: 0.9882\n",
      "Epoch 1027/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0491 - val_accuracy: 0.9908\n",
      "Epoch 1028/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0693 - val_accuracy: 0.9872\n",
      "Epoch 1029/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.9938 - val_loss: 0.0789 - val_accuracy: 0.9846\n",
      "Epoch 1030/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.0536 - val_accuracy: 0.9897\n",
      "Epoch 1031/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0487 - val_accuracy: 0.9908\n",
      "Epoch 1032/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0680 - val_accuracy: 0.9887\n",
      "Epoch 1033/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0634 - val_accuracy: 0.9877\n",
      "Epoch 1034/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0519 - val_accuracy: 0.9908\n",
      "Epoch 1035/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0475 - val_accuracy: 0.9918\n",
      "Epoch 1036/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0623 - val_accuracy: 0.9887\n",
      "Epoch 1037/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0574 - val_accuracy: 0.9908\n",
      "Epoch 1038/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0860 - val_accuracy: 0.9851\n",
      "Epoch 1039/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0552 - val_accuracy: 0.9892\n",
      "Epoch 1040/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0600 - val_accuracy: 0.9862\n",
      "Epoch 1041/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0622 - val_accuracy: 0.9903\n",
      "Epoch 1042/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0705 - val_accuracy: 0.9872\n",
      "Epoch 1043/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0537 - val_accuracy: 0.9913\n",
      "Epoch 1044/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0541 - val_accuracy: 0.9913\n",
      "Epoch 1045/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0453 - val_accuracy: 0.9918\n",
      "Epoch 1046/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0540 - val_accuracy: 0.9913\n",
      "Epoch 1047/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0483 - val_accuracy: 0.9877\n",
      "Epoch 1048/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0584 - val_accuracy: 0.9862\n",
      "Epoch 1049/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.1041 - val_accuracy: 0.9841\n",
      "Epoch 1050/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0440 - val_accuracy: 0.9918\n",
      "Epoch 1051/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0600 - val_accuracy: 0.9908\n",
      "Epoch 1052/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0499 - val_accuracy: 0.9908\n",
      "Epoch 1053/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0642 - val_accuracy: 0.9867\n",
      "Epoch 1054/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0444 - val_accuracy: 0.9923\n",
      "Epoch 1055/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.0590 - val_accuracy: 0.9882\n",
      "Epoch 1056/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0523 - val_accuracy: 0.9918\n",
      "Epoch 1057/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.99 - 0s 27us/sample - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0588 - val_accuracy: 0.9913\n",
      "Epoch 1058/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0306 - accuracy: 0.9892 - val_loss: 0.0695 - val_accuracy: 0.9826\n",
      "Epoch 1059/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0507 - val_accuracy: 0.9882\n",
      "Epoch 1060/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.0537 - val_accuracy: 0.9908\n",
      "Epoch 1061/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0509 - val_accuracy: 0.9918\n",
      "Epoch 1062/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0532 - val_accuracy: 0.9918\n",
      "Epoch 1063/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.0532 - val_accuracy: 0.9908\n",
      "Epoch 1064/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0620 - val_accuracy: 0.9892\n",
      "Epoch 1065/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0475 - val_accuracy: 0.9923\n",
      "Epoch 1066/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0487 - val_accuracy: 0.9913\n",
      "Epoch 1067/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.0502 - val_accuracy: 0.9918\n",
      "Epoch 1068/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0504 - val_accuracy: 0.9913\n",
      "Epoch 1069/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.0516 - val_accuracy: 0.9918\n",
      "Epoch 1070/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0552 - val_accuracy: 0.9897\n",
      "Epoch 1071/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0418 - val_accuracy: 0.9928\n",
      "Epoch 1072/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0455 - val_accuracy: 0.9928\n",
      "Epoch 1073/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0518 - val_accuracy: 0.9913\n",
      "Epoch 1074/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0520 - val_accuracy: 0.9913\n",
      "Epoch 1075/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0647 - val_accuracy: 0.9882\n",
      "Epoch 1076/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0523 - val_accuracy: 0.9903\n",
      "Epoch 1077/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0780 - val_accuracy: 0.9872\n",
      "Epoch 1078/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0603 - val_accuracy: 0.9872\n",
      "Epoch 1079/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0469 - val_accuracy: 0.9908\n",
      "Epoch 1080/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0316 - accuracy: 0.9914 - val_loss: 0.0766 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1081/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.0405 - val_accuracy: 0.9918\n",
      "Epoch 1082/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0496 - val_accuracy: 0.9918\n",
      "Epoch 1083/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0613 - val_accuracy: 0.9882\n",
      "Epoch 1084/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0690 - val_accuracy: 0.9877\n",
      "Epoch 1085/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0472 - val_accuracy: 0.9928\n",
      "Epoch 1086/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0579 - val_accuracy: 0.9892\n",
      "Epoch 1087/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0560 - val_accuracy: 0.9897\n",
      "Epoch 1088/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0656 - val_accuracy: 0.9897\n",
      "Epoch 1089/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0503 - val_accuracy: 0.9913\n",
      "Epoch 1090/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0511 - val_accuracy: 0.9908\n",
      "Epoch 1091/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0565 - val_accuracy: 0.9903\n",
      "Epoch 1092/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0534 - val_accuracy: 0.9903\n",
      "Epoch 1093/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0580 - val_accuracy: 0.9887\n",
      "Epoch 1094/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0552 - val_accuracy: 0.9908\n",
      "Epoch 1095/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0484 - val_accuracy: 0.9928\n",
      "Epoch 1096/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0532 - val_accuracy: 0.9923\n",
      "Epoch 1097/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0437 - val_accuracy: 0.9923\n",
      "Epoch 1098/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0445 - val_accuracy: 0.9923\n",
      "Epoch 1099/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0542 - val_accuracy: 0.9897\n",
      "Epoch 1100/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0498 - val_accuracy: 0.9913\n",
      "Epoch 1101/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0470 - val_accuracy: 0.9923\n",
      "Epoch 1102/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0503 - val_accuracy: 0.9908\n",
      "Epoch 1103/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0556 - val_accuracy: 0.9908\n",
      "Epoch 1104/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0955 - val_accuracy: 0.9831\n",
      "Epoch 1105/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9897\n",
      "Epoch 1106/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0486 - val_accuracy: 0.9913\n",
      "Epoch 1107/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0474 - val_accuracy: 0.9918\n",
      "Epoch 1108/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0517 - val_accuracy: 0.9913\n",
      "Epoch 1109/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0492 - val_accuracy: 0.9923\n",
      "Epoch 1110/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0503 - val_accuracy: 0.9913\n",
      "Epoch 1111/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0526 - val_accuracy: 0.9908\n",
      "Epoch 1112/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0503 - val_accuracy: 0.9923\n",
      "Epoch 1113/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0552 - val_accuracy: 0.9903\n",
      "Epoch 1114/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0557 - val_accuracy: 0.9908\n",
      "Epoch 1115/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0475 - val_accuracy: 0.9933\n",
      "Epoch 1116/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0468 - val_accuracy: 0.9923\n",
      "Epoch 1117/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0540 - val_accuracy: 0.9908\n",
      "Epoch 1118/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0598 - val_accuracy: 0.9887\n",
      "Epoch 1119/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0562 - val_accuracy: 0.9892\n",
      "Epoch 1120/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0715 - val_accuracy: 0.9841\n",
      "Epoch 1121/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0145 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9918\n",
      "Epoch 1122/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0502 - val_accuracy: 0.9928\n",
      "Epoch 1123/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0554 - val_accuracy: 0.9913\n",
      "Epoch 1124/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0669 - val_accuracy: 0.9877\n",
      "Epoch 1125/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0703 - val_accuracy: 0.9872\n",
      "Epoch 1126/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0449 - val_accuracy: 0.9928\n",
      "Epoch 1127/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0552 - val_accuracy: 0.9913\n",
      "Epoch 1128/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0410 - val_accuracy: 0.9923\n",
      "Epoch 1129/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0543 - val_accuracy: 0.9887\n",
      "Epoch 1130/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0440 - val_accuracy: 0.9933\n",
      "Epoch 1131/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0537 - val_accuracy: 0.9903\n",
      "Epoch 1132/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0455 - val_accuracy: 0.9918\n",
      "Epoch 1133/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0535 - val_accuracy: 0.9918\n",
      "Epoch 1134/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0591 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1135/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0504 - val_accuracy: 0.9923\n",
      "Epoch 1136/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0604 - val_accuracy: 0.9882\n",
      "Epoch 1137/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0519 - val_accuracy: 0.9903\n",
      "Epoch 1138/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0534 - val_accuracy: 0.9918\n",
      "Epoch 1139/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1610 - val_accuracy: 0.9774\n",
      "Epoch 1140/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 1141/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0425 - val_accuracy: 0.9923\n",
      "Epoch 1142/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0608 - val_accuracy: 0.9887\n",
      "Epoch 1143/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0486 - val_accuracy: 0.9908\n",
      "Epoch 1144/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0563 - val_accuracy: 0.9892\n",
      "Epoch 1145/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0520 - val_accuracy: 0.9908\n",
      "Epoch 1146/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0567 - val_accuracy: 0.9897\n",
      "Epoch 1147/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0126 - accuracy: 0.9952 - val_loss: 0.0529 - val_accuracy: 0.9908\n",
      "Epoch 1148/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0507 - val_accuracy: 0.9908\n",
      "Epoch 1149/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0459 - val_accuracy: 0.9913\n",
      "Epoch 1150/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0507 - val_accuracy: 0.9918\n",
      "Epoch 1151/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0571 - val_accuracy: 0.9913\n",
      "Epoch 1152/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0636 - val_accuracy: 0.9892\n",
      "Epoch 1153/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0488 - val_accuracy: 0.9918\n",
      "Epoch 1154/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0606 - val_accuracy: 0.9882\n",
      "Epoch 1155/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0559 - val_accuracy: 0.9913\n",
      "Epoch 1156/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0582 - val_accuracy: 0.9897\n",
      "Epoch 1157/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9887\n",
      "Epoch 1158/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0582 - val_accuracy: 0.9897\n",
      "Epoch 1159/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0588 - val_accuracy: 0.9903\n",
      "Epoch 1160/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0558 - val_accuracy: 0.9903\n",
      "Epoch 1161/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0631 - val_accuracy: 0.9892\n",
      "Epoch 1162/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0495 - val_accuracy: 0.9928\n",
      "Epoch 1163/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0899 - val_accuracy: 0.9826\n",
      "Epoch 1164/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0479 - val_accuracy: 0.9928\n",
      "Epoch 1165/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0504 - val_accuracy: 0.9918\n",
      "Epoch 1166/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.0654 - val_accuracy: 0.9887\n",
      "Epoch 1167/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0559 - val_accuracy: 0.9918\n",
      "Epoch 1168/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0549 - val_accuracy: 0.9903\n",
      "Epoch 1169/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0526 - val_accuracy: 0.9913\n",
      "Epoch 1170/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0520 - val_accuracy: 0.9897\n",
      "Epoch 1171/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0538 - val_accuracy: 0.9908\n",
      "Epoch 1172/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0586 - val_accuracy: 0.9923\n",
      "Epoch 1173/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0595 - val_accuracy: 0.9913\n",
      "Epoch 1174/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0601 - val_accuracy: 0.9877\n",
      "Epoch 1175/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0648 - val_accuracy: 0.9913\n",
      "Epoch 1176/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0580 - val_accuracy: 0.9918\n",
      "Epoch 1177/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0503 - val_accuracy: 0.9923\n",
      "Epoch 1178/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0499 - val_accuracy: 0.9928\n",
      "Epoch 1179/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0487 - val_accuracy: 0.9928\n",
      "Epoch 1180/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0588 - val_accuracy: 0.9892\n",
      "Epoch 1181/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0519 - val_accuracy: 0.9923\n",
      "Epoch 1182/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0573 - val_accuracy: 0.9908\n",
      "Epoch 1183/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0754 - val_accuracy: 0.9851\n",
      "Epoch 1184/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0814 - val_accuracy: 0.9856\n",
      "Epoch 1185/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0169 - accuracy: 0.9934 - val_loss: 0.0566 - val_accuracy: 0.9897\n",
      "Epoch 1186/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0547 - val_accuracy: 0.9903\n",
      "Epoch 1187/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.0497 - val_accuracy: 0.9908\n",
      "Epoch 1188/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0507 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1189/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0732 - val_accuracy: 0.9877\n",
      "Epoch 1190/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0656 - val_accuracy: 0.9897\n",
      "Epoch 1191/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0712 - val_accuracy: 0.9897\n",
      "Epoch 1192/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0634 - val_accuracy: 0.9908\n",
      "Epoch 1193/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0565 - val_accuracy: 0.9913\n",
      "Epoch 1194/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0511 - val_accuracy: 0.9903\n",
      "Epoch 1195/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0593 - val_accuracy: 0.9897\n",
      "Epoch 1196/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0559 - val_accuracy: 0.9903\n",
      "Epoch 1197/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0538 - val_accuracy: 0.9908\n",
      "Epoch 1198/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0700 - val_accuracy: 0.9856\n",
      "Epoch 1199/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0574 - val_accuracy: 0.9908\n",
      "Epoch 1200/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0573 - val_accuracy: 0.9892\n",
      "Epoch 1201/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0648 - val_accuracy: 0.9872\n",
      "Epoch 1202/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
      "Epoch 1203/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0565 - val_accuracy: 0.9908\n",
      "Epoch 1204/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0545 - val_accuracy: 0.9913\n",
      "Epoch 1205/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0610 - val_accuracy: 0.9887\n",
      "Epoch 1206/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0647 - val_accuracy: 0.9882\n",
      "Epoch 1207/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9867\n",
      "Epoch 1208/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0730 - val_accuracy: 0.9882\n",
      "Epoch 1209/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0612 - val_accuracy: 0.9913\n",
      "Epoch 1210/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0555 - val_accuracy: 0.9908\n",
      "Epoch 1211/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0750 - val_accuracy: 0.9882\n",
      "Epoch 1212/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0705 - val_accuracy: 0.9882\n",
      "Epoch 1213/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0624 - val_accuracy: 0.9892\n",
      "Epoch 1214/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0560 - val_accuracy: 0.9887\n",
      "Epoch 1215/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0537 - val_accuracy: 0.9908\n",
      "Epoch 1216/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0562 - val_accuracy: 0.9913\n",
      "Epoch 1217/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9892\n",
      "Epoch 1218/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0658 - val_accuracy: 0.9877\n",
      "Epoch 1219/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0556 - val_accuracy: 0.9928\n",
      "Epoch 1220/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0577 - val_accuracy: 0.9903\n",
      "Epoch 1221/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0683 - val_accuracy: 0.9887\n",
      "Epoch 1222/3000\n",
      "4547/4547 [==============================] - 0s 40us/sample - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0652 - val_accuracy: 0.9882\n",
      "Epoch 1223/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0479 - val_accuracy: 0.9923\n",
      "Epoch 1224/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0565 - val_accuracy: 0.9918\n",
      "Epoch 1225/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0467 - val_accuracy: 0.9923\n",
      "Epoch 1226/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0545 - val_accuracy: 0.9867\n",
      "Epoch 1227/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0575 - val_accuracy: 0.9903\n",
      "Epoch 1228/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0608 - val_accuracy: 0.9892\n",
      "Epoch 1229/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0580 - val_accuracy: 0.9913\n",
      "Epoch 1230/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0520 - val_accuracy: 0.9913\n",
      "Epoch 1231/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0565 - val_accuracy: 0.9913\n",
      "Epoch 1232/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0555 - val_accuracy: 0.9908\n",
      "Epoch 1233/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0511 - val_accuracy: 0.9918\n",
      "Epoch 1234/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0561 - val_accuracy: 0.9903\n",
      "Epoch 1235/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0645 - val_accuracy: 0.9846\n",
      "Epoch 1236/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0536 - val_accuracy: 0.9913\n",
      "Epoch 1237/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0861 - val_accuracy: 0.9851\n",
      "Epoch 1238/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0709 - val_accuracy: 0.9872\n",
      "Epoch 1239/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0525 - val_accuracy: 0.9913\n",
      "Epoch 1240/3000\n",
      "4547/4547 [==============================] - 0s 41us/sample - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "Epoch 1241/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0555 - val_accuracy: 0.9918\n",
      "Epoch 1242/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0583 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1243/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0563 - val_accuracy: 0.9923\n",
      "Epoch 1244/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0712 - val_accuracy: 0.9862\n",
      "Epoch 1245/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0706 - val_accuracy: 0.9877\n",
      "Epoch 1246/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0676 - val_accuracy: 0.9892\n",
      "Epoch 1247/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0716 - val_accuracy: 0.9882\n",
      "Epoch 1248/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.0644 - val_accuracy: 0.9903\n",
      "Epoch 1249/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0523 - val_accuracy: 0.9903\n",
      "Epoch 1250/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0657 - val_accuracy: 0.9892\n",
      "Epoch 1251/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0591 - val_accuracy: 0.9903\n",
      "Epoch 1252/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0575 - val_accuracy: 0.9913\n",
      "Epoch 1253/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0574 - val_accuracy: 0.9913\n",
      "Epoch 1254/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0582 - val_accuracy: 0.9908\n",
      "Epoch 1255/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0540 - val_accuracy: 0.9913\n",
      "Epoch 1256/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0715 - val_accuracy: 0.9862\n",
      "Epoch 1257/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.0583 - val_accuracy: 0.9918\n",
      "Epoch 1258/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.0681 - val_accuracy: 0.9877\n",
      "Epoch 1259/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.0525 - val_accuracy: 0.9918\n",
      "Epoch 1260/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9960 - val_loss: 0.0557 - val_accuracy: 0.9913\n",
      "Epoch 1261/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0587 - val_accuracy: 0.9918\n",
      "Epoch 1262/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0754 - val_accuracy: 0.9882\n",
      "Epoch 1263/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0610 - val_accuracy: 0.9908\n",
      "Epoch 1264/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0606 - val_accuracy: 0.9913\n",
      "Epoch 1265/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0800 - val_accuracy: 0.9872\n",
      "Epoch 1266/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0798 - val_accuracy: 0.9851\n",
      "Epoch 1267/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0630 - val_accuracy: 0.9908\n",
      "Epoch 1268/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0550 - val_accuracy: 0.9923\n",
      "Epoch 1269/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "Epoch 1270/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0811 - val_accuracy: 0.9841\n",
      "Epoch 1271/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0625 - val_accuracy: 0.9908\n",
      "Epoch 1272/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0607 - val_accuracy: 0.9897\n",
      "Epoch 1273/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0658 - val_accuracy: 0.9887\n",
      "Epoch 1274/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0628 - val_accuracy: 0.9892\n",
      "Epoch 1275/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.0536 - val_accuracy: 0.9918\n",
      "Epoch 1276/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0591 - val_accuracy: 0.9908\n",
      "Epoch 1277/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0527 - val_accuracy: 0.9923\n",
      "Epoch 1278/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0560 - val_accuracy: 0.9882\n",
      "Epoch 1279/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.0649 - val_accuracy: 0.9913\n",
      "Epoch 1280/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0535 - val_accuracy: 0.9918\n",
      "Epoch 1281/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0607 - val_accuracy: 0.9908\n",
      "Epoch 1282/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0592 - val_accuracy: 0.9908\n",
      "Epoch 1283/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0579 - val_accuracy: 0.9908\n",
      "Epoch 1284/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0630 - val_accuracy: 0.9903\n",
      "Epoch 1285/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0545 - val_accuracy: 0.9918\n",
      "Epoch 1286/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0692 - val_accuracy: 0.9892\n",
      "Epoch 1287/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9960 - val_loss: 0.0771 - val_accuracy: 0.9887\n",
      "Epoch 1288/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0768 - val_accuracy: 0.9867\n",
      "Epoch 1289/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0711 - val_accuracy: 0.9892\n",
      "Epoch 1290/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0630 - val_accuracy: 0.9913\n",
      "Epoch 1291/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0931 - val_accuracy: 0.9836\n",
      "Epoch 1292/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0153 - accuracy: 0.9941 - val_loss: 0.0614 - val_accuracy: 0.9882\n",
      "Epoch 1293/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0540 - val_accuracy: 0.9918\n",
      "Epoch 1294/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "Epoch 1295/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0696 - val_accuracy: 0.9897\n",
      "Epoch 1296/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0650 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1297/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0685 - val_accuracy: 0.9897\n",
      "Epoch 1298/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0630 - val_accuracy: 0.9856\n",
      "Epoch 1299/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0113 - accuracy: 0.9952 - val_loss: 0.0575 - val_accuracy: 0.9897\n",
      "Epoch 1300/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0596 - val_accuracy: 0.9913\n",
      "Epoch 1301/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9892\n",
      "Epoch 1302/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0566 - val_accuracy: 0.9908\n",
      "Epoch 1303/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0559 - val_accuracy: 0.9928\n",
      "Epoch 1304/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0573 - val_accuracy: 0.9913\n",
      "Epoch 1305/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0589 - val_accuracy: 0.9918\n",
      "Epoch 1306/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.0916 - val_accuracy: 0.9846\n",
      "Epoch 1307/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0633 - val_accuracy: 0.9897\n",
      "Epoch 1308/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0621 - val_accuracy: 0.9903\n",
      "Epoch 1309/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0803 - val_accuracy: 0.9867\n",
      "Epoch 1310/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.0663 - val_accuracy: 0.9867\n",
      "Epoch 1311/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.0623 - val_accuracy: 0.9913\n",
      "Epoch 1312/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0919 - val_accuracy: 0.9877\n",
      "Epoch 1313/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0626 - val_accuracy: 0.9882\n",
      "Epoch 1314/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0570 - val_accuracy: 0.9882\n",
      "Epoch 1315/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "Epoch 1316/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0674 - val_accuracy: 0.9892\n",
      "Epoch 1317/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0530 - val_accuracy: 0.9928\n",
      "Epoch 1318/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9952 - val_loss: 0.0711 - val_accuracy: 0.9892\n",
      "Epoch 1319/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0870 - val_accuracy: 0.9851\n",
      "Epoch 1320/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0535 - val_accuracy: 0.9903\n",
      "Epoch 1321/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0569 - val_accuracy: 0.9897\n",
      "Epoch 1322/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0589 - val_accuracy: 0.9918\n",
      "Epoch 1323/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0560 - val_accuracy: 0.9908\n",
      "Epoch 1324/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0847 - val_accuracy: 0.9867\n",
      "Epoch 1325/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0576 - val_accuracy: 0.9918\n",
      "Epoch 1326/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0530 - val_accuracy: 0.9918\n",
      "Epoch 1327/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.0597 - val_accuracy: 0.9897\n",
      "Epoch 1328/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0466 - val_accuracy: 0.9918\n",
      "Epoch 1329/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0524 - val_accuracy: 0.9908\n",
      "Epoch 1330/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0609 - val_accuracy: 0.9913\n",
      "Epoch 1331/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0739 - val_accuracy: 0.9887\n",
      "Epoch 1332/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0571 - val_accuracy: 0.9923\n",
      "Epoch 1333/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0564 - val_accuracy: 0.9913\n",
      "Epoch 1334/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0582 - val_accuracy: 0.9928\n",
      "Epoch 1335/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0580 - val_accuracy: 0.9897\n",
      "Epoch 1336/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0533 - val_accuracy: 0.9923\n",
      "Epoch 1337/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9892\n",
      "Epoch 1338/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0577 - val_accuracy: 0.9928\n",
      "Epoch 1339/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0536 - val_accuracy: 0.9923\n",
      "Epoch 1340/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0556 - val_accuracy: 0.9908\n",
      "Epoch 1341/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0637 - val_accuracy: 0.9908\n",
      "Epoch 1342/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0827 - val_accuracy: 0.9867\n",
      "Epoch 1343/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9897\n",
      "Epoch 1344/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0628 - val_accuracy: 0.9903\n",
      "Epoch 1345/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0580 - val_accuracy: 0.9913\n",
      "Epoch 1346/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0722 - val_accuracy: 0.9882\n",
      "Epoch 1347/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0676 - val_accuracy: 0.9908\n",
      "Epoch 1348/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0726 - val_accuracy: 0.9872\n",
      "Epoch 1349/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0623 - val_accuracy: 0.9887\n",
      "Epoch 1350/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0537 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1351/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0494 - val_accuracy: 0.9923\n",
      "Epoch 1352/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0483 - val_accuracy: 0.9908\n",
      "Epoch 1353/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0454 - val_accuracy: 0.9908\n",
      "Epoch 1354/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0654 - val_accuracy: 0.9882\n",
      "Epoch 1355/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0657 - val_accuracy: 0.9851\n",
      "Epoch 1356/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0103 - accuracy: 0.9956 - val_loss: 0.0661 - val_accuracy: 0.9897\n",
      "Epoch 1357/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9872\n",
      "Epoch 1358/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0560 - val_accuracy: 0.9913\n",
      "Epoch 1359/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.0683 - val_accuracy: 0.9897\n",
      "Epoch 1360/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0593 - val_accuracy: 0.9918\n",
      "Epoch 1361/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0551 - val_accuracy: 0.9913\n",
      "Epoch 1362/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0661 - val_accuracy: 0.9913\n",
      "Epoch 1363/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0524 - val_accuracy: 0.9918\n",
      "Epoch 1364/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0571 - val_accuracy: 0.9913\n",
      "Epoch 1365/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0562 - val_accuracy: 0.9923\n",
      "Epoch 1366/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0614 - val_accuracy: 0.9908\n",
      "Epoch 1367/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0608 - val_accuracy: 0.9897\n",
      "Epoch 1368/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0645 - val_accuracy: 0.9908\n",
      "Epoch 1369/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0602 - val_accuracy: 0.9887\n",
      "Epoch 1370/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0864 - val_accuracy: 0.9867\n",
      "Epoch 1371/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.1355 - val_accuracy: 0.9774\n",
      "Epoch 1372/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0654 - val_accuracy: 0.9908\n",
      "Epoch 1373/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0657 - val_accuracy: 0.9903\n",
      "Epoch 1374/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0663 - val_accuracy: 0.9918\n",
      "Epoch 1375/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0633 - val_accuracy: 0.9903\n",
      "Epoch 1376/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0649 - val_accuracy: 0.9897\n",
      "Epoch 1377/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0689 - val_accuracy: 0.9908\n",
      "Epoch 1378/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.0586 - val_accuracy: 0.9903\n",
      "Epoch 1379/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0689 - val_accuracy: 0.9882\n",
      "Epoch 1380/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0975 - val_accuracy: 0.9846\n",
      "Epoch 1381/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "Epoch 1382/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0621 - val_accuracy: 0.9918\n",
      "Epoch 1383/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0631 - val_accuracy: 0.9918\n",
      "Epoch 1384/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0620 - val_accuracy: 0.9897\n",
      "Epoch 1385/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0574 - val_accuracy: 0.9923\n",
      "Epoch 1386/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0568 - val_accuracy: 0.9908\n",
      "Epoch 1387/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.1024 - val_accuracy: 0.9831\n",
      "Epoch 1388/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0614 - val_accuracy: 0.9892\n",
      "Epoch 1389/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0685 - val_accuracy: 0.9913\n",
      "Epoch 1390/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0651 - val_accuracy: 0.9903\n",
      "Epoch 1391/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0798 - val_accuracy: 0.9877\n",
      "Epoch 1392/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0620 - val_accuracy: 0.9913\n",
      "Epoch 1393/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0616 - val_accuracy: 0.9913\n",
      "Epoch 1394/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0581 - val_accuracy: 0.9913\n",
      "Epoch 1395/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0654 - val_accuracy: 0.9913\n",
      "Epoch 1396/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0563 - val_accuracy: 0.9918\n",
      "Epoch 1397/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0667 - val_accuracy: 0.9908\n",
      "Epoch 1398/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0594 - val_accuracy: 0.9918\n",
      "Epoch 1399/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0649 - val_accuracy: 0.9923\n",
      "Epoch 1400/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0663 - val_accuracy: 0.9908\n",
      "Epoch 1401/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0656 - val_accuracy: 0.9913\n",
      "Epoch 1402/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0614 - val_accuracy: 0.9913\n",
      "Epoch 1403/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0580 - val_accuracy: 0.9903\n",
      "Epoch 1404/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0848 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1405/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0783 - val_accuracy: 0.9872\n",
      "Epoch 1406/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0661 - val_accuracy: 0.9918\n",
      "Epoch 1407/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0598 - val_accuracy: 0.9918\n",
      "Epoch 1408/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0779 - val_accuracy: 0.9867\n",
      "Epoch 1409/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.0671 - val_accuracy: 0.9903\n",
      "Epoch 1410/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0671 - val_accuracy: 0.9892\n",
      "Epoch 1411/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0608 - val_accuracy: 0.9923\n",
      "Epoch 1412/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0717 - val_accuracy: 0.9887\n",
      "Epoch 1413/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0661 - val_accuracy: 0.9903\n",
      "Epoch 1414/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0677 - val_accuracy: 0.9892\n",
      "Epoch 1415/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9918\n",
      "Epoch 1416/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0595 - val_accuracy: 0.9918\n",
      "Epoch 1417/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0559 - val_accuracy: 0.9908\n",
      "Epoch 1418/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.0533 - val_accuracy: 0.9913\n",
      "Epoch 1419/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0692 - val_accuracy: 0.9913\n",
      "Epoch 1420/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0679 - val_accuracy: 0.9908\n",
      "Epoch 1421/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0746 - val_accuracy: 0.9887\n",
      "Epoch 1422/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0568 - val_accuracy: 0.9908\n",
      "Epoch 1423/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0538 - val_accuracy: 0.9908\n",
      "Epoch 1424/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0524 - val_accuracy: 0.9918\n",
      "Epoch 1425/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0568 - val_accuracy: 0.9918\n",
      "Epoch 1426/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0647 - val_accuracy: 0.9908\n",
      "Epoch 1427/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0581 - val_accuracy: 0.9913\n",
      "Epoch 1428/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.0603 - val_accuracy: 0.9918\n",
      "Epoch 1429/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0745 - val_accuracy: 0.9892\n",
      "Epoch 1430/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.0761 - val_accuracy: 0.9882\n",
      "Epoch 1431/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0683 - val_accuracy: 0.9897\n",
      "Epoch 1432/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0920 - val_accuracy: 0.9856\n",
      "Epoch 1433/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0707 - val_accuracy: 0.9882\n",
      "Epoch 1434/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0621 - val_accuracy: 0.9913\n",
      "Epoch 1435/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.0562 - val_accuracy: 0.9892\n",
      "Epoch 1436/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9913\n",
      "Epoch 1437/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9913\n",
      "Epoch 1438/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0746 - val_accuracy: 0.9856\n",
      "Epoch 1439/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0853 - val_accuracy: 0.9887\n",
      "Epoch 1440/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0685 - val_accuracy: 0.9903\n",
      "Epoch 1441/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0674 - val_accuracy: 0.9897\n",
      "Epoch 1442/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0552 - val_accuracy: 0.9903\n",
      "Epoch 1443/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0688 - val_accuracy: 0.9897\n",
      "Epoch 1444/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0580 - val_accuracy: 0.9913\n",
      "Epoch 1445/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0609 - val_accuracy: 0.9913\n",
      "Epoch 1446/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0782 - val_accuracy: 0.9882\n",
      "Epoch 1447/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0664 - val_accuracy: 0.9908\n",
      "Epoch 1448/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0722 - val_accuracy: 0.9908\n",
      "Epoch 1449/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0585 - val_accuracy: 0.9903\n",
      "Epoch 1450/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0735 - val_accuracy: 0.9897\n",
      "Epoch 1451/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0625 - val_accuracy: 0.9887\n",
      "Epoch 1452/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0989 - val_accuracy: 0.9810\n",
      "Epoch 1453/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.0608 - val_accuracy: 0.9918\n",
      "Epoch 1454/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0593 - val_accuracy: 0.9897\n",
      "Epoch 1455/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0594 - val_accuracy: 0.9923\n",
      "Epoch 1456/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0590 - val_accuracy: 0.9923\n",
      "Epoch 1457/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0618 - val_accuracy: 0.9918\n",
      "Epoch 1458/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0583 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1459/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0691 - val_accuracy: 0.9908\n",
      "Epoch 1460/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0082 - accuracy: 0.9967 - val_loss: 0.0798 - val_accuracy: 0.9887\n",
      "Epoch 1461/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9967 - val_loss: 0.0684 - val_accuracy: 0.9908\n",
      "Epoch 1462/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0609 - val_accuracy: 0.9908\n",
      "Epoch 1463/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0635 - val_accuracy: 0.9913\n",
      "Epoch 1464/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0653 - val_accuracy: 0.9897\n",
      "Epoch 1465/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0584 - val_accuracy: 0.9918\n",
      "Epoch 1466/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0651 - val_accuracy: 0.9918\n",
      "Epoch 1467/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0696 - val_accuracy: 0.9872\n",
      "Epoch 1468/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.0554 - val_accuracy: 0.9923\n",
      "Epoch 1469/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0885 - val_accuracy: 0.9872\n",
      "Epoch 1470/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0728 - val_accuracy: 0.9872\n",
      "Epoch 1471/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0614 - val_accuracy: 0.9918\n",
      "Epoch 1472/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0584 - val_accuracy: 0.9887\n",
      "Epoch 1473/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0672 - val_accuracy: 0.9903\n",
      "Epoch 1474/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0663 - val_accuracy: 0.9913\n",
      "Epoch 1475/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9908\n",
      "Epoch 1476/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0775 - val_accuracy: 0.9887\n",
      "Epoch 1477/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0527 - val_accuracy: 0.9918\n",
      "Epoch 1478/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0724 - val_accuracy: 0.9897\n",
      "Epoch 1479/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0775 - val_accuracy: 0.9867\n",
      "Epoch 1480/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.0575 - val_accuracy: 0.9928\n",
      "Epoch 1481/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0606 - val_accuracy: 0.9923\n",
      "Epoch 1482/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0609 - val_accuracy: 0.9903\n",
      "Epoch 1483/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0609 - val_accuracy: 0.9908\n",
      "Epoch 1484/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0565 - val_accuracy: 0.9923\n",
      "Epoch 1485/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0600 - val_accuracy: 0.9918\n",
      "Epoch 1486/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0717 - val_accuracy: 0.9897\n",
      "Epoch 1487/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0761 - val_accuracy: 0.9877\n",
      "Epoch 1488/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0576 - val_accuracy: 0.9913\n",
      "Epoch 1489/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0749 - val_accuracy: 0.9892\n",
      "Epoch 1490/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0634 - val_accuracy: 0.9882\n",
      "Epoch 1491/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0647 - val_accuracy: 0.9913\n",
      "Epoch 1492/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0568 - val_accuracy: 0.9913\n",
      "Epoch 1493/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0716 - val_accuracy: 0.9913\n",
      "Epoch 1494/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0692 - val_accuracy: 0.9918\n",
      "Epoch 1495/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0662 - val_accuracy: 0.9918\n",
      "Epoch 1496/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0748 - val_accuracy: 0.9897\n",
      "Epoch 1497/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0669 - val_accuracy: 0.9923\n",
      "Epoch 1498/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0668 - val_accuracy: 0.9908\n",
      "Epoch 1499/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.0824 - val_accuracy: 0.9887\n",
      "Epoch 1500/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0511 - val_accuracy: 0.9913\n",
      "Epoch 1501/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0685 - val_accuracy: 0.9908\n",
      "Epoch 1502/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0663 - val_accuracy: 0.9903\n",
      "Epoch 1503/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0726 - val_accuracy: 0.9903\n",
      "Epoch 1504/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0751 - val_accuracy: 0.9882\n",
      "Epoch 1505/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0658 - val_accuracy: 0.9918\n",
      "Epoch 1506/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0595 - val_accuracy: 0.9908\n",
      "Epoch 1507/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0706 - val_accuracy: 0.9903\n",
      "Epoch 1508/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0651 - val_accuracy: 0.9903\n",
      "Epoch 1509/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0794 - val_accuracy: 0.9892\n",
      "Epoch 1510/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0733 - val_accuracy: 0.9867\n",
      "Epoch 1511/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0649 - val_accuracy: 0.9913\n",
      "Epoch 1512/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0723 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1513/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0726 - val_accuracy: 0.9908\n",
      "Epoch 1514/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0756 - val_accuracy: 0.9887\n",
      "Epoch 1515/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.0623 - val_accuracy: 0.9913\n",
      "Epoch 1516/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0620 - val_accuracy: 0.9918\n",
      "Epoch 1517/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0629 - val_accuracy: 0.9918\n",
      "Epoch 1518/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0630 - val_accuracy: 0.9913\n",
      "Epoch 1519/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0755 - val_accuracy: 0.9903\n",
      "Epoch 1520/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0720 - val_accuracy: 0.9882\n",
      "Epoch 1521/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0597 - val_accuracy: 0.9903\n",
      "Epoch 1522/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0638 - val_accuracy: 0.9913\n",
      "Epoch 1523/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0678 - val_accuracy: 0.9913\n",
      "Epoch 1524/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.0644 - val_accuracy: 0.9887\n",
      "Epoch 1525/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0632 - val_accuracy: 0.9913\n",
      "Epoch 1526/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.0682 - val_accuracy: 0.9892\n",
      "Epoch 1527/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0623 - val_accuracy: 0.9887\n",
      "Epoch 1528/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0577 - val_accuracy: 0.9923\n",
      "Epoch 1529/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0653 - val_accuracy: 0.9908\n",
      "Epoch 1530/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0765 - val_accuracy: 0.9887\n",
      "Epoch 1531/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0689 - val_accuracy: 0.9908\n",
      "Epoch 1532/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0706 - val_accuracy: 0.9908\n",
      "Epoch 1533/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0608 - val_accuracy: 0.9908\n",
      "Epoch 1534/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0571 - val_accuracy: 0.9913\n",
      "Epoch 1535/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0659 - val_accuracy: 0.9913\n",
      "Epoch 1536/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0664 - val_accuracy: 0.9913\n",
      "Epoch 1537/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0715 - val_accuracy: 0.9887\n",
      "Epoch 1538/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9897\n",
      "Epoch 1539/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.0730 - val_accuracy: 0.9887\n",
      "Epoch 1540/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0748 - val_accuracy: 0.9903\n",
      "Epoch 1541/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0716 - val_accuracy: 0.9887\n",
      "Epoch 1542/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.0582 - val_accuracy: 0.9918\n",
      "Epoch 1543/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.0718 - val_accuracy: 0.9908\n",
      "Epoch 1544/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.0673 - val_accuracy: 0.9913\n",
      "Epoch 1545/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0593 - val_accuracy: 0.9908\n",
      "Epoch 1546/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0598 - val_accuracy: 0.9908\n",
      "Epoch 1547/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9923\n",
      "Epoch 1548/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0613 - val_accuracy: 0.9923\n",
      "Epoch 1549/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0644 - val_accuracy: 0.9882\n",
      "Epoch 1550/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0126 - accuracy: 0.9952 - val_loss: 0.0637 - val_accuracy: 0.9856\n",
      "Epoch 1551/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0621 - val_accuracy: 0.9913\n",
      "Epoch 1552/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0647 - val_accuracy: 0.9923\n",
      "Epoch 1553/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0643 - val_accuracy: 0.9913\n",
      "Epoch 1554/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0653 - val_accuracy: 0.9923\n",
      "Epoch 1555/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.0665 - val_accuracy: 0.9918\n",
      "Epoch 1556/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0871 - val_accuracy: 0.9877\n",
      "Epoch 1557/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0712 - val_accuracy: 0.9913\n",
      "Epoch 1558/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0661 - val_accuracy: 0.9918\n",
      "Epoch 1559/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0625 - val_accuracy: 0.9918\n",
      "Epoch 1560/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0686 - val_accuracy: 0.9913\n",
      "Epoch 1561/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0680 - val_accuracy: 0.9908\n",
      "Epoch 1562/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0667 - val_accuracy: 0.9897\n",
      "Epoch 1563/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0599 - val_accuracy: 0.9928\n",
      "Epoch 1564/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.1033 - val_accuracy: 0.9836\n",
      "Epoch 1565/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0668 - val_accuracy: 0.9903\n",
      "Epoch 1566/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0624 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1567/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0731 - val_accuracy: 0.9908\n",
      "Epoch 1568/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0645 - val_accuracy: 0.9908\n",
      "Epoch 1569/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0625 - val_accuracy: 0.9908\n",
      "Epoch 1570/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9903\n",
      "Epoch 1571/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0680 - val_accuracy: 0.9903\n",
      "Epoch 1572/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0575 - val_accuracy: 0.9913\n",
      "Epoch 1573/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0588 - val_accuracy: 0.9918\n",
      "Epoch 1574/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.1006 - val_accuracy: 0.9851\n",
      "Epoch 1575/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0682 - val_accuracy: 0.9908\n",
      "Epoch 1576/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0707 - val_accuracy: 0.9913\n",
      "Epoch 1577/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0621 - val_accuracy: 0.9903\n",
      "Epoch 1578/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0736 - val_accuracy: 0.9887\n",
      "Epoch 1579/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0420 - accuracy: 0.9883 - val_loss: 0.0830 - val_accuracy: 0.9810\n",
      "Epoch 1580/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0645 - accuracy: 0.9850 - val_loss: 0.0809 - val_accuracy: 0.9841\n",
      "Epoch 1581/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0576 - accuracy: 0.9850 - val_loss: 0.0466 - val_accuracy: 0.9892\n",
      "Epoch 1582/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.0784 - val_accuracy: 0.9841\n",
      "Epoch 1583/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.0599 - val_accuracy: 0.9892\n",
      "Epoch 1584/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0556 - val_accuracy: 0.9908\n",
      "Epoch 1585/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0593 - val_accuracy: 0.9918\n",
      "Epoch 1586/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0601 - val_accuracy: 0.9923\n",
      "Epoch 1587/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0642 - val_accuracy: 0.9908\n",
      "Epoch 1588/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0622 - val_accuracy: 0.9923\n",
      "Epoch 1589/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0806 - val_accuracy: 0.9867\n",
      "Epoch 1590/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0652 - val_accuracy: 0.9913\n",
      "Epoch 1591/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0629 - val_accuracy: 0.9913\n",
      "Epoch 1592/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.0610 - val_accuracy: 0.9918\n",
      "Epoch 1593/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0650 - val_accuracy: 0.9913\n",
      "Epoch 1594/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0597 - val_accuracy: 0.9918\n",
      "Epoch 1595/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.99 - 0s 26us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0606 - val_accuracy: 0.9923\n",
      "Epoch 1596/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0740 - val_accuracy: 0.9892\n",
      "Epoch 1597/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0637 - val_accuracy: 0.9908\n",
      "Epoch 1598/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0630 - val_accuracy: 0.9913\n",
      "Epoch 1599/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0607 - val_accuracy: 0.9928\n",
      "Epoch 1600/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0629 - val_accuracy: 0.9903\n",
      "Epoch 1601/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0566 - val_accuracy: 0.9908\n",
      "Epoch 1602/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0701 - val_accuracy: 0.9897\n",
      "Epoch 1603/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0656 - val_accuracy: 0.9913\n",
      "Epoch 1604/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.0747 - val_accuracy: 0.9897\n",
      "Epoch 1605/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0713 - val_accuracy: 0.9913\n",
      "Epoch 1606/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0730 - val_accuracy: 0.9887\n",
      "Epoch 1607/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.0823 - val_accuracy: 0.9872\n",
      "Epoch 1608/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0706 - val_accuracy: 0.9897\n",
      "Epoch 1609/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0831 - val_accuracy: 0.9877\n",
      "Epoch 1610/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.0632 - val_accuracy: 0.9913\n",
      "Epoch 1611/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9882\n",
      "Epoch 1612/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0696 - val_accuracy: 0.9908\n",
      "Epoch 1613/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0672 - val_accuracy: 0.9887\n",
      "Epoch 1614/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0080 - accuracy: 0.9967 - val_loss: 0.0641 - val_accuracy: 0.9913\n",
      "Epoch 1615/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0934 - val_accuracy: 0.9846\n",
      "Epoch 1616/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0296 - accuracy: 0.9914 - val_loss: 0.0683 - val_accuracy: 0.9877\n",
      "Epoch 1617/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0601 - val_accuracy: 0.9918\n",
      "Epoch 1618/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0616 - val_accuracy: 0.9918\n",
      "Epoch 1619/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0647 - val_accuracy: 0.9903\n",
      "Epoch 1620/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0704 - val_accuracy: 0.9908\n",
      "Epoch 1621/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0762 - val_accuracy: 0.9897\n",
      "Epoch 1622/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0649 - val_accuracy: 0.9908\n",
      "Epoch 1623/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0730 - val_accuracy: 0.9887\n",
      "Epoch 1624/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0774 - val_accuracy: 0.9887\n",
      "Epoch 1625/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0695 - val_accuracy: 0.9908\n",
      "Epoch 1626/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.0767 - val_accuracy: 0.9882\n",
      "Epoch 1627/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0855 - val_accuracy: 0.9872\n",
      "Epoch 1628/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0701 - val_accuracy: 0.9892\n",
      "Epoch 1629/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0758 - val_accuracy: 0.9882\n",
      "Epoch 1630/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0689 - val_accuracy: 0.9903\n",
      "Epoch 1631/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0643 - val_accuracy: 0.9918\n",
      "Epoch 1632/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0651 - val_accuracy: 0.9923\n",
      "Epoch 1633/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9903\n",
      "Epoch 1634/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0734 - val_accuracy: 0.9897\n",
      "Epoch 1635/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0707 - val_accuracy: 0.9913\n",
      "Epoch 1636/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0646 - val_accuracy: 0.9908\n",
      "Epoch 1637/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0611 - val_accuracy: 0.9903\n",
      "Epoch 1638/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0724 - val_accuracy: 0.9913\n",
      "Epoch 1639/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0721 - val_accuracy: 0.9903\n",
      "Epoch 1640/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0838 - val_accuracy: 0.9872\n",
      "Epoch 1641/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0650 - val_accuracy: 0.9913\n",
      "Epoch 1642/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0589 - val_accuracy: 0.9918\n",
      "Epoch 1643/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9913\n",
      "Epoch 1644/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0729 - val_accuracy: 0.9908\n",
      "Epoch 1645/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0676 - val_accuracy: 0.9908\n",
      "Epoch 1646/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0639 - val_accuracy: 0.9918\n",
      "Epoch 1647/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.0957 - val_accuracy: 0.9887\n",
      "Epoch 1648/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0731 - val_accuracy: 0.9903\n",
      "Epoch 1649/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.1009 - val_accuracy: 0.9872\n",
      "Epoch 1650/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0171 - accuracy: 0.9936 - val_loss: 0.0720 - val_accuracy: 0.9877\n",
      "Epoch 1651/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9908\n",
      "Epoch 1652/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0720 - val_accuracy: 0.9897\n",
      "Epoch 1653/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9892\n",
      "Epoch 1654/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0864 - val_accuracy: 0.9877\n",
      "Epoch 1655/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0790 - val_accuracy: 0.9872\n",
      "Epoch 1656/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.0710 - val_accuracy: 0.9903\n",
      "Epoch 1657/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0711 - val_accuracy: 0.9903\n",
      "Epoch 1658/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0734 - val_accuracy: 0.9897\n",
      "Epoch 1659/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0709 - val_accuracy: 0.9903\n",
      "Epoch 1660/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.0886 - val_accuracy: 0.9851\n",
      "Epoch 1661/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.1071 - val_accuracy: 0.9846\n",
      "Epoch 1662/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "Epoch 1663/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0757 - val_accuracy: 0.9892\n",
      "Epoch 1664/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0640 - val_accuracy: 0.9913\n",
      "Epoch 1665/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0732 - val_accuracy: 0.9913\n",
      "Epoch 1666/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0673 - val_accuracy: 0.9892\n",
      "Epoch 1667/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0643 - val_accuracy: 0.9918\n",
      "Epoch 1668/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0750 - val_accuracy: 0.9908\n",
      "Epoch 1669/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.0858 - val_accuracy: 0.9892\n",
      "Epoch 1670/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0691 - val_accuracy: 0.9923\n",
      "Epoch 1671/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0815 - val_accuracy: 0.9892\n",
      "Epoch 1672/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0751 - val_accuracy: 0.9908\n",
      "Epoch 1673/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0742 - val_accuracy: 0.9892\n",
      "Epoch 1674/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0713 - val_accuracy: 0.9913\n",
      "Epoch 1675/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0717 - val_accuracy: 0.9903\n",
      "Epoch 1676/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.0628 - val_accuracy: 0.9913\n",
      "Epoch 1677/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0102 - accuracy: 0.9956 - val_loss: 0.1109 - val_accuracy: 0.9826\n",
      "Epoch 1678/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0681 - val_accuracy: 0.9928\n",
      "Epoch 1679/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0753 - val_accuracy: 0.9872\n",
      "Epoch 1680/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0864 - val_accuracy: 0.9877\n",
      "Epoch 1681/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0949 - val_accuracy: 0.9851\n",
      "Epoch 1682/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0691 - val_accuracy: 0.9903\n",
      "Epoch 1683/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0716 - val_accuracy: 0.9903\n",
      "Epoch 1684/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0976 - val_accuracy: 0.9856\n",
      "Epoch 1685/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0730 - val_accuracy: 0.9892\n",
      "Epoch 1686/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0793 - val_accuracy: 0.9897\n",
      "Epoch 1687/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0725 - val_accuracy: 0.9913\n",
      "Epoch 1688/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0793 - val_accuracy: 0.9892\n",
      "Epoch 1689/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0652 - val_accuracy: 0.9928\n",
      "Epoch 1690/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1056 - val_accuracy: 0.9831\n",
      "Epoch 1691/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0650 - val_accuracy: 0.9903\n",
      "Epoch 1692/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0845 - val_accuracy: 0.9892\n",
      "Epoch 1693/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0716 - val_accuracy: 0.9918\n",
      "Epoch 1694/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.0650 - val_accuracy: 0.9928\n",
      "Epoch 1695/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0637 - val_accuracy: 0.9913\n",
      "Epoch 1696/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0708 - val_accuracy: 0.9923\n",
      "Epoch 1697/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0675 - val_accuracy: 0.9918\n",
      "Epoch 1698/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0706 - val_accuracy: 0.9908\n",
      "Epoch 1699/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0955 - val_accuracy: 0.9856\n",
      "Epoch 1700/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0973 - val_accuracy: 0.9846\n",
      "Epoch 1701/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0661 - val_accuracy: 0.9877\n",
      "Epoch 1702/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9956 - val_loss: 0.0672 - val_accuracy: 0.9913\n",
      "Epoch 1703/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0646 - val_accuracy: 0.9913\n",
      "Epoch 1704/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9913\n",
      "Epoch 1705/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.0756 - val_accuracy: 0.9892\n",
      "Epoch 1706/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0763 - val_accuracy: 0.9892\n",
      "Epoch 1707/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0666 - val_accuracy: 0.9913\n",
      "Epoch 1708/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0778 - val_accuracy: 0.9908\n",
      "Epoch 1709/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0734 - val_accuracy: 0.9913\n",
      "Epoch 1710/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0063 - accuracy: 0.9971 - val_loss: 0.0893 - val_accuracy: 0.9872\n",
      "Epoch 1711/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0704 - val_accuracy: 0.9923\n",
      "Epoch 1712/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0696 - val_accuracy: 0.9908\n",
      "Epoch 1713/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0840 - val_accuracy: 0.9887\n",
      "Epoch 1714/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0883 - val_accuracy: 0.9872\n",
      "Epoch 1715/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0822 - val_accuracy: 0.9872\n",
      "Epoch 1716/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0674 - val_accuracy: 0.9913\n",
      "Epoch 1717/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0678 - val_accuracy: 0.9933\n",
      "Epoch 1718/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.0818 - val_accuracy: 0.9897\n",
      "Epoch 1719/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0799 - val_accuracy: 0.9892\n",
      "Epoch 1720/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0700 - val_accuracy: 0.9908\n",
      "Epoch 1721/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0762 - val_accuracy: 0.9903\n",
      "Epoch 1722/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0838 - val_accuracy: 0.9872\n",
      "Epoch 1723/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.0595 - val_accuracy: 0.9923\n",
      "Epoch 1724/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0644 - val_accuracy: 0.9908\n",
      "Epoch 1725/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9918\n",
      "Epoch 1726/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0083 - accuracy: 0.9965 - val_loss: 0.0688 - val_accuracy: 0.9918\n",
      "Epoch 1727/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0674 - val_accuracy: 0.9913\n",
      "Epoch 1728/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0668 - val_accuracy: 0.9903\n",
      "Epoch 1729/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0592 - val_accuracy: 0.9923\n",
      "Epoch 1730/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0757 - val_accuracy: 0.9903\n",
      "Epoch 1731/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0725 - val_accuracy: 0.9908\n",
      "Epoch 1732/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0717 - val_accuracy: 0.9913\n",
      "Epoch 1733/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0718 - val_accuracy: 0.9913\n",
      "Epoch 1734/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0729 - val_accuracy: 0.9918\n",
      "Epoch 1735/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0834 - val_accuracy: 0.9877\n",
      "Epoch 1736/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0683 - val_accuracy: 0.9892\n",
      "Epoch 1737/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0803 - val_accuracy: 0.9897\n",
      "Epoch 1738/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0634 - val_accuracy: 0.9897\n",
      "Epoch 1739/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0720 - val_accuracy: 0.9908\n",
      "Epoch 1740/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0620 - val_accuracy: 0.9913\n",
      "Epoch 1741/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0572 - val_accuracy: 0.9908\n",
      "Epoch 1742/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0809 - val_accuracy: 0.9903\n",
      "Epoch 1743/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0909 - val_accuracy: 0.9882\n",
      "Epoch 1744/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0677 - val_accuracy: 0.9892\n",
      "Epoch 1745/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0647 - val_accuracy: 0.9908\n",
      "Epoch 1746/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0619 - val_accuracy: 0.9923\n",
      "Epoch 1747/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0713 - val_accuracy: 0.9918\n",
      "Epoch 1748/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0690 - val_accuracy: 0.9918\n",
      "Epoch 1749/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0844 - val_accuracy: 0.9872\n",
      "Epoch 1750/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0647 - val_accuracy: 0.9913\n",
      "Epoch 1751/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0728 - val_accuracy: 0.9913\n",
      "Epoch 1752/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0648 - val_accuracy: 0.9918\n",
      "Epoch 1753/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9971 - val_loss: 0.0668 - val_accuracy: 0.9913\n",
      "Epoch 1754/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0645 - val_accuracy: 0.9913\n",
      "Epoch 1755/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.0615 - val_accuracy: 0.9918\n",
      "Epoch 1756/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0847 - val_accuracy: 0.9877\n",
      "Epoch 1757/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0990 - val_accuracy: 0.9851\n",
      "Epoch 1758/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0681 - val_accuracy: 0.9923\n",
      "Epoch 1759/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0728 - val_accuracy: 0.9913\n",
      "Epoch 1760/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0727 - val_accuracy: 0.9903\n",
      "Epoch 1761/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0984 - val_accuracy: 0.9862\n",
      "Epoch 1762/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0809 - val_accuracy: 0.9908\n",
      "Epoch 1763/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0583 - val_accuracy: 0.9923\n",
      "Epoch 1764/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0653 - val_accuracy: 0.9913\n",
      "Epoch 1765/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0702 - val_accuracy: 0.9903\n",
      "Epoch 1766/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0723 - val_accuracy: 0.9913\n",
      "Epoch 1767/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.0621 - val_accuracy: 0.9908\n",
      "Epoch 1768/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.0631 - val_accuracy: 0.9908\n",
      "Epoch 1769/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9903\n",
      "Epoch 1770/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0758 - val_accuracy: 0.9897\n",
      "Epoch 1771/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0655 - val_accuracy: 0.9918\n",
      "Epoch 1772/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0688 - val_accuracy: 0.9923\n",
      "Epoch 1773/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0642 - val_accuracy: 0.9918\n",
      "Epoch 1774/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0644 - val_accuracy: 0.9928\n",
      "Epoch 1775/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0659 - val_accuracy: 0.9923\n",
      "Epoch 1776/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.0741 - val_accuracy: 0.9908\n",
      "Epoch 1777/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0305 - accuracy: 0.9934 - val_loss: 0.0854 - val_accuracy: 0.9903\n",
      "Epoch 1778/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.1108 - val_accuracy: 0.9810\n",
      "Epoch 1779/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0650 - val_accuracy: 0.9913\n",
      "Epoch 1780/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0630 - val_accuracy: 0.9913\n",
      "Epoch 1781/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0764 - val_accuracy: 0.9903\n",
      "Epoch 1782/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0768 - val_accuracy: 0.9903\n",
      "Epoch 1783/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0694 - val_accuracy: 0.9908\n",
      "Epoch 1784/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0739 - val_accuracy: 0.9918\n",
      "Epoch 1785/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0768 - val_accuracy: 0.9918\n",
      "Epoch 1786/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0697 - val_accuracy: 0.9908\n",
      "Epoch 1787/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0661 - val_accuracy: 0.9913\n",
      "Epoch 1788/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0684 - val_accuracy: 0.9897\n",
      "Epoch 1789/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.0633 - val_accuracy: 0.9908\n",
      "Epoch 1790/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0750 - val_accuracy: 0.9903\n",
      "Epoch 1791/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0668 - val_accuracy: 0.9903\n",
      "Epoch 1792/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0750 - val_accuracy: 0.9913\n",
      "Epoch 1793/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0769 - val_accuracy: 0.9892\n",
      "Epoch 1794/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0682 - val_accuracy: 0.9908\n",
      "Epoch 1795/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0808 - val_accuracy: 0.9908\n",
      "Epoch 1796/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.0746 - val_accuracy: 0.9903\n",
      "Epoch 1797/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0721 - val_accuracy: 0.9908\n",
      "Epoch 1798/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0700 - val_accuracy: 0.9918\n",
      "Epoch 1799/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0805 - val_accuracy: 0.9897\n",
      "Epoch 1800/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0673 - val_accuracy: 0.9913\n",
      "Epoch 1801/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.99 - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0801 - val_accuracy: 0.9897\n",
      "Epoch 1802/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1001 - val_accuracy: 0.9836\n",
      "Epoch 1803/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0727 - val_accuracy: 0.9892\n",
      "Epoch 1804/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0933 - val_accuracy: 0.9846\n",
      "Epoch 1805/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0715 - val_accuracy: 0.9903\n",
      "Epoch 1806/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.0702 - val_accuracy: 0.9887\n",
      "Epoch 1807/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0914 - val_accuracy: 0.9872\n",
      "Epoch 1808/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0680 - val_accuracy: 0.9913\n",
      "Epoch 1809/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0701 - val_accuracy: 0.9908\n",
      "Epoch 1810/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0892 - val_accuracy: 0.9882\n",
      "Epoch 1811/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0630 - val_accuracy: 0.9908\n",
      "Epoch 1812/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0684 - val_accuracy: 0.9918\n",
      "Epoch 1813/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0659 - val_accuracy: 0.9918\n",
      "Epoch 1814/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0728 - val_accuracy: 0.9913\n",
      "Epoch 1815/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0907 - val_accuracy: 0.9877\n",
      "Epoch 1816/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0690 - val_accuracy: 0.9923\n",
      "Epoch 1817/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0716 - val_accuracy: 0.9903\n",
      "Epoch 1818/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0794 - val_accuracy: 0.9897\n",
      "Epoch 1819/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0732 - val_accuracy: 0.9913\n",
      "Epoch 1820/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 1821/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0679 - val_accuracy: 0.9908\n",
      "Epoch 1822/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0876 - val_accuracy: 0.9877\n",
      "Epoch 1823/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0659 - val_accuracy: 0.9928\n",
      "Epoch 1824/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.0737 - val_accuracy: 0.9908\n",
      "Epoch 1825/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0648 - val_accuracy: 0.9913\n",
      "Epoch 1826/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0715 - val_accuracy: 0.9908\n",
      "Epoch 1827/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.0738 - val_accuracy: 0.9882\n",
      "Epoch 1828/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0871 - val_accuracy: 0.9892\n",
      "Epoch 1829/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0746 - val_accuracy: 0.9892\n",
      "Epoch 1830/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0801 - val_accuracy: 0.9903\n",
      "Epoch 1831/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0714 - val_accuracy: 0.9913\n",
      "Epoch 1832/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0733 - val_accuracy: 0.9908\n",
      "Epoch 1833/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0700 - val_accuracy: 0.9908\n",
      "Epoch 1834/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0780 - val_accuracy: 0.9913\n",
      "Epoch 1835/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1836/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0766 - val_accuracy: 0.9903\n",
      "Epoch 1837/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0851 - val_accuracy: 0.9877\n",
      "Epoch 1838/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0685 - val_accuracy: 0.9918\n",
      "Epoch 1839/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0736 - val_accuracy: 0.9918\n",
      "Epoch 1840/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0070 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9918\n",
      "Epoch 1841/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0839 - val_accuracy: 0.9846\n",
      "Epoch 1842/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0254 - accuracy: 0.9901 - val_loss: 0.0796 - val_accuracy: 0.9846\n",
      "Epoch 1843/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.0682 - val_accuracy: 0.9913\n",
      "Epoch 1844/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0785 - val_accuracy: 0.9903\n",
      "Epoch 1845/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0073 - accuracy: 0.9971 - val_loss: 0.0722 - val_accuracy: 0.9913\n",
      "Epoch 1846/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0675 - val_accuracy: 0.9908\n",
      "Epoch 1847/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0714 - val_accuracy: 0.9923\n",
      "Epoch 1848/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0776 - val_accuracy: 0.9903\n",
      "Epoch 1849/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0624 - val_accuracy: 0.9923\n",
      "Epoch 1850/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0679 - val_accuracy: 0.9923\n",
      "Epoch 1851/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0732 - val_accuracy: 0.9913\n",
      "Epoch 1852/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0700 - val_accuracy: 0.9913\n",
      "Epoch 1853/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0713 - val_accuracy: 0.9913\n",
      "Epoch 1854/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0862 - val_accuracy: 0.9877\n",
      "Epoch 1855/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0712 - val_accuracy: 0.9918\n",
      "Epoch 1856/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0844 - val_accuracy: 0.9897\n",
      "Epoch 1857/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0770 - val_accuracy: 0.9913\n",
      "Epoch 1858/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1242 - val_accuracy: 0.9815\n",
      "Epoch 1859/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.0724 - val_accuracy: 0.9897\n",
      "Epoch 1860/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0857 - val_accuracy: 0.9882\n",
      "Epoch 1861/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0835 - val_accuracy: 0.9882\n",
      "Epoch 1862/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0918 - val_accuracy: 0.9841\n",
      "Epoch 1863/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0772 - val_accuracy: 0.9892\n",
      "Epoch 1864/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0872 - val_accuracy: 0.9892\n",
      "Epoch 1865/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0758 - val_accuracy: 0.9908\n",
      "Epoch 1866/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0993 - val_accuracy: 0.9846\n",
      "Epoch 1867/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0682 - val_accuracy: 0.9923\n",
      "Epoch 1868/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0777 - val_accuracy: 0.9903\n",
      "Epoch 1869/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0843 - val_accuracy: 0.9897\n",
      "Epoch 1870/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0843 - val_accuracy: 0.9856\n",
      "Epoch 1871/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0838 - val_accuracy: 0.9903\n",
      "Epoch 1872/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0844 - val_accuracy: 0.9872\n",
      "Epoch 1873/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0806 - val_accuracy: 0.9913\n",
      "Epoch 1874/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0737 - val_accuracy: 0.9892\n",
      "Epoch 1875/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0769 - val_accuracy: 0.9908\n",
      "Epoch 1876/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 1877/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0789 - val_accuracy: 0.9903\n",
      "Epoch 1878/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0716 - val_accuracy: 0.9913\n",
      "Epoch 1879/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0753 - val_accuracy: 0.9903\n",
      "Epoch 1880/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0800 - val_accuracy: 0.9892\n",
      "Epoch 1881/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0759 - val_accuracy: 0.9918\n",
      "Epoch 1882/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0089 - accuracy: 0.9960 - val_loss: 0.0856 - val_accuracy: 0.9887\n",
      "Epoch 1883/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0840 - val_accuracy: 0.9908\n",
      "Epoch 1884/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0710 - val_accuracy: 0.9913\n",
      "Epoch 1885/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0826 - val_accuracy: 0.9887\n",
      "Epoch 1886/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.0824 - val_accuracy: 0.9903\n",
      "Epoch 1887/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0873 - val_accuracy: 0.9892\n",
      "Epoch 1888/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0791 - val_accuracy: 0.9897\n",
      "Epoch 1889/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0993 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1890/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0989 - val_accuracy: 0.9856\n",
      "Epoch 1891/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0105 - accuracy: 0.9956 - val_loss: 0.0786 - val_accuracy: 0.9897\n",
      "Epoch 1892/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0845 - val_accuracy: 0.9872\n",
      "Epoch 1893/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0739 - val_accuracy: 0.9913\n",
      "Epoch 1894/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0922 - val_accuracy: 0.9872\n",
      "Epoch 1895/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.1079 - val_accuracy: 0.9841\n",
      "Epoch 1896/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0819 - val_accuracy: 0.9908\n",
      "Epoch 1897/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0777 - val_accuracy: 0.9918\n",
      "Epoch 1898/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0723 - val_accuracy: 0.9908\n",
      "Epoch 1899/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0730 - val_accuracy: 0.9908\n",
      "Epoch 1900/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9903\n",
      "Epoch 1901/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0768 - val_accuracy: 0.9913\n",
      "Epoch 1902/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0762 - val_accuracy: 0.9903\n",
      "Epoch 1903/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0793 - val_accuracy: 0.9913\n",
      "Epoch 1904/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.0723 - val_accuracy: 0.9903\n",
      "Epoch 1905/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0814 - val_accuracy: 0.9903\n",
      "Epoch 1906/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0775 - val_accuracy: 0.9918\n",
      "Epoch 1907/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0873 - val_accuracy: 0.9882\n",
      "Epoch 1908/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0780 - val_accuracy: 0.9892\n",
      "Epoch 1909/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0777 - val_accuracy: 0.9908\n",
      "Epoch 1910/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0077 - accuracy: 0.9965 - val_loss: 0.0762 - val_accuracy: 0.9918\n",
      "Epoch 1911/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1250 - val_accuracy: 0.9831\n",
      "Epoch 1912/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0662 - val_accuracy: 0.9918\n",
      "Epoch 1913/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0767 - val_accuracy: 0.9887\n",
      "Epoch 1914/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0689 - val_accuracy: 0.9913\n",
      "Epoch 1915/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0661 - val_accuracy: 0.9918\n",
      "Epoch 1916/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0778 - val_accuracy: 0.9897\n",
      "Epoch 1917/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0784 - val_accuracy: 0.9913\n",
      "Epoch 1918/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0067 - accuracy: 0.9971 - val_loss: 0.0742 - val_accuracy: 0.9918\n",
      "Epoch 1919/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.0715 - val_accuracy: 0.9938\n",
      "Epoch 1920/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.0890 - val_accuracy: 0.9882\n",
      "Epoch 1921/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0660 - val_accuracy: 0.9913\n",
      "Epoch 1922/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0709 - val_accuracy: 0.9923\n",
      "Epoch 1923/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0707 - val_accuracy: 0.9928\n",
      "Epoch 1924/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0709 - val_accuracy: 0.9903\n",
      "Epoch 1925/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0693 - val_accuracy: 0.9918\n",
      "Epoch 1926/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0861 - val_accuracy: 0.9892\n",
      "Epoch 1927/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0728 - val_accuracy: 0.9918\n",
      "Epoch 1928/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0773 - val_accuracy: 0.9913\n",
      "Epoch 1929/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0138 - accuracy: 0.9943 - val_loss: 0.0770 - val_accuracy: 0.9877\n",
      "Epoch 1930/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.1002 - val_accuracy: 0.9862\n",
      "Epoch 1931/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.1789 - val_accuracy: 0.9728\n",
      "Epoch 1932/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0316 - accuracy: 0.9914 - val_loss: 0.0861 - val_accuracy: 0.9851\n",
      "Epoch 1933/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0995 - val_accuracy: 0.9872\n",
      "Epoch 1934/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0652 - val_accuracy: 0.9913\n",
      "Epoch 1935/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0724 - val_accuracy: 0.9918\n",
      "Epoch 1936/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0833 - val_accuracy: 0.9892\n",
      "Epoch 1937/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0763 - val_accuracy: 0.9913\n",
      "Epoch 1938/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0711 - val_accuracy: 0.9908\n",
      "Epoch 1939/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0689 - val_accuracy: 0.9928\n",
      "Epoch 1940/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0715 - val_accuracy: 0.9918\n",
      "Epoch 1941/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0841 - val_accuracy: 0.9882\n",
      "Epoch 1942/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.0790 - val_accuracy: 0.9908\n",
      "Epoch 1943/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0749 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1944/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0681 - val_accuracy: 0.9918\n",
      "Epoch 1945/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0698 - val_accuracy: 0.9923\n",
      "Epoch 1946/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0833 - val_accuracy: 0.9913\n",
      "Epoch 1947/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0881 - val_accuracy: 0.9872\n",
      "Epoch 1948/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0974 - val_accuracy: 0.9846\n",
      "Epoch 1949/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0859 - val_accuracy: 0.9892\n",
      "Epoch 1950/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.0745 - val_accuracy: 0.9918\n",
      "Epoch 1951/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0783 - val_accuracy: 0.9897\n",
      "Epoch 1952/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1090 - val_accuracy: 0.9841\n",
      "Epoch 1953/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0797 - val_accuracy: 0.9897\n",
      "Epoch 1954/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0754 - val_accuracy: 0.9903\n",
      "Epoch 1955/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0773 - val_accuracy: 0.9918\n",
      "Epoch 1956/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.0732 - val_accuracy: 0.9923\n",
      "Epoch 1957/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0725 - val_accuracy: 0.9913\n",
      "Epoch 1958/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0772 - val_accuracy: 0.9913\n",
      "Epoch 1959/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0742 - val_accuracy: 0.9913\n",
      "Epoch 1960/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0924 - val_accuracy: 0.9867\n",
      "Epoch 1961/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0788 - val_accuracy: 0.9918\n",
      "Epoch 1962/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0780 - val_accuracy: 0.9908\n",
      "Epoch 1963/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0775 - val_accuracy: 0.9897\n",
      "Epoch 1964/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0782 - val_accuracy: 0.9872\n",
      "Epoch 1965/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0700 - val_accuracy: 0.9913\n",
      "Epoch 1966/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0950 - val_accuracy: 0.9887\n",
      "Epoch 1967/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0846 - val_accuracy: 0.9887\n",
      "Epoch 1968/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0723 - val_accuracy: 0.9897\n",
      "Epoch 1969/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0091 - accuracy: 0.9965 - val_loss: 0.0691 - val_accuracy: 0.9918\n",
      "Epoch 1970/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0818 - val_accuracy: 0.9892\n",
      "Epoch 1971/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0680 - val_accuracy: 0.9918\n",
      "Epoch 1972/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0750 - val_accuracy: 0.9923\n",
      "Epoch 1973/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0728 - val_accuracy: 0.9913\n",
      "Epoch 1974/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0742 - val_accuracy: 0.9913\n",
      "Epoch 1975/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0745 - val_accuracy: 0.9913\n",
      "Epoch 1976/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0716 - val_accuracy: 0.9923\n",
      "Epoch 1977/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.0738 - val_accuracy: 0.9908\n",
      "Epoch 1978/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0941 - val_accuracy: 0.9856\n",
      "Epoch 1979/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0518 - accuracy: 0.9890 - val_loss: 0.0529 - val_accuracy: 0.9928\n",
      "Epoch 1980/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0790 - val_accuracy: 0.9887\n",
      "Epoch 1981/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0668 - val_accuracy: 0.9918\n",
      "Epoch 1982/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0759 - val_accuracy: 0.9862\n",
      "Epoch 1983/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0797 - val_accuracy: 0.9897\n",
      "Epoch 1984/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0740 - val_accuracy: 0.9918\n",
      "Epoch 1985/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0803 - val_accuracy: 0.9903\n",
      "Epoch 1986/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0725 - val_accuracy: 0.9928\n",
      "Epoch 1987/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.0842 - val_accuracy: 0.9892\n",
      "Epoch 1988/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0716 - val_accuracy: 0.9928\n",
      "Epoch 1989/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0717 - val_accuracy: 0.9923\n",
      "Epoch 1990/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0774 - val_accuracy: 0.9908\n",
      "Epoch 1991/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1090 - val_accuracy: 0.9821\n",
      "Epoch 1992/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0620 - val_accuracy: 0.9918\n",
      "Epoch 1993/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0956 - val_accuracy: 0.9846\n",
      "Epoch 1994/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0837 - val_accuracy: 0.9897\n",
      "Epoch 1995/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.0904 - val_accuracy: 0.9877\n",
      "Epoch 1996/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0819 - val_accuracy: 0.9892\n",
      "Epoch 1997/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0762 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1998/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0738 - val_accuracy: 0.9897\n",
      "Epoch 1999/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0773 - val_accuracy: 0.9903\n",
      "Epoch 2000/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0765 - val_accuracy: 0.9908\n",
      "Epoch 2001/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0775 - val_accuracy: 0.9892\n",
      "Epoch 2002/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9913\n",
      "Epoch 2003/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9913\n",
      "Epoch 2004/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9892\n",
      "Epoch 2005/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0778 - val_accuracy: 0.9887\n",
      "Epoch 2006/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9980 - val_loss: 0.0685 - val_accuracy: 0.9918\n",
      "Epoch 2007/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0702 - val_accuracy: 0.9903\n",
      "Epoch 2008/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0778 - val_accuracy: 0.9882\n",
      "Epoch 2009/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0741 - val_accuracy: 0.9892\n",
      "Epoch 2010/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0730 - val_accuracy: 0.9923\n",
      "Epoch 2011/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0801 - val_accuracy: 0.9867\n",
      "Epoch 2012/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0141 - accuracy: 0.9938 - val_loss: 0.0835 - val_accuracy: 0.9903\n",
      "Epoch 2013/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9956 - val_loss: 0.0642 - val_accuracy: 0.9923\n",
      "Epoch 2014/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0878 - val_accuracy: 0.9887\n",
      "Epoch 2015/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0755 - val_accuracy: 0.9903\n",
      "Epoch 2016/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0740 - val_accuracy: 0.9913\n",
      "Epoch 2017/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9903\n",
      "Epoch 2018/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0703 - val_accuracy: 0.9903\n",
      "Epoch 2019/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0772 - val_accuracy: 0.9892\n",
      "Epoch 2020/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0712 - val_accuracy: 0.9918\n",
      "Epoch 2021/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0735 - val_accuracy: 0.9903\n",
      "Epoch 2022/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0739 - val_accuracy: 0.9908\n",
      "Epoch 2023/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0790 - val_accuracy: 0.9913\n",
      "Epoch 2024/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0776 - val_accuracy: 0.9913\n",
      "Epoch 2025/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0855 - val_accuracy: 0.9887\n",
      "Epoch 2026/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0762 - val_accuracy: 0.9913\n",
      "Epoch 2027/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0174 - accuracy: 0.9934 - val_loss: 0.0845 - val_accuracy: 0.9892\n",
      "Epoch 2028/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0829 - val_accuracy: 0.9882\n",
      "Epoch 2029/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0854 - val_accuracy: 0.9892\n",
      "Epoch 2030/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0713 - val_accuracy: 0.9908\n",
      "Epoch 2031/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0761 - val_accuracy: 0.9908\n",
      "Epoch 2032/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0837 - val_accuracy: 0.9887\n",
      "Epoch 2033/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0709 - val_accuracy: 0.9913\n",
      "Epoch 2034/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0750 - val_accuracy: 0.9913\n",
      "Epoch 2035/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0779 - val_accuracy: 0.9913\n",
      "Epoch 2036/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0997 - val_accuracy: 0.9862\n",
      "Epoch 2037/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0831 - val_accuracy: 0.9897\n",
      "Epoch 2038/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0905 - val_accuracy: 0.9887\n",
      "Epoch 2039/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0829 - val_accuracy: 0.9892\n",
      "Epoch 2040/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0778 - val_accuracy: 0.9897\n",
      "Epoch 2041/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0733 - val_accuracy: 0.9923\n",
      "Epoch 2042/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0713 - val_accuracy: 0.9908\n",
      "Epoch 2043/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0891 - val_accuracy: 0.9877\n",
      "Epoch 2044/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0720 - val_accuracy: 0.9918\n",
      "Epoch 2045/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.0879 - val_accuracy: 0.9882\n",
      "Epoch 2046/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0854 - val_accuracy: 0.9897\n",
      "Epoch 2047/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0735 - val_accuracy: 0.9918\n",
      "Epoch 2048/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0703 - val_accuracy: 0.9908\n",
      "Epoch 2049/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0802 - val_accuracy: 0.9897\n",
      "Epoch 2050/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0796 - val_accuracy: 0.9908\n",
      "Epoch 2051/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0741 - val_accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2052/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0726 - val_accuracy: 0.9913\n",
      "Epoch 2053/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0710 - val_accuracy: 0.9908\n",
      "Epoch 2054/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0777 - val_accuracy: 0.9897\n",
      "Epoch 2055/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0708 - val_accuracy: 0.9918\n",
      "Epoch 2056/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.0755 - val_accuracy: 0.9923\n",
      "Epoch 2057/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0935 - val_accuracy: 0.9862\n",
      "Epoch 2058/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0979 - val_accuracy: 0.9877\n",
      "Epoch 2059/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0792 - val_accuracy: 0.9877\n",
      "Epoch 2060/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0668 - val_accuracy: 0.9918\n",
      "Epoch 2061/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0733 - val_accuracy: 0.9913\n",
      "Epoch 2062/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.0805 - val_accuracy: 0.9913\n",
      "Epoch 2063/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0881 - val_accuracy: 0.9872\n",
      "Epoch 2064/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0726 - val_accuracy: 0.9913\n",
      "Epoch 2065/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0722 - val_accuracy: 0.9918\n",
      "Epoch 2066/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0738 - val_accuracy: 0.9923\n",
      "Epoch 2067/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0899 - val_accuracy: 0.9897\n",
      "Epoch 2068/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0729 - val_accuracy: 0.9903\n",
      "Epoch 2069/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0745 - val_accuracy: 0.9913\n",
      "Epoch 2070/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0721 - val_accuracy: 0.9903\n",
      "Epoch 2071/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0827 - val_accuracy: 0.9897\n",
      "Epoch 2072/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0916 - val_accuracy: 0.9867\n",
      "Epoch 2073/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0737 - val_accuracy: 0.9913\n",
      "Epoch 2074/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.0765 - val_accuracy: 0.9897\n",
      "Epoch 2075/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.1104 - val_accuracy: 0.9851\n",
      "Epoch 2076/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.99 - 0s 27us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0701 - val_accuracy: 0.9913\n",
      "Epoch 2077/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0837 - val_accuracy: 0.9887\n",
      "Epoch 2078/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0791 - val_accuracy: 0.9908\n",
      "Epoch 2079/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 0.9978 - val_loss: 0.0732 - val_accuracy: 0.9908\n",
      "Epoch 2080/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0797 - val_accuracy: 0.9903\n",
      "Epoch 2081/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0975 - val_accuracy: 0.9851\n",
      "Epoch 2082/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1020 - val_accuracy: 0.9882\n",
      "Epoch 2083/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0678 - val_accuracy: 0.9923\n",
      "Epoch 2084/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0699 - val_accuracy: 0.9908\n",
      "Epoch 2085/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9892\n",
      "Epoch 2086/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0704 - val_accuracy: 0.9918\n",
      "Epoch 2087/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0726 - val_accuracy: 0.9918\n",
      "Epoch 2088/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0715 - val_accuracy: 0.9913\n",
      "Epoch 2089/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0911 - val_accuracy: 0.9887\n",
      "Epoch 2090/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0787 - val_accuracy: 0.9903\n",
      "Epoch 2091/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0787 - val_accuracy: 0.9913\n",
      "Epoch 2092/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0732 - val_accuracy: 0.9897\n",
      "Epoch 2093/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.1068 - val_accuracy: 0.9872\n",
      "Epoch 2094/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0738 - val_accuracy: 0.9913\n",
      "Epoch 2095/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0809 - val_accuracy: 0.9918\n",
      "Epoch 2096/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0744 - val_accuracy: 0.9903\n",
      "Epoch 2097/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0770 - val_accuracy: 0.9918\n",
      "Epoch 2098/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0718 - val_accuracy: 0.9923\n",
      "Epoch 2099/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0789 - val_accuracy: 0.9913\n",
      "Epoch 2100/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0851 - val_accuracy: 0.9918\n",
      "Epoch 2101/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0806 - val_accuracy: 0.9913\n",
      "Epoch 2102/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.0737 - val_accuracy: 0.9923\n",
      "Epoch 2103/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.0796 - val_accuracy: 0.9892\n",
      "Epoch 2104/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0866 - val_accuracy: 0.9856\n",
      "Epoch 2105/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0912 - val_accuracy: 0.9877\n",
      "Epoch 2106/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0745 - val_accuracy: 0.9897\n",
      "Epoch 2107/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0763 - val_accuracy: 0.9928\n",
      "Epoch 2108/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0832 - val_accuracy: 0.9897\n",
      "Epoch 2109/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0758 - val_accuracy: 0.9908\n",
      "Epoch 2110/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0858 - val_accuracy: 0.9887\n",
      "Epoch 2111/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0809 - val_accuracy: 0.9897\n",
      "Epoch 2112/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0778 - val_accuracy: 0.9887\n",
      "Epoch 2113/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.1001 - val_accuracy: 0.9862\n",
      "Epoch 2114/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0724 - val_accuracy: 0.9913\n",
      "Epoch 2115/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0758 - val_accuracy: 0.9908\n",
      "Epoch 2116/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0700 - val_accuracy: 0.9923\n",
      "Epoch 2117/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0901 - val_accuracy: 0.9877\n",
      "Epoch 2118/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0763 - val_accuracy: 0.9908\n",
      "Epoch 2119/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0758 - val_accuracy: 0.9918\n",
      "Epoch 2120/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0782 - val_accuracy: 0.9913\n",
      "Epoch 2121/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0715 - val_accuracy: 0.9923\n",
      "Epoch 2122/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0730 - val_accuracy: 0.9923\n",
      "Epoch 2123/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0810 - val_accuracy: 0.9913\n",
      "Epoch 2124/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.0774 - val_accuracy: 0.9897\n",
      "Epoch 2125/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0897 - val_accuracy: 0.9877\n",
      "Epoch 2126/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0758 - val_accuracy: 0.9908\n",
      "Epoch 2127/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0781 - val_accuracy: 0.9908\n",
      "Epoch 2128/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.0757 - val_accuracy: 0.9918\n",
      "Epoch 2129/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0829 - val_accuracy: 0.9903\n",
      "Epoch 2130/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.0708 - val_accuracy: 0.9923\n",
      "Epoch 2131/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0753 - val_accuracy: 0.9913\n",
      "Epoch 2132/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0761 - val_accuracy: 0.9908\n",
      "Epoch 2133/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0755 - val_accuracy: 0.9913\n",
      "Epoch 2134/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.0769 - val_accuracy: 0.9913\n",
      "Epoch 2135/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0760 - val_accuracy: 0.9913\n",
      "Epoch 2136/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0691 - val_accuracy: 0.9913\n",
      "Epoch 2137/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0801 - val_accuracy: 0.9892\n",
      "Epoch 2138/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0745 - val_accuracy: 0.9918\n",
      "Epoch 2139/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0744 - val_accuracy: 0.9913\n",
      "Epoch 2140/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0768 - val_accuracy: 0.9908\n",
      "Epoch 2141/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0884 - val_accuracy: 0.9897\n",
      "Epoch 2142/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.0694 - val_accuracy: 0.9908\n",
      "Epoch 2143/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0716 - val_accuracy: 0.9923\n",
      "Epoch 2144/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0845 - val_accuracy: 0.9887\n",
      "Epoch 2145/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0693 - val_accuracy: 0.9903\n",
      "Epoch 2146/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0673 - val_accuracy: 0.9903\n",
      "Epoch 2147/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0689 - val_accuracy: 0.9923\n",
      "Epoch 2148/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0957 - val_accuracy: 0.9877\n",
      "Epoch 2149/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.0903 - val_accuracy: 0.9882\n",
      "Epoch 2150/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0741 - val_accuracy: 0.9903\n",
      "Epoch 2151/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0858 - val_accuracy: 0.9897\n",
      "Epoch 2152/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0783 - val_accuracy: 0.9913\n",
      "Epoch 2153/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0784 - val_accuracy: 0.9903\n",
      "Epoch 2154/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0805 - val_accuracy: 0.9897\n",
      "Epoch 2155/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0749 - val_accuracy: 0.9908\n",
      "Epoch 2156/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0664 - val_accuracy: 0.9923\n",
      "Epoch 2157/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.0799 - val_accuracy: 0.9923\n",
      "Epoch 2158/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0777 - val_accuracy: 0.9928\n",
      "Epoch 2159/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0705 - val_accuracy: 0.9918\n",
      "Epoch 2160/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0865 - val_accuracy: 0.9877\n",
      "Epoch 2161/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0772 - val_accuracy: 0.9903\n",
      "Epoch 2162/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0783 - val_accuracy: 0.9913\n",
      "Epoch 2163/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0707 - val_accuracy: 0.9903\n",
      "Epoch 2164/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.0813 - val_accuracy: 0.9903\n",
      "Epoch 2165/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0817 - val_accuracy: 0.9903\n",
      "Epoch 2166/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0917 - val_accuracy: 0.9862\n",
      "Epoch 2167/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0668 - val_accuracy: 0.9913\n",
      "Epoch 2168/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1126 - val_accuracy: 0.9826\n",
      "Epoch 2169/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0768 - val_accuracy: 0.9918\n",
      "Epoch 2170/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0847 - val_accuracy: 0.9877\n",
      "Epoch 2171/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0731 - val_accuracy: 0.9918\n",
      "Epoch 2172/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0752 - val_accuracy: 0.9897\n",
      "Epoch 2173/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0754 - val_accuracy: 0.9897\n",
      "Epoch 2174/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0879 - val_accuracy: 0.9897\n",
      "Epoch 2175/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0291 - accuracy: 0.9914 - val_loss: 0.0929 - val_accuracy: 0.9851\n",
      "Epoch 2176/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0766 - val_accuracy: 0.9887\n",
      "Epoch 2177/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0720 - val_accuracy: 0.9903\n",
      "Epoch 2178/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.0727 - val_accuracy: 0.9903\n",
      "Epoch 2179/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0740 - val_accuracy: 0.9908\n",
      "Epoch 2180/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0713 - val_accuracy: 0.9913\n",
      "Epoch 2181/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0726 - val_accuracy: 0.9913\n",
      "Epoch 2182/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0746 - val_accuracy: 0.9913\n",
      "Epoch 2183/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0729 - val_accuracy: 0.9908\n",
      "Epoch 2184/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0749 - val_accuracy: 0.9923\n",
      "Epoch 2185/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.0751 - val_accuracy: 0.9908\n",
      "Epoch 2186/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0674 - val_accuracy: 0.9897\n",
      "Epoch 2187/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0723 - val_accuracy: 0.9903\n",
      "Epoch 2188/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1116 - val_accuracy: 0.9856\n",
      "Epoch 2189/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0730 - val_accuracy: 0.9913\n",
      "Epoch 2190/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0735 - val_accuracy: 0.9918\n",
      "Epoch 2191/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0762 - val_accuracy: 0.9913\n",
      "Epoch 2192/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0705 - val_accuracy: 0.9923\n",
      "Epoch 2193/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0759 - val_accuracy: 0.9913\n",
      "Epoch 2194/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0760 - val_accuracy: 0.9903\n",
      "Epoch 2195/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0821 - val_accuracy: 0.9892\n",
      "Epoch 2196/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0884 - val_accuracy: 0.9892\n",
      "Epoch 2197/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0743 - val_accuracy: 0.9903\n",
      "Epoch 2198/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0872 - val_accuracy: 0.9892\n",
      "Epoch 2199/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0770 - val_accuracy: 0.9908\n",
      "Epoch 2200/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0800 - val_accuracy: 0.9887\n",
      "Epoch 2201/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9908\n",
      "Epoch 2202/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0793 - val_accuracy: 0.9887\n",
      "Epoch 2203/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0871 - val_accuracy: 0.9913\n",
      "Epoch 2204/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0832 - val_accuracy: 0.9877\n",
      "Epoch 2205/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0067 - accuracy: 0.9971 - val_loss: 0.0813 - val_accuracy: 0.9903\n",
      "Epoch 2206/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0804 - val_accuracy: 0.9903\n",
      "Epoch 2207/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0693 - val_accuracy: 0.9913\n",
      "Epoch 2208/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0793 - val_accuracy: 0.9892\n",
      "Epoch 2209/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0862 - val_accuracy: 0.9887\n",
      "Epoch 2210/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0803 - val_accuracy: 0.9903\n",
      "Epoch 2211/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0750 - val_accuracy: 0.9918\n",
      "Epoch 2212/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0843 - val_accuracy: 0.9872\n",
      "Epoch 2213/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0842 - val_accuracy: 0.9897\n",
      "Epoch 2214/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0740 - val_accuracy: 0.9908\n",
      "Epoch 2215/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0754 - val_accuracy: 0.9908\n",
      "Epoch 2216/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.0829 - val_accuracy: 0.9892\n",
      "Epoch 2217/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.0831 - val_accuracy: 0.9872\n",
      "Epoch 2218/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0812 - val_accuracy: 0.9903\n",
      "Epoch 2219/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0719 - val_accuracy: 0.9913\n",
      "Epoch 2220/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0771 - val_accuracy: 0.9892\n",
      "Epoch 2221/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0839 - val_accuracy: 0.9897\n",
      "Epoch 2222/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0771 - val_accuracy: 0.9913\n",
      "Epoch 2223/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0808 - val_accuracy: 0.9903\n",
      "Epoch 2224/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0757 - val_accuracy: 0.9913\n",
      "Epoch 2225/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0735 - val_accuracy: 0.9913\n",
      "Epoch 2226/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1049 - val_accuracy: 0.9841\n",
      "Epoch 2227/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0889 - val_accuracy: 0.9882\n",
      "Epoch 2228/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1032 - val_accuracy: 0.9867\n",
      "Epoch 2229/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.1442 - val_accuracy: 0.9805\n",
      "Epoch 2230/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.0948 - val_accuracy: 0.9908\n",
      "Epoch 2231/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.0771 - val_accuracy: 0.9913\n",
      "Epoch 2232/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0737 - val_accuracy: 0.9908\n",
      "Epoch 2233/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0822 - val_accuracy: 0.9892\n",
      "Epoch 2234/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0973 - val_accuracy: 0.9872\n",
      "Epoch 2235/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0790 - val_accuracy: 0.9908\n",
      "Epoch 2236/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0690 - val_accuracy: 0.9918\n",
      "Epoch 2237/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0833 - val_accuracy: 0.9908\n",
      "Epoch 2238/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0703 - val_accuracy: 0.9918\n",
      "Epoch 2239/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0787 - val_accuracy: 0.9882\n",
      "Epoch 2240/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0746 - val_accuracy: 0.9913\n",
      "Epoch 2241/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0778 - val_accuracy: 0.9892\n",
      "Epoch 2242/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0851 - val_accuracy: 0.9887\n",
      "Epoch 2243/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0787 - val_accuracy: 0.9897\n",
      "Epoch 2244/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9971 - val_loss: 0.0821 - val_accuracy: 0.9903\n",
      "Epoch 2245/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.1020 - val_accuracy: 0.9877\n",
      "Epoch 2246/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.0762 - val_accuracy: 0.9908\n",
      "Epoch 2247/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0731 - val_accuracy: 0.9913\n",
      "Epoch 2248/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0777 - val_accuracy: 0.9903\n",
      "Epoch 2249/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0802 - val_accuracy: 0.9897\n",
      "Epoch 2250/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0856 - val_accuracy: 0.9908\n",
      "Epoch 2251/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0868 - val_accuracy: 0.9897\n",
      "Epoch 2252/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0809 - val_accuracy: 0.9908\n",
      "Epoch 2253/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0915 - val_accuracy: 0.9892\n",
      "Epoch 2254/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0954 - val_accuracy: 0.9877\n",
      "Epoch 2255/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0959 - val_accuracy: 0.9872\n",
      "Epoch 2256/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0722 - val_accuracy: 0.9918\n",
      "Epoch 2257/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0795 - val_accuracy: 0.9918\n",
      "Epoch 2258/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1253 - val_accuracy: 0.9800\n",
      "Epoch 2259/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.0859 - val_accuracy: 0.9908\n",
      "Epoch 2260/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0745 - val_accuracy: 0.9913\n",
      "Epoch 2261/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.1019 - val_accuracy: 0.9867\n",
      "Epoch 2262/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0778 - val_accuracy: 0.9897\n",
      "Epoch 2263/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0913 - val_accuracy: 0.9892\n",
      "Epoch 2264/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0753 - val_accuracy: 0.9918\n",
      "Epoch 2265/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.1019 - val_accuracy: 0.9862\n",
      "Epoch 2266/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.0878 - val_accuracy: 0.9897\n",
      "Epoch 2267/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0732 - val_accuracy: 0.9918\n",
      "Epoch 2268/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0857 - val_accuracy: 0.9908\n",
      "Epoch 2269/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0734 - val_accuracy: 0.9913\n",
      "Epoch 2270/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0800 - val_accuracy: 0.9918\n",
      "Epoch 2271/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0836 - val_accuracy: 0.9903\n",
      "Epoch 2272/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0791 - val_accuracy: 0.9908\n",
      "Epoch 2273/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0791 - val_accuracy: 0.9903\n",
      "Epoch 2274/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0747 - val_accuracy: 0.9897\n",
      "Epoch 2275/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0705 - val_accuracy: 0.9892\n",
      "Epoch 2276/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0817 - val_accuracy: 0.9897\n",
      "Epoch 2277/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.0801 - val_accuracy: 0.9918\n",
      "Epoch 2278/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9971 - val_loss: 0.0889 - val_accuracy: 0.9856\n",
      "Epoch 2279/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0789 - val_accuracy: 0.9903\n",
      "Epoch 2280/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0998 - val_accuracy: 0.9851\n",
      "Epoch 2281/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0834 - val_accuracy: 0.9908\n",
      "Epoch 2282/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0808 - val_accuracy: 0.9913\n",
      "Epoch 2283/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0079 - accuracy: 0.9967 - val_loss: 0.0852 - val_accuracy: 0.9903\n",
      "Epoch 2284/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0769 - val_accuracy: 0.9918\n",
      "Epoch 2285/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0740 - val_accuracy: 0.9913\n",
      "Epoch 2286/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0833 - val_accuracy: 0.9913\n",
      "Epoch 2287/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0798 - val_accuracy: 0.9913\n",
      "Epoch 2288/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0788 - val_accuracy: 0.9918\n",
      "Epoch 2289/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0786 - val_accuracy: 0.9908\n",
      "Epoch 2290/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0792 - val_accuracy: 0.9913\n",
      "Epoch 2291/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0779 - val_accuracy: 0.9913\n",
      "Epoch 2292/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1247 - val_accuracy: 0.9831\n",
      "Epoch 2293/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0594 - accuracy: 0.9842 - val_loss: 0.1296 - val_accuracy: 0.9815\n",
      "Epoch 2294/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.0981 - val_accuracy: 0.9856\n",
      "Epoch 2295/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0783 - val_accuracy: 0.9892\n",
      "Epoch 2296/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0766 - val_accuracy: 0.9918\n",
      "Epoch 2297/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0796 - val_accuracy: 0.9908\n",
      "Epoch 2298/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0712 - val_accuracy: 0.9923\n",
      "Epoch 2299/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0738 - val_accuracy: 0.9903\n",
      "Epoch 2300/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.0896 - val_accuracy: 0.9887\n",
      "Epoch 2301/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0848 - val_accuracy: 0.9897\n",
      "Epoch 2302/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0756 - val_accuracy: 0.9928\n",
      "Epoch 2303/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0749 - val_accuracy: 0.9908\n",
      "Epoch 2304/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0788 - val_accuracy: 0.9908\n",
      "Epoch 2305/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0782 - val_accuracy: 0.9918\n",
      "Epoch 2306/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0841 - val_accuracy: 0.9892\n",
      "Epoch 2307/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0728 - val_accuracy: 0.9918\n",
      "Epoch 2308/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0782 - val_accuracy: 0.9918\n",
      "Epoch 2309/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0878 - val_accuracy: 0.9887\n",
      "Epoch 2310/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0714 - val_accuracy: 0.9913\n",
      "Epoch 2311/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9969 - val_loss: 0.0784 - val_accuracy: 0.9903\n",
      "Epoch 2312/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0928 - val_accuracy: 0.9882\n",
      "Epoch 2313/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.0796 - val_accuracy: 0.9908\n",
      "Epoch 2314/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0754 - val_accuracy: 0.9923\n",
      "Epoch 2315/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0772 - val_accuracy: 0.9897\n",
      "Epoch 2316/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0749 - val_accuracy: 0.9908\n",
      "Epoch 2317/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0796 - val_accuracy: 0.9903\n",
      "Epoch 2318/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9908\n",
      "Epoch 2319/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0803 - val_accuracy: 0.9913\n",
      "Epoch 2320/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0847 - val_accuracy: 0.9892\n",
      "Epoch 2321/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0895 - val_accuracy: 0.9892\n",
      "Epoch 2322/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0796 - val_accuracy: 0.9903\n",
      "Epoch 2323/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0945 - val_accuracy: 0.9882\n",
      "Epoch 2324/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.0914 - val_accuracy: 0.9887\n",
      "Epoch 2325/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0789 - val_accuracy: 0.9908\n",
      "Epoch 2326/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0797 - val_accuracy: 0.9913\n",
      "Epoch 2327/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0748 - val_accuracy: 0.9913\n",
      "Epoch 2328/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0745 - val_accuracy: 0.9918\n",
      "Epoch 2329/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.0808 - val_accuracy: 0.9913\n",
      "Epoch 2330/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0755 - val_accuracy: 0.9918\n",
      "Epoch 2331/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0774 - val_accuracy: 0.9897\n",
      "Epoch 2332/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0746 - val_accuracy: 0.9928\n",
      "Epoch 2333/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0745 - val_accuracy: 0.9923\n",
      "Epoch 2334/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0774 - val_accuracy: 0.9908\n",
      "Epoch 2335/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0850 - val_accuracy: 0.9908\n",
      "Epoch 2336/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0766 - val_accuracy: 0.9913\n",
      "Epoch 2337/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0967 - val_accuracy: 0.9882\n",
      "Epoch 2338/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0900 - val_accuracy: 0.9877\n",
      "Epoch 2339/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0790 - val_accuracy: 0.9908\n",
      "Epoch 2340/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0795 - val_accuracy: 0.9908\n",
      "Epoch 2341/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0747 - val_accuracy: 0.9918\n",
      "Epoch 2342/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0750 - val_accuracy: 0.9918\n",
      "Epoch 2343/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0801 - val_accuracy: 0.9913\n",
      "Epoch 2344/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1020 - val_accuracy: 0.9821\n",
      "Epoch 2345/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.1114 - val_accuracy: 0.9882\n",
      "Epoch 2346/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0896 - val_accuracy: 0.9897\n",
      "Epoch 2347/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9954 - val_loss: 0.0899 - val_accuracy: 0.9887\n",
      "Epoch 2348/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0834 - val_accuracy: 0.9918\n",
      "Epoch 2349/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0825 - val_accuracy: 0.9913\n",
      "Epoch 2350/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0890 - val_accuracy: 0.9913\n",
      "Epoch 2351/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0961 - val_accuracy: 0.9887\n",
      "Epoch 2352/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0869 - val_accuracy: 0.9882\n",
      "Epoch 2353/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0992 - val_accuracy: 0.9882\n",
      "Epoch 2354/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.0790 - val_accuracy: 0.9913\n",
      "Epoch 2355/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0856 - val_accuracy: 0.9903\n",
      "Epoch 2356/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0880 - val_accuracy: 0.9903\n",
      "Epoch 2357/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0920 - val_accuracy: 0.9892\n",
      "Epoch 2358/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.0986 - val_accuracy: 0.9867\n",
      "Epoch 2359/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0901 - val_accuracy: 0.9903\n",
      "Epoch 2360/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0781 - val_accuracy: 0.9913\n",
      "Epoch 2361/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0940 - val_accuracy: 0.9887\n",
      "Epoch 2362/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0905 - val_accuracy: 0.9867\n",
      "Epoch 2363/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.0890 - val_accuracy: 0.9892\n",
      "Epoch 2364/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1011 - val_accuracy: 0.9856\n",
      "Epoch 2365/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0930 - val_accuracy: 0.9882\n",
      "Epoch 2366/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0869 - val_accuracy: 0.9908\n",
      "Epoch 2367/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0870 - val_accuracy: 0.9897\n",
      "Epoch 2368/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0865 - val_accuracy: 0.9908\n",
      "Epoch 2369/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1013 - val_accuracy: 0.9862\n",
      "Epoch 2370/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0821 - val_accuracy: 0.9913\n",
      "Epoch 2371/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0818 - val_accuracy: 0.9913\n",
      "Epoch 2372/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0844 - val_accuracy: 0.9897\n",
      "Epoch 2373/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0788 - val_accuracy: 0.9913\n",
      "Epoch 2374/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0947 - val_accuracy: 0.9867\n",
      "Epoch 2375/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0178 - accuracy: 0.9936 - val_loss: 0.0878 - val_accuracy: 0.9877\n",
      "Epoch 2376/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0786 - val_accuracy: 0.9908\n",
      "Epoch 2377/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.0920 - val_accuracy: 0.9887\n",
      "Epoch 2378/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0947 - val_accuracy: 0.9877\n",
      "Epoch 2379/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0848 - val_accuracy: 0.9903\n",
      "Epoch 2380/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0769 - val_accuracy: 0.9918\n",
      "Epoch 2381/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0761 - val_accuracy: 0.9913\n",
      "Epoch 2382/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0786 - val_accuracy: 0.9918\n",
      "Epoch 2383/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0757 - val_accuracy: 0.9903\n",
      "Epoch 2384/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0734 - val_accuracy: 0.9923\n",
      "Epoch 2385/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.0785 - val_accuracy: 0.9923\n",
      "Epoch 2386/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0785 - val_accuracy: 0.9913\n",
      "Epoch 2387/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0899 - val_accuracy: 0.9877\n",
      "Epoch 2388/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0793 - val_accuracy: 0.9918\n",
      "Epoch 2389/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0860 - val_accuracy: 0.9897\n",
      "Epoch 2390/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0794 - val_accuracy: 0.9908\n",
      "Epoch 2391/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1047 - val_accuracy: 0.9867\n",
      "Epoch 2392/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0920 - val_accuracy: 0.9887\n",
      "Epoch 2393/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0809 - val_accuracy: 0.9903\n",
      "Epoch 2394/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.0800 - val_accuracy: 0.9897\n",
      "Epoch 2395/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0851 - val_accuracy: 0.9892\n",
      "Epoch 2396/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0770 - val_accuracy: 0.9903\n",
      "Epoch 2397/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.0806 - val_accuracy: 0.9908\n",
      "Epoch 2398/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0816 - val_accuracy: 0.9913\n",
      "Epoch 2399/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0746 - val_accuracy: 0.9918\n",
      "Epoch 2400/3000\n",
      "4547/4547 [==============================] - 0s 25us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0795 - val_accuracy: 0.9923\n",
      "Epoch 2401/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0772 - val_accuracy: 0.9913\n",
      "Epoch 2402/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0746 - val_accuracy: 0.9913\n",
      "Epoch 2403/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0743 - val_accuracy: 0.9923\n",
      "Epoch 2404/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0742 - val_accuracy: 0.9918\n",
      "Epoch 2405/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0782 - val_accuracy: 0.9913\n",
      "Epoch 2406/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1073 - val_accuracy: 0.9872\n",
      "Epoch 2407/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0785 - val_accuracy: 0.9903\n",
      "Epoch 2408/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0757 - val_accuracy: 0.9918\n",
      "Epoch 2409/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0831 - val_accuracy: 0.9892\n",
      "Epoch 2410/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0773 - val_accuracy: 0.9908\n",
      "Epoch 2411/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0784 - val_accuracy: 0.9903\n",
      "Epoch 2412/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.0756 - val_accuracy: 0.9928\n",
      "Epoch 2413/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0783 - val_accuracy: 0.9913\n",
      "Epoch 2414/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0714 - val_accuracy: 0.9913\n",
      "Epoch 2415/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0874 - val_accuracy: 0.9892\n",
      "Epoch 2416/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0996 - val_accuracy: 0.9872\n",
      "Epoch 2417/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0999 - val_accuracy: 0.9862\n",
      "Epoch 2418/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1051 - val_accuracy: 0.9856\n",
      "Epoch 2419/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0972 - val_accuracy: 0.9897\n",
      "Epoch 2420/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0965 - val_accuracy: 0.9887\n",
      "Epoch 2421/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0873 - val_accuracy: 0.9897\n",
      "Epoch 2422/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.0740 - val_accuracy: 0.9928\n",
      "Epoch 2423/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1051 - val_accuracy: 0.9877\n",
      "Epoch 2424/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0799 - val_accuracy: 0.9908\n",
      "Epoch 2425/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0696 - val_accuracy: 0.9923\n",
      "Epoch 2426/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0744 - val_accuracy: 0.9913\n",
      "Epoch 2427/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0775 - val_accuracy: 0.9918\n",
      "Epoch 2428/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0787 - val_accuracy: 0.9913\n",
      "Epoch 2429/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0811 - val_accuracy: 0.9903\n",
      "Epoch 2430/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0918 - val_accuracy: 0.9892\n",
      "Epoch 2431/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0065 - accuracy: 0.9971 - val_loss: 0.0878 - val_accuracy: 0.9851\n",
      "Epoch 2432/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0767 - val_accuracy: 0.9897\n",
      "Epoch 2433/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0783 - val_accuracy: 0.9913\n",
      "Epoch 2434/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0205 - accuracy: 0.9952 - val_loss: 0.0664 - val_accuracy: 0.9913\n",
      "Epoch 2435/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0795 - val_accuracy: 0.9903\n",
      "Epoch 2436/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0824 - val_accuracy: 0.9908\n",
      "Epoch 2437/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0905 - val_accuracy: 0.9867\n",
      "Epoch 2438/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0714 - val_accuracy: 0.9918\n",
      "Epoch 2439/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0756 - val_accuracy: 0.9887\n",
      "Epoch 2440/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0774 - val_accuracy: 0.9923\n",
      "Epoch 2441/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0971 - val_accuracy: 0.9882\n",
      "Epoch 2442/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0781 - val_accuracy: 0.9913\n",
      "Epoch 2443/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0780 - val_accuracy: 0.9913\n",
      "Epoch 2444/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0897 - val_accuracy: 0.9887\n",
      "Epoch 2445/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0904 - val_accuracy: 0.9908\n",
      "Epoch 2446/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0771 - val_accuracy: 0.9913\n",
      "Epoch 2447/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0903 - val_accuracy: 0.9908\n",
      "Epoch 2448/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0840 - val_accuracy: 0.9897\n",
      "Epoch 2449/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.0805 - val_accuracy: 0.9908\n",
      "Epoch 2450/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0813 - val_accuracy: 0.9908\n",
      "Epoch 2451/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0897 - val_accuracy: 0.9892\n",
      "Epoch 2452/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0788 - val_accuracy: 0.9908\n",
      "Epoch 2453/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0739 - val_accuracy: 0.9918\n",
      "Epoch 2454/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0791 - val_accuracy: 0.9913\n",
      "Epoch 2455/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0976 - val_accuracy: 0.9851\n",
      "Epoch 2456/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0847 - val_accuracy: 0.9908\n",
      "Epoch 2457/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0825 - val_accuracy: 0.9908\n",
      "Epoch 2458/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0798 - val_accuracy: 0.9918\n",
      "Epoch 2459/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0820 - val_accuracy: 0.9913\n",
      "Epoch 2460/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.0854 - val_accuracy: 0.9897\n",
      "Epoch 2461/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.1069 - val_accuracy: 0.9856\n",
      "Epoch 2462/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0953 - val_accuracy: 0.9872\n",
      "Epoch 2463/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.0884 - val_accuracy: 0.9913\n",
      "Epoch 2464/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.0789 - val_accuracy: 0.9913\n",
      "Epoch 2465/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0962 - val_accuracy: 0.9872\n",
      "Epoch 2466/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.1047 - val_accuracy: 0.9856\n",
      "Epoch 2467/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0891 - val_accuracy: 0.9897\n",
      "Epoch 2468/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0765 - val_accuracy: 0.9903\n",
      "Epoch 2469/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0797 - val_accuracy: 0.9887\n",
      "Epoch 2470/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0911 - val_accuracy: 0.9913\n",
      "Epoch 2471/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.0777 - val_accuracy: 0.9908\n",
      "Epoch 2472/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0851 - val_accuracy: 0.9913\n",
      "Epoch 2473/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.0816 - val_accuracy: 0.9923\n",
      "Epoch 2474/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0832 - val_accuracy: 0.9918\n",
      "Epoch 2475/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1009 - val_accuracy: 0.9887\n",
      "Epoch 2476/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0774 - val_accuracy: 0.9928\n",
      "Epoch 2477/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0770 - val_accuracy: 0.9913\n",
      "Epoch 2478/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.0856 - val_accuracy: 0.9897\n",
      "Epoch 2479/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.0789 - val_accuracy: 0.9918\n",
      "Epoch 2480/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.0851 - val_accuracy: 0.9908\n",
      "Epoch 2481/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0844 - val_accuracy: 0.9913\n",
      "Epoch 2482/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0981 - val_accuracy: 0.9867\n",
      "Epoch 2483/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0760 - val_accuracy: 0.9918\n",
      "Epoch 2484/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0770 - val_accuracy: 0.9913\n",
      "Epoch 2485/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0808 - val_accuracy: 0.9887\n",
      "Epoch 2486/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0789 - val_accuracy: 0.9918\n",
      "Epoch 2487/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0751 - val_accuracy: 0.9923\n",
      "Epoch 2488/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.1083 - val_accuracy: 0.9877\n",
      "Epoch 2489/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.0821 - val_accuracy: 0.9897\n",
      "Epoch 2490/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0883 - val_accuracy: 0.9908\n",
      "Epoch 2491/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0795 - val_accuracy: 0.9913\n",
      "Epoch 2492/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.0755 - val_accuracy: 0.9913\n",
      "Epoch 2493/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1040 - val_accuracy: 0.9862\n",
      "Epoch 2494/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0955 - val_accuracy: 0.9877\n",
      "Epoch 2495/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.0918 - val_accuracy: 0.9892\n",
      "Epoch 2496/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0748 - val_accuracy: 0.9918\n",
      "Epoch 2497/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0791 - val_accuracy: 0.9913\n",
      "Epoch 2498/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.1629 - val_accuracy: 0.9759\n",
      "Epoch 2499/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0867 - accuracy: 0.9802 - val_loss: 0.0934 - val_accuracy: 0.9867\n",
      "Epoch 2500/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0435 - accuracy: 0.9894 - val_loss: 0.0955 - val_accuracy: 0.9872\n",
      "Epoch 2501/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.0757 - val_accuracy: 0.9908\n",
      "Epoch 2502/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0822 - val_accuracy: 0.9903\n",
      "Epoch 2503/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0827 - val_accuracy: 0.9903\n",
      "Epoch 2504/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0844 - val_accuracy: 0.9897\n",
      "Epoch 2505/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0766 - val_accuracy: 0.9908\n",
      "Epoch 2506/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0805 - val_accuracy: 0.9908\n",
      "Epoch 2507/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0865 - val_accuracy: 0.9908\n",
      "Epoch 2508/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0785 - val_accuracy: 0.9903\n",
      "Epoch 2509/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0830 - val_accuracy: 0.9903\n",
      "Epoch 2510/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0776 - val_accuracy: 0.9908\n",
      "Epoch 2511/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0831 - val_accuracy: 0.9908\n",
      "Epoch 2512/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0855 - val_accuracy: 0.9913\n",
      "Epoch 2513/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9903\n",
      "Epoch 2514/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0763 - val_accuracy: 0.9903\n",
      "Epoch 2515/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0784 - val_accuracy: 0.9913\n",
      "Epoch 2516/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9913\n",
      "Epoch 2517/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0829 - val_accuracy: 0.9908\n",
      "Epoch 2518/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0857 - val_accuracy: 0.9908\n",
      "Epoch 2519/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0745 - val_accuracy: 0.9918\n",
      "Epoch 2520/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0834 - val_accuracy: 0.9913\n",
      "Epoch 2521/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0840 - val_accuracy: 0.9908\n",
      "Epoch 2522/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0845 - val_accuracy: 0.9913\n",
      "Epoch 2523/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0751 - val_accuracy: 0.9913\n",
      "Epoch 2524/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0738 - val_accuracy: 0.9918\n",
      "Epoch 2525/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1033 - val_accuracy: 0.9856\n",
      "Epoch 2526/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0814 - val_accuracy: 0.9913\n",
      "Epoch 2527/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.0899 - val_accuracy: 0.9892\n",
      "Epoch 2528/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0746 - val_accuracy: 0.9918\n",
      "Epoch 2529/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0831 - val_accuracy: 0.9867\n",
      "Epoch 2530/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.0971 - val_accuracy: 0.9882\n",
      "Epoch 2531/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.0872 - val_accuracy: 0.9897\n",
      "Epoch 2532/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.0848 - val_accuracy: 0.9897\n",
      "Epoch 2533/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0903 - val_accuracy: 0.9877\n",
      "Epoch 2534/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.0983 - val_accuracy: 0.9862\n",
      "Epoch 2535/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0742 - val_accuracy: 0.9918\n",
      "Epoch 2536/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0814 - val_accuracy: 0.9897\n",
      "Epoch 2537/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0839 - val_accuracy: 0.9908\n",
      "Epoch 2538/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0803 - val_accuracy: 0.9918\n",
      "Epoch 2539/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0796 - val_accuracy: 0.9903\n",
      "Epoch 2540/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0867 - val_accuracy: 0.9892\n",
      "Epoch 2541/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0780 - val_accuracy: 0.9908\n",
      "Epoch 2542/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0758 - val_accuracy: 0.9913\n",
      "Epoch 2543/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0766 - val_accuracy: 0.9897\n",
      "Epoch 2544/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0740 - val_accuracy: 0.9913\n",
      "Epoch 2545/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0776 - val_accuracy: 0.9913\n",
      "Epoch 2546/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0812 - val_accuracy: 0.9908\n",
      "Epoch 2547/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0740 - val_accuracy: 0.9923\n",
      "Epoch 2548/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0813 - val_accuracy: 0.9908\n",
      "Epoch 2549/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0832 - val_accuracy: 0.9908\n",
      "Epoch 2550/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0856 - val_accuracy: 0.9882\n",
      "Epoch 2551/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.0808 - val_accuracy: 0.9892\n",
      "Epoch 2552/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0779 - val_accuracy: 0.9918\n",
      "Epoch 2553/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0811 - val_accuracy: 0.9913\n",
      "Epoch 2554/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0782 - val_accuracy: 0.9913\n",
      "Epoch 2555/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0746 - val_accuracy: 0.9913\n",
      "Epoch 2556/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.0802 - val_accuracy: 0.9862\n",
      "Epoch 2557/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0228 - accuracy: 0.9943 - val_loss: 0.0739 - val_accuracy: 0.9913\n",
      "Epoch 2558/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0813 - val_accuracy: 0.9887\n",
      "Epoch 2559/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0749 - val_accuracy: 0.9918\n",
      "Epoch 2560/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1028 - val_accuracy: 0.9851\n",
      "Epoch 2561/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0818 - val_accuracy: 0.9908\n",
      "Epoch 2562/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0834 - val_accuracy: 0.9887\n",
      "Epoch 2563/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0803 - val_accuracy: 0.9892\n",
      "Epoch 2564/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0910 - val_accuracy: 0.9882\n",
      "Epoch 2565/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0901 - val_accuracy: 0.9882\n",
      "Epoch 2566/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0080 - accuracy: 0.9965 - val_loss: 0.0817 - val_accuracy: 0.9913\n",
      "Epoch 2567/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9960 - val_loss: 0.0849 - val_accuracy: 0.9903\n",
      "Epoch 2568/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.1056 - val_accuracy: 0.9862\n",
      "Epoch 2569/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0781 - val_accuracy: 0.9908\n",
      "Epoch 2570/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0827 - val_accuracy: 0.9908\n",
      "Epoch 2571/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0775 - val_accuracy: 0.9913\n",
      "Epoch 2572/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0798 - val_accuracy: 0.9913\n",
      "Epoch 2573/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0814 - val_accuracy: 0.9908\n",
      "Epoch 2574/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - 0s 27us/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0764 - val_accuracy: 0.9918\n",
      "Epoch 2575/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0836 - val_accuracy: 0.9897\n",
      "Epoch 2576/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0842 - val_accuracy: 0.9903\n",
      "Epoch 2577/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0842 - val_accuracy: 0.9903\n",
      "Epoch 2578/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0836 - val_accuracy: 0.9918\n",
      "Epoch 2579/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0747 - val_accuracy: 0.9918\n",
      "Epoch 2580/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0785 - val_accuracy: 0.9913\n",
      "Epoch 2581/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.0877 - val_accuracy: 0.9877\n",
      "Epoch 2582/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0868 - val_accuracy: 0.9913\n",
      "Epoch 2583/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0749 - val_accuracy: 0.9923\n",
      "Epoch 2584/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0824 - val_accuracy: 0.9887\n",
      "Epoch 2585/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0082 - accuracy: 0.9960 - val_loss: 0.0718 - val_accuracy: 0.9908\n",
      "Epoch 2586/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0773 - val_accuracy: 0.9918\n",
      "Epoch 2587/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0855 - val_accuracy: 0.9897\n",
      "Epoch 2588/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0851 - val_accuracy: 0.9892\n",
      "Epoch 2589/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0808 - val_accuracy: 0.9903\n",
      "Epoch 2590/3000\n",
      "4547/4547 [==============================] - 0s 39us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0926 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2591/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0749 - val_accuracy: 0.9913\n",
      "Epoch 2592/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0193 - accuracy: 0.9956 - val_loss: 0.0776 - val_accuracy: 0.9933\n",
      "Epoch 2593/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0906 - val_accuracy: 0.9877\n",
      "Epoch 2594/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0797 - val_accuracy: 0.9913\n",
      "Epoch 2595/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0841 - val_accuracy: 0.9903\n",
      "Epoch 2596/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0902 - val_accuracy: 0.9897\n",
      "Epoch 2597/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.0859 - val_accuracy: 0.9877\n",
      "Epoch 2598/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0715 - val_accuracy: 0.9897\n",
      "Epoch 2599/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0768 - val_accuracy: 0.9897\n",
      "Epoch 2600/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.0784 - val_accuracy: 0.9887\n",
      "Epoch 2601/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0759 - val_accuracy: 0.9897\n",
      "Epoch 2602/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0851 - val_accuracy: 0.9887\n",
      "Epoch 2603/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0757 - val_accuracy: 0.9918\n",
      "Epoch 2604/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0848 - val_accuracy: 0.9877\n",
      "Epoch 2605/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0764 - val_accuracy: 0.9913\n",
      "Epoch 2606/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0780 - val_accuracy: 0.9892\n",
      "Epoch 2607/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0759 - val_accuracy: 0.9913\n",
      "Epoch 2608/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0781 - val_accuracy: 0.9897\n",
      "Epoch 2609/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0715 - val_accuracy: 0.9908\n",
      "Epoch 2610/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.99 - 0s 28us/sample - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0769 - val_accuracy: 0.9903\n",
      "Epoch 2611/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0856 - val_accuracy: 0.9872\n",
      "Epoch 2612/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0765 - val_accuracy: 0.9892\n",
      "Epoch 2613/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0792 - val_accuracy: 0.9908\n",
      "Epoch 2614/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0818 - val_accuracy: 0.9913\n",
      "Epoch 2615/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0813 - val_accuracy: 0.9897\n",
      "Epoch 2616/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0771 - val_accuracy: 0.9897\n",
      "Epoch 2617/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0836 - val_accuracy: 0.9903\n",
      "Epoch 2618/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0729 - val_accuracy: 0.9908\n",
      "Epoch 2619/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0749 - val_accuracy: 0.9918\n",
      "Epoch 2620/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0951 - val_accuracy: 0.9882\n",
      "Epoch 2621/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0731 - val_accuracy: 0.9908\n",
      "Epoch 2622/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0849 - val_accuracy: 0.9903\n",
      "Epoch 2623/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0946 - val_accuracy: 0.9867\n",
      "Epoch 2624/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0933 - val_accuracy: 0.9897\n",
      "Epoch 2625/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0916 - val_accuracy: 0.9892\n",
      "Epoch 2626/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0799 - val_accuracy: 0.9903\n",
      "Epoch 2627/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.1037 - val_accuracy: 0.9872\n",
      "Epoch 2628/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0735 - val_accuracy: 0.9918\n",
      "Epoch 2629/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0806 - val_accuracy: 0.9918\n",
      "Epoch 2630/3000\n",
      "4547/4547 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985   - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0791 - val_accuracy: 0.9903\n",
      "Epoch 2631/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.1027 - val_accuracy: 0.9892\n",
      "Epoch 2632/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0802 - val_accuracy: 0.9887\n",
      "Epoch 2633/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0064 - accuracy: 0.9969 - val_loss: 0.0832 - val_accuracy: 0.9882\n",
      "Epoch 2634/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0797 - val_accuracy: 0.9908\n",
      "Epoch 2635/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0755 - val_accuracy: 0.9918\n",
      "Epoch 2636/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0735 - val_accuracy: 0.9918\n",
      "Epoch 2637/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0792 - val_accuracy: 0.9908\n",
      "Epoch 2638/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0869 - val_accuracy: 0.9903\n",
      "Epoch 2639/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0687 - val_accuracy: 0.9918\n",
      "Epoch 2640/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0713 - val_accuracy: 0.9918\n",
      "Epoch 2641/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.1081 - val_accuracy: 0.9872\n",
      "Epoch 2642/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0796 - val_accuracy: 0.9908\n",
      "Epoch 2643/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0814 - val_accuracy: 0.9892\n",
      "Epoch 2644/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1006 - val_accuracy: 0.9867\n",
      "Epoch 2645/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0793 - val_accuracy: 0.9903\n",
      "Epoch 2646/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0737 - val_accuracy: 0.9913\n",
      "Epoch 2647/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0726 - val_accuracy: 0.9913\n",
      "Epoch 2648/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0729 - val_accuracy: 0.9903\n",
      "Epoch 2649/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0713 - val_accuracy: 0.9918\n",
      "Epoch 2650/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0804 - val_accuracy: 0.9892\n",
      "Epoch 2651/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0855 - val_accuracy: 0.9856\n",
      "Epoch 2652/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0689 - val_accuracy: 0.9913\n",
      "Epoch 2653/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0797 - val_accuracy: 0.9892\n",
      "Epoch 2654/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0729 - val_accuracy: 0.9918\n",
      "Epoch 2655/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0760 - val_accuracy: 0.9908\n",
      "Epoch 2656/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0753 - val_accuracy: 0.9897\n",
      "Epoch 2657/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0746 - val_accuracy: 0.9918\n",
      "Epoch 2658/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0747 - val_accuracy: 0.9903\n",
      "Epoch 2659/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0845 - val_accuracy: 0.9897\n",
      "Epoch 2660/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0782 - val_accuracy: 0.9908\n",
      "Epoch 2661/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0234 - accuracy: 0.9934 - val_loss: 0.0851 - val_accuracy: 0.9877\n",
      "Epoch 2662/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0762 - val_accuracy: 0.9903\n",
      "Epoch 2663/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0742 - val_accuracy: 0.9913\n",
      "Epoch 2664/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.0786 - val_accuracy: 0.9877\n",
      "Epoch 2665/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0090 - accuracy: 0.9965 - val_loss: 0.0795 - val_accuracy: 0.9882\n",
      "Epoch 2666/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0712 - val_accuracy: 0.9918\n",
      "Epoch 2667/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0966 - val_accuracy: 0.9887\n",
      "Epoch 2668/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0075 - accuracy: 0.9971 - val_loss: 0.0898 - val_accuracy: 0.9892\n",
      "Epoch 2669/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 2670/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0836 - val_accuracy: 0.9903\n",
      "Epoch 2671/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0731 - val_accuracy: 0.9908\n",
      "Epoch 2672/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.0814 - val_accuracy: 0.9908\n",
      "Epoch 2673/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.0798 - val_accuracy: 0.9918\n",
      "Epoch 2674/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0780 - val_accuracy: 0.9913\n",
      "Epoch 2675/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0815 - val_accuracy: 0.9908\n",
      "Epoch 2676/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.0744 - val_accuracy: 0.9928\n",
      "Epoch 2677/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0746 - val_accuracy: 0.9903\n",
      "Epoch 2678/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0744 - val_accuracy: 0.9923\n",
      "Epoch 2679/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0812 - val_accuracy: 0.9923\n",
      "Epoch 2680/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0785 - val_accuracy: 0.9908\n",
      "Epoch 2681/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0764 - val_accuracy: 0.9897\n",
      "Epoch 2682/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.1220 - val_accuracy: 0.9831\n",
      "Epoch 2683/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0790 - val_accuracy: 0.9872\n",
      "Epoch 2684/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0803 - val_accuracy: 0.9918\n",
      "Epoch 2685/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0794 - val_accuracy: 0.9913\n",
      "Epoch 2686/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0838 - val_accuracy: 0.9913\n",
      "Epoch 2687/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0784 - val_accuracy: 0.9908\n",
      "Epoch 2688/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0859 - val_accuracy: 0.9908\n",
      "Epoch 2689/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0838 - val_accuracy: 0.9903\n",
      "Epoch 2690/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0829 - val_accuracy: 0.9918\n",
      "Epoch 2691/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0799 - val_accuracy: 0.9908\n",
      "Epoch 2692/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0752 - val_accuracy: 0.9897\n",
      "Epoch 2693/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.0805 - val_accuracy: 0.9892\n",
      "Epoch 2694/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0979 - val_accuracy: 0.9867\n",
      "Epoch 2695/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0929 - val_accuracy: 0.9887\n",
      "Epoch 2696/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 2697/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0746 - val_accuracy: 0.9908\n",
      "Epoch 2698/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0854 - val_accuracy: 0.9897\n",
      "Epoch 2699/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0744 - val_accuracy: 0.9908\n",
      "Epoch 2700/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0789 - val_accuracy: 0.9928\n",
      "Epoch 2701/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0880 - val_accuracy: 0.9897\n",
      "Epoch 2702/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0776 - val_accuracy: 0.9913\n",
      "Epoch 2703/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0812 - val_accuracy: 0.9908\n",
      "Epoch 2704/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0794 - val_accuracy: 0.9897\n",
      "Epoch 2705/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0856 - val_accuracy: 0.9918\n",
      "Epoch 2706/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0788 - val_accuracy: 0.9913\n",
      "Epoch 2707/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0974 - val_accuracy: 0.9887\n",
      "Epoch 2708/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0805 - val_accuracy: 0.9913\n",
      "Epoch 2709/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0791 - val_accuracy: 0.9913\n",
      "Epoch 2710/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0858 - val_accuracy: 0.9867\n",
      "Epoch 2711/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0924 - val_accuracy: 0.9877\n",
      "Epoch 2712/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0805 - val_accuracy: 0.9897\n",
      "Epoch 2713/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0846 - val_accuracy: 0.9908\n",
      "Epoch 2714/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0754 - val_accuracy: 0.9913\n",
      "Epoch 2715/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1083 - val_accuracy: 0.9856\n",
      "Epoch 2716/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0900 - val_accuracy: 0.9892\n",
      "Epoch 2717/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0694 - val_accuracy: 0.9928\n",
      "Epoch 2718/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0828 - val_accuracy: 0.9918\n",
      "Epoch 2719/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0775 - val_accuracy: 0.9918\n",
      "Epoch 2720/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0875 - val_accuracy: 0.9892\n",
      "Epoch 2721/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.0801 - val_accuracy: 0.9903\n",
      "Epoch 2722/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0768 - val_accuracy: 0.9908\n",
      "Epoch 2723/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0764 - val_accuracy: 0.9913\n",
      "Epoch 2724/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0807 - val_accuracy: 0.9903\n",
      "Epoch 2725/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0757 - val_accuracy: 0.9918\n",
      "Epoch 2726/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0791 - val_accuracy: 0.9918\n",
      "Epoch 2727/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0384 - accuracy: 0.9903 - val_loss: 0.1047 - val_accuracy: 0.9846\n",
      "Epoch 2728/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0793 - val_accuracy: 0.9908\n",
      "Epoch 2729/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0815 - val_accuracy: 0.9913\n",
      "Epoch 2730/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0764 - val_accuracy: 0.9908\n",
      "Epoch 2731/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0933 - val_accuracy: 0.9887\n",
      "Epoch 2732/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0917 - val_accuracy: 0.9872\n",
      "Epoch 2733/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0851 - val_accuracy: 0.9903\n",
      "Epoch 2734/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0846 - val_accuracy: 0.9897\n",
      "Epoch 2735/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0862 - val_accuracy: 0.9908\n",
      "Epoch 2736/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0872 - val_accuracy: 0.9903\n",
      "Epoch 2737/3000\n",
      "4547/4547 [==============================] - 0s 37us/sample - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0888 - val_accuracy: 0.9913\n",
      "Epoch 2738/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0958 - val_accuracy: 0.9872\n",
      "Epoch 2739/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0817 - val_accuracy: 0.9908\n",
      "Epoch 2740/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0813 - val_accuracy: 0.9903\n",
      "Epoch 2741/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0806 - val_accuracy: 0.9903\n",
      "Epoch 2742/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.0800 - val_accuracy: 0.9918\n",
      "Epoch 2743/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0859 - val_accuracy: 0.9903\n",
      "Epoch 2744/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0788 - val_accuracy: 0.9918\n",
      "Epoch 2745/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.0797 - val_accuracy: 0.9908\n",
      "Epoch 2746/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0790 - val_accuracy: 0.9903\n",
      "Epoch 2747/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0831 - val_accuracy: 0.9913\n",
      "Epoch 2748/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0750 - val_accuracy: 0.9913\n",
      "Epoch 2749/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9903\n",
      "Epoch 2750/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0780 - val_accuracy: 0.9918\n",
      "Epoch 2751/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0841 - val_accuracy: 0.9908\n",
      "Epoch 2752/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0781 - val_accuracy: 0.9913\n",
      "Epoch 2753/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 2754/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0112 - accuracy: 0.9956 - val_loss: 0.0846 - val_accuracy: 0.9892\n",
      "Epoch 2755/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.1034 - val_accuracy: 0.9851\n",
      "Epoch 2756/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0714 - val_accuracy: 0.9923\n",
      "Epoch 2757/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0994 - val_accuracy: 0.9887\n",
      "Epoch 2758/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0841 - val_accuracy: 0.9913\n",
      "Epoch 2759/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0884 - val_accuracy: 0.9887\n",
      "Epoch 2760/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0779 - val_accuracy: 0.9918\n",
      "Epoch 2761/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0804 - val_accuracy: 0.9918\n",
      "Epoch 2762/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0927 - val_accuracy: 0.9892\n",
      "Epoch 2763/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0883 - val_accuracy: 0.9872\n",
      "Epoch 2764/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0888 - val_accuracy: 0.9903\n",
      "Epoch 2765/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0828 - val_accuracy: 0.9908\n",
      "Epoch 2766/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0820 - val_accuracy: 0.9918\n",
      "Epoch 2767/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0939 - val_accuracy: 0.9872\n",
      "Epoch 2768/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0790 - val_accuracy: 0.9913\n",
      "Epoch 2769/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0905 - val_accuracy: 0.9882\n",
      "Epoch 2770/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.1042 - val_accuracy: 0.9872\n",
      "Epoch 2771/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0803 - val_accuracy: 0.9908\n",
      "Epoch 2772/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0760 - val_accuracy: 0.9908\n",
      "Epoch 2773/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0814 - val_accuracy: 0.9908\n",
      "Epoch 2774/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0782 - val_accuracy: 0.9918\n",
      "Epoch 2775/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0784 - val_accuracy: 0.9903\n",
      "Epoch 2776/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0818 - val_accuracy: 0.9903\n",
      "Epoch 2777/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0752 - val_accuracy: 0.9918\n",
      "Epoch 2778/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0813 - val_accuracy: 0.9897\n",
      "Epoch 2779/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0797 - val_accuracy: 0.9918\n",
      "Epoch 2780/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0875 - val_accuracy: 0.9903\n",
      "Epoch 2781/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0841 - val_accuracy: 0.9913\n",
      "Epoch 2782/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0744 - val_accuracy: 0.9918\n",
      "Epoch 2783/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0807 - val_accuracy: 0.9918\n",
      "Epoch 2784/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0758 - val_accuracy: 0.9923\n",
      "Epoch 2785/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0801 - val_accuracy: 0.9903\n",
      "Epoch 2786/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0764 - val_accuracy: 0.9913\n",
      "Epoch 2787/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0776 - val_accuracy: 0.9903\n",
      "Epoch 2788/3000\n",
      "4547/4547 [==============================] - 0s 38us/sample - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0826 - val_accuracy: 0.9913\n",
      "Epoch 2789/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.0837 - val_accuracy: 0.9877\n",
      "Epoch 2790/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0232 - accuracy: 0.9945 - val_loss: 0.0898 - val_accuracy: 0.9887\n",
      "Epoch 2791/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0863 - val_accuracy: 0.9903\n",
      "Epoch 2792/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0765 - val_accuracy: 0.9923\n",
      "Epoch 2793/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0808 - val_accuracy: 0.9908\n",
      "Epoch 2794/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0056 - accuracy: 0.9969 - val_loss: 0.0843 - val_accuracy: 0.9903\n",
      "Epoch 2795/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0927 - val_accuracy: 0.9882\n",
      "Epoch 2796/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.0803 - val_accuracy: 0.9918\n",
      "Epoch 2797/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0811 - val_accuracy: 0.9913\n",
      "Epoch 2798/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.0964 - val_accuracy: 0.9872\n",
      "Epoch 2799/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0076 - accuracy: 0.9969 - val_loss: 0.1026 - val_accuracy: 0.9872\n",
      "Epoch 2800/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1013 - val_accuracy: 0.9882\n",
      "Epoch 2801/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.1018 - val_accuracy: 0.9882\n",
      "Epoch 2802/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0873 - val_accuracy: 0.9903\n",
      "Epoch 2803/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0787 - val_accuracy: 0.9913\n",
      "Epoch 2804/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0810 - val_accuracy: 0.9918\n",
      "Epoch 2805/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0766 - val_accuracy: 0.9923\n",
      "Epoch 2806/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0860 - val_accuracy: 0.9851\n",
      "Epoch 2807/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0792 - val_accuracy: 0.9918\n",
      "Epoch 2808/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0807 - val_accuracy: 0.9908\n",
      "Epoch 2809/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.0841 - val_accuracy: 0.9903\n",
      "Epoch 2810/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0769 - val_accuracy: 0.9923\n",
      "Epoch 2811/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0829 - val_accuracy: 0.9913\n",
      "Epoch 2812/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0820 - val_accuracy: 0.9908\n",
      "Epoch 2813/3000\n",
      "4547/4547 [==============================] - 0s 36us/sample - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0840 - val_accuracy: 0.9923\n",
      "Epoch 2814/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0880 - val_accuracy: 0.9913\n",
      "Epoch 2815/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0782 - val_accuracy: 0.9908\n",
      "Epoch 2816/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0881 - val_accuracy: 0.9908\n",
      "Epoch 2817/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.0978 - val_accuracy: 0.9887\n",
      "Epoch 2818/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0838 - val_accuracy: 0.9913\n",
      "Epoch 2819/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0761 - val_accuracy: 0.9918\n",
      "Epoch 2820/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0732 - val_accuracy: 0.9918\n",
      "Epoch 2821/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0829 - val_accuracy: 0.9908\n",
      "Epoch 2822/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0798 - val_accuracy: 0.9897\n",
      "Epoch 2823/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0075 - accuracy: 0.9967 - val_loss: 0.0834 - val_accuracy: 0.9887\n",
      "Epoch 2824/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0093 - accuracy: 0.9960 - val_loss: 0.0847 - val_accuracy: 0.9913\n",
      "Epoch 2825/3000\n",
      "4547/4547 [==============================] - 0s 32us/sample - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.1038 - val_accuracy: 0.9887\n",
      "Epoch 2826/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.1030 - val_accuracy: 0.9892\n",
      "Epoch 2827/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0798 - val_accuracy: 0.9903\n",
      "Epoch 2828/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0843 - val_accuracy: 0.9903\n",
      "Epoch 2829/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0815 - val_accuracy: 0.9913\n",
      "Epoch 2830/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0855 - val_accuracy: 0.9903\n",
      "Epoch 2831/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0831 - val_accuracy: 0.9913\n",
      "Epoch 2832/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0872 - val_accuracy: 0.9897\n",
      "Epoch 2833/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0933 - val_accuracy: 0.9903\n",
      "Epoch 2834/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0800 - val_accuracy: 0.9903\n",
      "Epoch 2835/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.0877 - val_accuracy: 0.9903\n",
      "Epoch 2836/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0901 - val_accuracy: 0.9872\n",
      "Epoch 2837/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0799 - val_accuracy: 0.9918\n",
      "Epoch 2838/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0842 - val_accuracy: 0.9913\n",
      "Epoch 2839/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.0896 - val_accuracy: 0.9892\n",
      "Epoch 2840/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0840 - val_accuracy: 0.9903\n",
      "Epoch 2841/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0837 - val_accuracy: 0.9923\n",
      "Epoch 2842/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0745 - val_accuracy: 0.9918\n",
      "Epoch 2843/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0812 - val_accuracy: 0.9908\n",
      "Epoch 2844/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0765 - val_accuracy: 0.9913\n",
      "Epoch 2845/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0825 - val_accuracy: 0.9913\n",
      "Epoch 2846/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0811 - val_accuracy: 0.9913\n",
      "Epoch 2847/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0763 - val_accuracy: 0.9903\n",
      "Epoch 2848/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0820 - val_accuracy: 0.9923\n",
      "Epoch 2849/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0770 - val_accuracy: 0.9923\n",
      "Epoch 2850/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0799 - val_accuracy: 0.9908\n",
      "Epoch 2851/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0850 - val_accuracy: 0.9918\n",
      "Epoch 2852/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0861 - val_accuracy: 0.9913\n",
      "Epoch 2853/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0904 - val_accuracy: 0.9882\n",
      "Epoch 2854/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0868 - val_accuracy: 0.9913\n",
      "Epoch 2855/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0806 - val_accuracy: 0.9918\n",
      "Epoch 2856/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0819 - val_accuracy: 0.9918\n",
      "Epoch 2857/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0833 - val_accuracy: 0.9913\n",
      "Epoch 2858/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0788 - val_accuracy: 0.9913\n",
      "Epoch 2859/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.0824 - val_accuracy: 0.9923\n",
      "Epoch 2860/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0826 - val_accuracy: 0.9908\n",
      "Epoch 2861/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0886 - val_accuracy: 0.9913\n",
      "Epoch 2862/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0970 - val_accuracy: 0.9867\n",
      "Epoch 2863/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0826 - val_accuracy: 0.9892\n",
      "Epoch 2864/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1187 - val_accuracy: 0.9841\n",
      "Epoch 2865/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0742 - val_accuracy: 0.9918\n",
      "Epoch 2866/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.0745 - val_accuracy: 0.9903\n",
      "Epoch 2867/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0769 - val_accuracy: 0.9918\n",
      "Epoch 2868/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0950 - val_accuracy: 0.9892\n",
      "Epoch 2869/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.0753 - val_accuracy: 0.9918\n",
      "Epoch 2870/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0749 - val_accuracy: 0.9913\n",
      "Epoch 2871/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0761 - val_accuracy: 0.9903\n",
      "Epoch 2872/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.0719 - val_accuracy: 0.9908\n",
      "Epoch 2873/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0207 - accuracy: 0.9960 - val_loss: 0.0772 - val_accuracy: 0.9923\n",
      "Epoch 2874/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0708 - val_accuracy: 0.9913\n",
      "Epoch 2875/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.0902 - val_accuracy: 0.9892\n",
      "Epoch 2876/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0681 - val_accuracy: 0.9938\n",
      "Epoch 2877/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0813 - val_accuracy: 0.9908\n",
      "Epoch 2878/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0748 - val_accuracy: 0.9908\n",
      "Epoch 2879/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0744 - val_accuracy: 0.9913\n",
      "Epoch 2880/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0744 - val_accuracy: 0.9918\n",
      "Epoch 2881/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0774 - val_accuracy: 0.9923\n",
      "Epoch 2882/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0780 - val_accuracy: 0.9918\n",
      "Epoch 2883/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0724 - val_accuracy: 0.9913\n",
      "Epoch 2884/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1006 - val_accuracy: 0.9882\n",
      "Epoch 2885/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0773 - val_accuracy: 0.9913\n",
      "Epoch 2886/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0724 - val_accuracy: 0.9918\n",
      "Epoch 2887/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.0812 - val_accuracy: 0.9897\n",
      "Epoch 2888/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0789 - val_accuracy: 0.9913\n",
      "Epoch 2889/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0813 - val_accuracy: 0.9913\n",
      "Epoch 2890/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0842 - val_accuracy: 0.9908\n",
      "Epoch 2891/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0803 - val_accuracy: 0.9918\n",
      "Epoch 2892/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.0892 - val_accuracy: 0.9913\n",
      "Epoch 2893/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1508 - val_accuracy: 0.9759\n",
      "Epoch 2894/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.1162 - val_accuracy: 0.9841\n",
      "Epoch 2895/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0842 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9887\n",
      "Epoch 2896/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.0717 - val_accuracy: 0.9903\n",
      "Epoch 2897/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0873 - val_accuracy: 0.9897\n",
      "Epoch 2898/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0929 - val_accuracy: 0.9892\n",
      "Epoch 2899/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0754 - val_accuracy: 0.9908\n",
      "Epoch 2900/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0800 - val_accuracy: 0.9923\n",
      "Epoch 2901/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0826 - val_accuracy: 0.9918\n",
      "Epoch 2902/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0080 - accuracy: 0.9967 - val_loss: 0.0786 - val_accuracy: 0.9918\n",
      "Epoch 2903/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0696 - val_accuracy: 0.9928\n",
      "Epoch 2904/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0749 - val_accuracy: 0.9903\n",
      "Epoch 2905/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0747 - val_accuracy: 0.9908\n",
      "Epoch 2906/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0826 - val_accuracy: 0.9913\n",
      "Epoch 2907/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0726 - val_accuracy: 0.9923\n",
      "Epoch 2908/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.0969 - val_accuracy: 0.9867\n",
      "Epoch 2909/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.0802 - val_accuracy: 0.9923\n",
      "Epoch 2910/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0723 - val_accuracy: 0.9908\n",
      "Epoch 2911/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0757 - val_accuracy: 0.9913\n",
      "Epoch 2912/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0749 - val_accuracy: 0.9918\n",
      "Epoch 2913/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0778 - val_accuracy: 0.9918\n",
      "Epoch 2914/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0714 - val_accuracy: 0.9918\n",
      "Epoch 2915/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0738 - val_accuracy: 0.9913\n",
      "Epoch 2916/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.0744 - val_accuracy: 0.9918\n",
      "Epoch 2917/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0825 - val_accuracy: 0.9892\n",
      "Epoch 2918/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0827 - val_accuracy: 0.9913\n",
      "Epoch 2919/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0772 - val_accuracy: 0.9918\n",
      "Epoch 2920/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0750 - val_accuracy: 0.9918\n",
      "Epoch 2921/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0794 - val_accuracy: 0.9923\n",
      "Epoch 2922/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0881 - val_accuracy: 0.9897\n",
      "Epoch 2923/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0814 - val_accuracy: 0.9913\n",
      "Epoch 2924/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0740 - val_accuracy: 0.9913\n",
      "Epoch 2925/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0785 - val_accuracy: 0.9913\n",
      "Epoch 2926/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0912 - val_accuracy: 0.9892\n",
      "Epoch 2927/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0751 - val_accuracy: 0.9923\n",
      "Epoch 2928/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0743 - val_accuracy: 0.9908\n",
      "Epoch 2929/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0780 - val_accuracy: 0.9908\n",
      "Epoch 2930/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0804 - val_accuracy: 0.9913\n",
      "Epoch 2931/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0851 - val_accuracy: 0.9908\n",
      "Epoch 2932/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0842 - val_accuracy: 0.9918\n",
      "Epoch 2933/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0810 - val_accuracy: 0.9913\n",
      "Epoch 2934/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0784 - val_accuracy: 0.9918\n",
      "Epoch 2935/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0773 - val_accuracy: 0.9918\n",
      "Epoch 2936/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.0760 - val_accuracy: 0.9918\n",
      "Epoch 2937/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0748 - val_accuracy: 0.9918\n",
      "Epoch 2938/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0842 - val_accuracy: 0.9908\n",
      "Epoch 2939/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0776 - val_accuracy: 0.9918\n",
      "Epoch 2940/3000\n",
      "4547/4547 [==============================] - 0s 34us/sample - loss: 0.0289 - accuracy: 0.9930 - val_loss: 0.1015 - val_accuracy: 0.9846\n",
      "Epoch 2941/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.1006 - val_accuracy: 0.9887\n",
      "Epoch 2942/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0811 - val_accuracy: 0.9908\n",
      "Epoch 2943/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0786 - val_accuracy: 0.9913\n",
      "Epoch 2944/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0729 - val_accuracy: 0.9918\n",
      "Epoch 2945/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0855 - val_accuracy: 0.9913\n",
      "Epoch 2946/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0833 - val_accuracy: 0.9908\n",
      "Epoch 2947/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0893 - val_accuracy: 0.9903\n",
      "Epoch 2948/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0895 - val_accuracy: 0.9897\n",
      "Epoch 2949/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0885 - val_accuracy: 0.9908\n",
      "Epoch 2950/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0790 - val_accuracy: 0.9908\n",
      "Epoch 2951/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0942 - val_accuracy: 0.9913\n",
      "Epoch 2952/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0770 - val_accuracy: 0.9908\n",
      "Epoch 2953/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0803 - val_accuracy: 0.9908\n",
      "Epoch 2954/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0813 - val_accuracy: 0.9928\n",
      "Epoch 2955/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0806 - val_accuracy: 0.9908\n",
      "Epoch 2956/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0899 - val_accuracy: 0.9897\n",
      "Epoch 2957/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0853 - val_accuracy: 0.9908\n",
      "Epoch 2958/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0830 - val_accuracy: 0.9913\n",
      "Epoch 2959/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0810 - val_accuracy: 0.9903\n",
      "Epoch 2960/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0813 - val_accuracy: 0.9913\n",
      "Epoch 2961/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0869 - val_accuracy: 0.9872\n",
      "Epoch 2962/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.0947 - val_accuracy: 0.9882\n",
      "Epoch 2963/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0874 - val_accuracy: 0.9913\n",
      "Epoch 2964/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0054 - accuracy: 0.9978 - val_loss: 0.0850 - val_accuracy: 0.9908\n",
      "Epoch 2965/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0074 - accuracy: 0.9965 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 2966/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0796 - val_accuracy: 0.9913\n",
      "Epoch 2967/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0789 - val_accuracy: 0.9903\n",
      "Epoch 2968/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1092 - val_accuracy: 0.9862\n",
      "Epoch 2969/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0808 - val_accuracy: 0.9897\n",
      "Epoch 2970/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0875 - val_accuracy: 0.9908\n",
      "Epoch 2971/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0811 - val_accuracy: 0.9918\n",
      "Epoch 2972/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0378 - accuracy: 0.9897 - val_loss: 0.1315 - val_accuracy: 0.9805\n",
      "Epoch 2973/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.0847 - val_accuracy: 0.9913\n",
      "Epoch 2974/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0788 - val_accuracy: 0.9903\n",
      "Epoch 2975/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0757 - val_accuracy: 0.9908\n",
      "Epoch 2976/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.0818 - val_accuracy: 0.9908\n",
      "Epoch 2977/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0944 - val_accuracy: 0.9882\n",
      "Epoch 2978/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0768 - val_accuracy: 0.9913\n",
      "Epoch 2979/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0895 - val_accuracy: 0.9908\n",
      "Epoch 2980/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0817 - val_accuracy: 0.9903\n",
      "Epoch 2981/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0814 - val_accuracy: 0.9908\n",
      "Epoch 2982/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0934 - val_accuracy: 0.9903\n",
      "Epoch 2983/3000\n",
      "4547/4547 [==============================] - 0s 31us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0753 - val_accuracy: 0.9918\n",
      "Epoch 2984/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0837 - val_accuracy: 0.9908\n",
      "Epoch 2985/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0754 - val_accuracy: 0.9913\n",
      "Epoch 2986/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.0760 - val_accuracy: 0.9908\n",
      "Epoch 2987/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0771 - val_accuracy: 0.9918\n",
      "Epoch 2988/3000\n",
      "4547/4547 [==============================] - 0s 26us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9918\n",
      "Epoch 2989/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0784 - val_accuracy: 0.9928\n",
      "Epoch 2990/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0834 - val_accuracy: 0.9908\n",
      "Epoch 2991/3000\n",
      "4547/4547 [==============================] - 0s 33us/sample - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.1027 - val_accuracy: 0.9882\n",
      "Epoch 2992/3000\n",
      "4547/4547 [==============================] - 0s 35us/sample - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0842 - val_accuracy: 0.9892\n",
      "Epoch 2993/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.1023 - val_accuracy: 0.9882\n",
      "Epoch 2994/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.0979 - val_accuracy: 0.9887\n",
      "Epoch 2995/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0909 - val_accuracy: 0.9903\n",
      "Epoch 2996/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0823 - val_accuracy: 0.9918\n",
      "Epoch 2997/3000\n",
      "4547/4547 [==============================] - 0s 27us/sample - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0783 - val_accuracy: 0.9923\n",
      "Epoch 2998/3000\n",
      "4547/4547 [==============================] - 0s 30us/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0813 - val_accuracy: 0.9918\n",
      "Epoch 2999/3000\n",
      "4547/4547 [==============================] - 0s 28us/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0845 - val_accuracy: 0.9918\n",
      "Epoch 3000/3000\n",
      "4547/4547 [==============================] - 0s 29us/sample - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0993 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "# epoch 학습 반복 횟수 결정하기 (학습 시간과 정확도, 테스트 결과)\n",
    "df = df_pre.sample(frac=0.2)\n",
    "\n",
    "history = model.fit(X,Y, validation_split = 0.3,\n",
    "                epochs=3000, batch_size=100)\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = numpy.arange(len(y_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no property 'makersize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5dbaf0947204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"o\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmakersize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"o\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmakersize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2761\u001b[0m     return gca().plot(\n\u001b[0;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2763\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1645\u001b[0m         \"\"\"\n\u001b[0;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \"non-matching shapes is deprecated.\")\n\u001b[0;32m    363\u001b[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[1;32m--> 364\u001b[1;33m                 for j in range(max(ncx, ncy))]\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \"non-matching shapes is deprecated.\")\n\u001b[0;32m    363\u001b[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[1;32m--> 364\u001b[1;33m                 for j in range(max(ncx, ncy))]\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[1;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_update_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m_update_property\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                     raise AttributeError('{!r} object has no property {!r}'\n\u001b[1;32m-> 1002\u001b[1;33m                                          .format(type(self).__name__, k))\n\u001b[0m\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Line2D' object has no property 'makersize'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_len, y_vloss, \"o\",c=\"red\",makersize = 2)\n",
    "plt.plot(x_len, y_acc, \"o\",c=\"blue\",makersize = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5197 samples, validate on 1300 samples\n",
      "Epoch 1/500\n",
      "5197/5197 [==============================] - 1s 126us/sample - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.1353 - val_accuracy: 0.9862\n",
      "Epoch 2/500\n",
      "5197/5197 [==============================] - 0s 26us/sample - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1029 - val_accuracy: 0.9885\n",
      "Epoch 3/500\n",
      "5197/5197 [==============================] - 0s 26us/sample - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.1112 - val_accuracy: 0.9869\n",
      "Epoch 4/500\n",
      "5197/5197 [==============================] - 0s 24us/sample - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0961 - val_accuracy: 0.9908\n",
      "Epoch 5/500\n",
      "5197/5197 [==============================] - 0s 24us/sample - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1119 - val_accuracy: 0.9854\n",
      "Epoch 6/500\n",
      "5197/5197 [==============================] - 0s 23us/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0995 - val_accuracy: 0.9900\n",
      "Epoch 7/500\n",
      "5197/5197 [==============================] - 0s 24us/sample - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.1177 - val_accuracy: 0.9854\n",
      "Epoch 8/500\n",
      "5197/5197 [==============================] - 0s 23us/sample - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1070 - val_accuracy: 0.9892\n",
      "Epoch 9/500\n",
      "5197/5197 [==============================] - 0s 24us/sample - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1043 - val_accuracy: 0.9862\n",
      "Epoch 10/500\n",
      "5197/5197 [==============================] - 0s 25us/sample - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.1002 - val_accuracy: 0.9900\n",
      "Epoch 11/500\n",
      "5197/5197 [==============================] - 0s 23us/sample - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0982 - val_accuracy: 0.9915\n",
      "Epoch 12/500\n",
      "5197/5197 [==============================] - 0s 24us/sample - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1291 - val_accuracy: 0.9838\n",
      "Epoch 13/500\n",
      "5197/5197 [==============================] - 0s 26us/sample - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9869\n",
      "Epoch 14/500\n",
      "5197/5197 [==============================] - 0s 24us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1074 - val_accuracy: 0.9885\n",
      "6497/6497 [==============================] - 0s 46us/sample - loss: 0.0246 - accuracy: 0.9968\n",
      "\n",
      " Accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 자동 중단 설정( EarlyStopping() 함수에 모니터할 값과 테스트 오차가 좋아지지 않아도 몇 번까지 기다릴지를 정한다)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "#모델 실행\n",
    "model.fit(X,Y,validation_split=0.2, epochs=500,\n",
    "         batch_size=100, callbacks=[early_stopping_callback])\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\anaconda\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\anaconda\\lib\\site-packages (from seaborn) (3.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\anaconda\\lib\\site-packages (from seaborn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\anaconda\\lib\\site-packages (from seaborn) (1.19.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\anaconda\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\anaconda\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 823.25x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############신경망을 이용한 다중 분류###########################\n",
    "#여러 개의 정답 중 하나를 고르는 분류 문제\n",
    "#상관도 그래프 시각화를 통해 꽃잎과 꽃받침의 크기와 너비가 품종별로 차이가 있는 지 확인\n",
    " \n",
    "import seaborn as sns \n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:/Users/손은주/Multicampus/part2/dataset/iris.csv', names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "\n",
    "# pairplot 그래프로 확인\n",
    "sns.pairplot(df, hue='species');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#클래스 Y값 문자열을 수치 데이터로 변환 \n",
    "#( sklearn의 LabelEncoder -> One-hot-Encoding) \n",
    "#tensorflow.keras.utils.to_categorical()\n",
    "\n",
    "data = df.values\n",
    "X = data[:, 0:4].astype(float)\n",
    "Y = data[:, 4]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le =LabelEncoder()\n",
    "Y_num = le.fit_transform(Y)\n",
    "Y_encoded = tf.keras.utils.to_categorical(Y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6259 - accuracy: 0.3267\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.1405 - accuracy: 0.4867\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.9412 - accuracy: 0.4600\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.7467\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.7267\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.8800\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.8267\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.9333\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8867\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8867\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.9467\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.9467\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.9067\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.9533\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.9533\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.9667\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.9600\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.9733\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9667\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9467\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9600\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9733\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9667\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9867\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9467\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9667\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9733\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9733\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9733\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9733\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9733\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9533\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9800\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9667\n",
      "150/150 [==============================] - 0s 199us/step\n",
      "\n",
      " Accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "#첫번째 은닉층 (출력뉴런수 16, 활성화함수 re)\n",
    "#출력증 (출력뉴런수 3, 활성화함수 softmax)\n",
    "#오차함수 : categorial_crossentroy\n",
    "#최적화함수 : adam\n",
    "#측정지표 : accuracy\n",
    "#epochs : 50\n",
    "#batch_size : 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16,  input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y_encoded, epochs=50, batch_size=1)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
      "0         6     148        72         35        0  33.6     0.627   50      1\n",
      "1         1      85        66         29        0  26.6     0.351   31      0\n",
      "2         8     183        64          0        0  23.3     0.672   32      1\n",
      "3         1      89        66         23       94  28.1     0.167   21      0\n",
      "4         0     137        40         35      168  43.1     2.288   33      1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pregnant   768 non-null    int64  \n",
      " 1   plasma     768 non-null    int64  \n",
      " 2   pressure   768 non-null    int64  \n",
      " 3   thickness  768 non-null    int64  \n",
      " 4   insulin    768 non-null    int64  \n",
      " 5   BMI        768 non-null    float64\n",
      " 6   pedigree   768 non-null    float64\n",
      " 7   age        768 non-null    int64  \n",
      " 8   class      768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApgAAAKvCAYAAADOTr/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde1zUVf7H8dcZwPsF7xfAMEPT0sIULSvNNERNzKygXd3Kst0kNS1Ld3+1XfZS20V3s9I1u23JdjVLyy7aTVMhEXWRAqV08i6KV5TL+f3BpAMyOeIMDPJ+Ph48ZL5zxvl85nznO4fP+Z7vGGstIiIiIiK+4qjqAERERETk7KIBpoiIiIj4lAaYIiIiIuJTGmCKiIiIiE9pgCkiIiIiPqUBpoiIiIj4lAaYIiIiImcxY8wgY8z3xphsY8wD5dzfzxiTZ4xZ4/p58EyfM/hM/wMRERERCUzGmCBgJjAQcAIpxpgF1tqMMk2/ttYO9dXzqoIpIiIicvaKAbKttZustceAZCDe309aGRVMfVWQiIiI+Jqp6gAIgDGOMeZOYKzbptnW2tlut8OALW63nUCvcv6rS40x6cBW4F5r7f/OJC5NkfvYLBMI+3vluNNaXq4h+d5iLS1qSK4Au6ylTQ3Jd5u1jKghuQK8ay3da0i+q2vgVyGva1sz+rbr1prXt564BpOzf6VJeTtF2RdwNXCOtfagMWYwMB+IOpO4NEUuIiIicvZyAhFut8MpqVIeZ63db6096Pp9ERBijGl+Jk+qAaaIiIjI2SsFiDLGtDfG1AISgAXuDYwxrY0pmdowxsRQMj7ccyZPqilyERERkYooLqzqCMDx60M5a22hMSYJWAwEAXOttf8zxvzedf8LwEjgD8aYQuAIkGDtmZ1jogGmiIiIyFnMNe29qMy2F9x+fxZ41pfPqQGmiIiISEVUgwpmVdE5mCIiIiLiUxpgioiIiIhPBWZdVURERCTQBcIUeYBSBVNEREREfEoVTBEREZGKUAXTI1UwRURERMSnNMAUEREREZ/SFLmIiIhIRWiK3CNVMEVERETEp1TBFBEREakIVTA9UgVTRERERHxKA0wRERER8SlNkYuIiIhUhKbIPVIFU0RERER8ShVMERERkYpQBdMjVTBFRERExKc0wBQRERERn9IUuYiIiEhFaIrcI1UwRURERMSnVMEUERERqQhVMD1SBVNEREREfEoDTBERERHxKU2Ri4iIiFSEpsg9UgVTRERERHxKA0wRERER8amzboA5depULr30UoYOHVrVofhERGwsN2VmkpCVxcX333/S/aGdOjF8+XJuz8+n2+TJx7cH1a7NdStXMnLNGm5Yv54ef/5zJUZdMWGxsVyXmcmIrCy6lpNr406dGLx8OaPy87nALddfGIeDa1ev5uoPPqiMcCvsrzNmsCoriy/S0+kWHV1um3aRkXy8YgUrf/iBfycnExISAkDDRo34z4IFLF2zhq/XryfxllsAaBsezntLlrAsI4Ov169n7PjxlZXOr3p0xgyWZ2XxeXo6XT3kGhEZycIVK1j2ww+84JbrH+69l0/T0vg0LY2l69bhLCwktEmT449zOBx8sno1rwZIf0fHxvKvzExmZmVxXTn7L8CYGTOYmZXF0+npnOv2eox78UVe2rGD6evWlWofedFF/P3bb3kqLY0nUlI4r2dPv+ZwOu6bMYP3s7L4b3o653vo27aRkbyyYgXzf/iBvycnE+zq277DhvHf9HTmpaXxn5QULu7Tp9TjHA4Hb6xezYwA6Vt3X331FbGxsQwcOJDZs2efdP/KlSu55JJLiI+PJz4+nmeffbbU/UVFRQwfPpw777yzskI+Iw36xdLx60w6LsuiRVI5n0HX3cx5n6Vz3mfpnLtgGXW6dAMgpG047d9aQtSXGUQtXU+zMYFxTPK54sKq/wlQZ90Ac8SIEcyZM6eqw/AJ43DQZ+ZMFsXF8WaXLpyXmEho586l2uTn5rJs/HjSn3yy1Paio0f5oH9/3r74Yt65+GLCBw2iZa9elRn+aTEOB71mzuTTuDjmd+lC+8REGpfJ9WhuLivHj2d9mVx/0XnCBPI2bKiMcCtsQFwc50ZFERMVxeSxY3ni+efLbffg44/zwjPP0KtjR/bt3ctvxowBYMy4cXyfkcFVF1/M8H79ePippwgJCaGosJCHJk+mT5cuDOrdm9vGjaNjmdevsvV35XpZVBT3jR3L3z3k+qfHH2f2M8/Qp2NH8vbuJdGV6/NPPsnA6GgGRkfz16lT+fbLL9m3d+/xx90xYQJZAdLfDoeDO2bO5LG4OCZ06cIViYmEl3n9u8fF0SYqinFRUbwwdixj3V6PpS+/zKODBp30/45+4gn++/DDTI6OJvnBBxn9xBN+z8UbfeLiaBcVRXxUFI+NHctUD307/vHHef2ZZxjesSP79+5luKtvV33+OTdddBGJ0dE8fNtt/F+ZY3bihAnkBEjfuisqKuKRRx5hzpw5LFy4kA8//JDs7OyT2vXo0YP333+f999/n6SkpFL3vfrqq3To0KGyQj4zDgdt/zqTnN/EkdWvC43jE6kdVXq/PrYlh03X9yV7wEXsfOZRwp4oGXTbwkK2PTKZrL5d2Di0N81uGXfSY+XsdtYNMHv27Enjxo2rOgyfaBkTw/7sbA7k5FBcUEB2cjKR8fGl2uTv2sWu1FSKCwpOenzhoUMAOEJCcISEgLWVEndFNI+J4UB2NgddueYkJ9OunFz3pKZiy8m1XlgY4UOG8EOA/3ExKD6e/776KgDfrVxJ49BQWrVufVK7y/v354O33wbgv6+8wuDhwwGw1tKgYUMA6jdowL7cXAoLC9mxfTtr09IAOHTwID9s2ECbsLDKSMmjQfHxvOXKdfXKlTQKDaWlh1w/dOX65iuvEOfK1d3wxETmz5t3/HabsDCuHjKENwKkv8+LiWFbdjY7cnIoLCjgm+RkYsrsvzHx8Xzhej1+WLmS+qGhNHG9Hhlff82B3NyT/l9rLfUaNQKgXuPG5G7d6udMvNMvPp4PXbmsW7mShqGhNC+nb3v278/nrr798JVXuMrVt0dcxyaAuvXrlzo2tQwL44ohQ5gfIH3rbu3atZxzzjlERERQq1YthgwZwueff+7147dv384XX3zByJEj/Ril79SLjuHYj9kUbM7BFhSQ934yjWJL79eHU7+lOG9fye+rVxDSJhyAwp3byV9XckwqPnSQo9kbCGlTtcckv6jq6mV1r2AaY9p7s018q15YGAe3bDl++5DTSf3TGDQYh4Pr09IYvXMnP3/6KTtXrfJHmD5RLyyMQ2VyrXcaucZMn853U6ZAcbE/wvOZNmFhbHXLc6vTSesyeTZt1oz9+/ZRVFR0Ups5zz5Lx86dWb91K1+tW8cfJ0zAlvnDIeKcc+gaHc13K1f6OZtf17pMrtuczpMGvU2bNSPPLddt5bwedevW5apBg1j4zjvHtz0yfTqPTZlCcYD0d7OwMPa45brH6aRp2VzDwth9ijZlzZ04kdH/+AezN2/md08+yetTp/o28ApqGRbGDrdcdjqdtCiTS2izZhx069sdZdpcNXw472zYwIyFC3n4ttuOb793+nRmBFDfutuxYwet3QbSrVq1YseOHSe1W7NmDcOGDeP2228nKyvr+Pa//vWv3HfffTgc1aO2E9w6jIKtJ/q5YJvzVweJTRPHcGDpRydtDwk/hzoXRnN4ddUek6RyebuXv1POtrd9GYiczBhz8sbTqELa4mLeiY7mP+HhtIiJockFF/gwOh87g1zDhwwhf+dO9qxe7eOgfK+8Pi07QPy1Nv1jY1m/Zg0Xtm3LVRdfzN+effZ4RROgfv36vPTOO/xp4kQOHjjg4+hPz5nm+ouB115LyrJlx6fHBwwZwu6dO1kbSP3txf7rTa5lDfrDH3jpnnsY264dL91zD3e9+OIZhekz3rxfT5Hv0vnzub5zZyYPH84fHn0UgCuGDCF35042BFLfuimvv8r26wUXXMCSJUtYsGABo0aNYty4cQAsXbqUpk2bcuGFF1ZKrD5xGvts/cv60SRxDNv/Uvo8TUe9+pwz5x22PTiR4oNVe0ySyvWrA0xjzPnGmOuBxsaYEW4/twB1fuVxY40xqcaY1PJOghbvHHI6aRARcfx2/fBwDlVgiuxYXh7bvviCiHLO8QoUh51O6pfJ9bCXubbs04eIYcMYmZND3+Rk2vTvzxWvveavUE/bbXfdxdK0NJampbF961bauuXZNjycHWXy3LN7N41CQwkKCjqpTeKtt7Lw3XcByNm4kc05OUSdfz4AwcHBvPTOO7z9+ussfO+9ykjtJLfcddfxhTk7yuTaJjyc7eXk2tgt1zblvB7DExJKTY/H9OnDNcOGsSonhxeSk7m8f3+ereL+3uN00swt12bh4SdNZ+9xOmleps3eU+zj/X73O1a4+nv5W28RFRPjw6hPz4133cW8tDTmpaWxa+tWWrnl0jI8nF1lctm3ezcN3Pq2VXg4u8vJd/XXXxPeoQOhzZpxUZ8+9B02jA9zcvhbcjI9+vfnsQB6L7du3Zrt27cfv71jxw5atmxZqk2DBg2oX78+AH379qWwsJDc3FxWr17NkiVL6N+/P5MmTWLFihXce++9lRr/6Src5iSk7Yl+DmkTTuH2k/uwTueuhD05h59ujador9upHsHBtJvzDvvefZ39H1XNMcnvqnp6vBpPkXcChgKhwLVuP92BOzw9yFo721rbw1rbY+zYsb6KtcbZmZJC46goGkZG4ggJ4byEBH5asMCrx9Zp3pxarnNRg+rUIWzAAPZlZvoz3DOyOyWFRlFRNHDl2j4hgS1e5rp62jTeiojg7fbt+TIhgW1LlvD1qFF+jth7c597jquio7kqOpqP5s/nptGjAbikVy/25+Wxw+0D6xfLli7lWtd5Wjf97nd89P77ADg3b+aKq68GoEXLlpzXqRM/bdoEwPQXX+SHDRt44ZlnKiOtcr383HPHF+Z8NH8+N7hy7d6rFwfy8tjpIdehrlxv/N3v+NiVK5Ssmu/dt2+pbX+dNo1LIiKIad+e3yck8M2SJSRVcX9np6TQJiqKlpGRBIeEcHlCAill9t+UBQvo53o9OvbqxeG8PPaW83q427t1Kxf07QtA1/792eY23VrZ3nzuORKjo0mMjuaL+fMZ6sqla69eHMzLY3c5uaQuXcrVrr4d+rvf8YWrHyPcFrmcHx1NSK1a7Nuzh2enTSMuIoKh7dszNSGB1CVL+FMAvZe7du3Kjz/+yJYtWzh27BgLFy6kf//+pdrs2rXreJVv7dq1FBcX06RJEyZPnsxXX33FkiVLePrpp+nduzdPeliwGCgOr0mhdvsoQiIiMSEhNI5PYP8npffrkLAI2s15F+f4URzbVHr/DH/qRY5mbWD37Ko7JknV+dVv8rHWvg+8b4y51Fr7bSXFdEYmTZrEqlWr2Lt3L1deeSV33303N9xwQ1WHVSG2qIhvkpIYvHgxJiiI7+fOZW9GBp1dl7fYMGsWdVu1YkRqKrUaNcIWF9N14kTe7NKFem3acNUrr2CCgjAOBxvffJPNCxdWcUae2aIiViQlMdCVa/bcuezLyKCTK9fvXbkOTU0lpFEjKC6my8SJzO/ShYIqngo+HZ8uWsSAwYNZlZ3NkcOHGX/rrcfvm7dwIRNvv50d27bxyP33Mzs5mWmPPca6tDRed02NPvXoo/zr5Zf5cu1ajDE8cv/95O7ZQ68+fbhp9Gj+t3YtS12Lff4ybRqffXTy+VCV5fNFi7h68GC+deV6j1uu/1m4kMmuXB+7/35eSE7m/sceY31aGvPcpoHjrruOLz/5hCOHD1dFCl4rLipiTlISDy5ejCMoiM/nzmVLRgbXuPbfT2bN4rtFi+g+eDDPZWdz9PBhnnV7Pe554w0u7NePhs2b8+8tW0h+6CE+nzuX5+64gzEzZhAUHMyx/HyeD5A/2L9ZtIjLBw/m/exs8g8f5s9uufxz4UIeuf12dm/bxj/vv5+/JScz7rHHyExLY76rb/tffz1DR4+msKCAo0eO8MBNN1VVKqclODiYBx98kNtvv52ioiKuv/56oqKimOeqsCcmJrJ48WLmzZtHUFAQderU4emnny7/dKfqoKiIrX9Mov0biyEoiL3Jczn6QwZNR5Xs17mvzaLlPQ8S3KQZbf/2HFCyenxjXE/qxfShyQ2jOZKxlvM+LTkm7fjbNA4sqbpjkl8EcAWxqplTnQMEYIxpQUnFMhK3Qam19jZPj3ETuEuX/WBWdT2QVMCd1vJyDcn3FmtpUUNyBdhlLW1qSL7brGVEDckV4F1r6V5D8l0dwFfO8Jd1bWtG33bdagGqPtnN31T9Ttbu8qp/Hcrh7XeRvw98DXwGFPkvHBERERGp7rwdYNaz1pb/1RQiIiIiNZGmyD3y9jJFHxpjBvs1EhERERE5K3hbwZwATDPGHAUKKDnvwVprG/ktMhEREZFApgqmR14NMK21DU/dSkRERETE+womxpgmQBRuF1i31n7lj6BEREREpPryaoBpjLmdkmnycGAN0Bv4Fuj/a48TEREROWtpitwjbxf5TAB6Aj9Za68CooFdfotKRERERKotb6fI8621+cYYjDG1rbWZxphOfo1MREREJJCpgumRtwNMpzEmFJgPfGqM2Quc/I33IiIiIlLjebuK/DrXr382xiwFGgMf+y0qEREREam2TmcVeRDQCshxbWoNbPZHUCIiIiIBT1PkHnm7ivxu4CFgB1Ds2myBbn6KS0RERESqqdP5Jp9O1to9/gxGREREpNpQBdMjby9TtAXI82cgIiIiInJ28LaCuQn4whizEDj6y0Zr7dN+iUpEREREqi1vB5ibXT+1XD8iIiIiNZumyD3y9jJFD/s7EBERERE5O3i7ivwDSlaNu8sDUoFZ1tp8XwcmIiIiItXT6ZyD2QKY57p9EyWXLOoI/BsY5fvQRERERAKYpsg98naAGW2tvdLt9gfGmK+stVcaY/7nj8BEREREpHrydoDZwhjTzlq7GcAY0w5o7rrvmF8iExEREQlkqmB65O0AczLwjTFmI2CA9sBdxpj6wCv+Ck5EREREqh9vV5EvMsZEAedTMsDMdFvYM91fwYmIiIhI9ePtKvJ6wCTgHGvtHcaYKGNMJ2vth/4NT0RERCRAaYrcI2+/KvIlSs61vNR12wk85peIRERERKRa8/YczA7W2puMMYkA1tojxhjjx7hEREREApsqmB55W8E8Zoypi+ti68aYDrh9J7mIiIiIyC+8rWA+BHwMRBhjXgf6ALf4KygRERERqb5OOcA0xjiAJsAIoDclq8gnWGt3+zk2ERERkcClKXKPTjnAtNYWG2OSrLVvAgsrISYRERERqcaMtfbUjYz5P+AI8F/g0C/brbW5XjzHqZ9ARERE5PRU/WLjFdOrfozTe2LVvw7l8PYczNsoGSjeVWb7ub4NR0RERESqO28HmF0oGVxeTslA82vgBW+fZFYNuaLRnV5Ug882yTWkbxOsJamG5ArwrLVwbw3J90nL2tY1JFeg23bLizVkXx5jLXsurxm5AjT7xsLW1KoOo3K07VHVEcgpeDvAfAXYD/zTdTvRte1GfwQlIiIiEvC0yMcjbweYnay1F7ndXmqMSfdHQCIiIiJSvXk7wEwzxvS21q4AMMb0Apb5LywRERGRAKcKpkfeDjB7AaONMZtdt9sBG4wx6wBrre3ml+hEREREpNrxdoA5yK9RiIiIiMhZw6sBprX2J38HIiIiIlKtaIrcI0dVByAiIiIiZxcNMEVERETEp7w9B1NERERE3GmK3CNVMEVERETEp1TBFBEREakIVTA9UgVTRERERHxKA0wRERER8SlNkYuIiIhUhKbIPVIFU0RERER8ShVMERERkYpQBdMjVTBFRERExKc0wBQRERERn9IUuYiIiEhFaIrcI1UwRURERMSnVMEUERERqQhVMD1SBVNEREREfEoDTBERERHxKU2Ri4iIiFSEpsg9UgVTRERERHxKFUwRERGRilAF0yNVMEVERETEpzTAFBERERGf0gBTREREpCKKC6v+xwvGmEHGmO+NMdnGmAd+pV1PY0yRMWbkmb40GmCKiIiInKWMMUHATCAO6AIkGmO6eGj3OLDYF89b7QaYEbGx3JSZSUJWFhfff/9J94d26sTw5cu5PT+fbpMnH98eVLs2161cycg1a7hh/Xp6/PnPlRi1f0ydOpVLL72UoUOHVnUoPtE6NpbBmZkMycqiczl927BTJwYsX84N+fl0cutbgGtzchi0di2xaWlck5JSWSGfts6xsfxfZiYPZWUxsJwcAUbOmMFDWVlMTU8nPDr6+PaHc3KYtnYtD6SlMcUtx1uTk3kgLY0H0tJ4OCeHB9LS/J7HaesUC1My4YEsuKqcvC8YBpPS4Z40mJACkX1KtgfXhvErYdIauHc9XPPnSg27ohpcFUunbzLp9G0WLZLKOU6NuJmoJelELUmnwwfLqNOlGwAhbcM5950ldPwqg45frqfZ7eMrO/QKCYuN5frMTG7IyqJbOft1406duHb5cm7Jz+fCMu9dAONwMHz1agZ+8EFlhHtGQnrFEvpGJqHJWdT57cm51hp4M41fTqfxy+k0en4ZQed1O36fadCYBo++RejrG2j8nwyCL+hdmaFXyFer0okdfS8DfzOJ2W8s8NhubeZGOl/9Wz7+ciUAmzZvJf72qcd/ug8Zw8tvf1RZYVeeqq5eelfBjAGyrbWbrLXHgGQgvpx2dwPvADt98dJUq1XkxuGgz8yZLBw4kENOJyNSUvhxwQL2bdhwvE1+bi7Lxo8ncvjwUo8tOnqUD/r3p/DQIRzBwQz75hs2f/QRO1eurOw0fGbEiBH89re/5X4PA5XqxDgc9Jg5k6UDB3LE6WRgSgo/L1jAfre+PZaby+rx4wkr07e/WHLVVRzbs6eyQj5txuHgxpkzeXbgQPY5ndyXksK6BQvY7pZjl7g4WkRF8XBUFJG9epHw/PM82fvEh9CMq67iUJkcX0pIOP77dU8+yZG8PP8nczqMA66bCbMHQp6zZACZsQB2nMibrM/hf64PrzZdYdSb8ERnKDwKL/SHY4fAEQxJ30DmR7A5gN+3Dgdhf5tJzo0DKdjm5LyPU9j/yQKO/uC2L2/OYdN1fSnK20fD/oMIf3I22YN7YwsL2fbnyRxZl4ajfgOiPvmOg199WuqxgcY4HFw2cyYfu47Lw1JS2FzmuHw0N5dvx4/nHA/v3QsmTGDfhg2ENGpUWWFXjMNB/Ukz2X/PQIp3Omk8J4WCbxZQ9OOJXIu35bD/7r7YA/sI6T2I+lNms39syXu43oQZFKz8mIP/dwMEh2Dq1KuqTLxSVFTMIzNe5qV/TKVVi6aM/P3/0f+y7pwXGX5SuydnJ3N5zxOD6XPbteX9OX87fv+VNyQx8PIelRq/HBcGbHG77QR6uTcwxoQB1wH9gZ6+eNJqVcFsGRPD/uxsDuTkUFxQQHZyMpHxpQfh+bt2sSs1leKCgpMeX3joEACOkBAcISFgbaXE7S89e/akcePGVR2GTzSNieFAdjaHXH27OTmZsDJ9e3TXLnJTU7Hl9G11EBkTw+7sbPbk5FBUUMDq5GS6lcmxW3w8q159FYAfV66kbmgojVq39vo5ut94I9/Nm+fTuM9YuxjYkw25OVBUAGuS4YIyfzwfO3Ti91r1S783f7kvKAQcIUBgv2/rRcdwLCebY5tzsAUF7JufTKPY0vkeTv2Worx9Jb9/t4KQNiUf2IU7t3NkXUkFuvjQQfKzNhDSOqxyEzhNLcoclzclJ9OunOPybg/H5XphYUQMGcL3c+ZUVsgVFtw5hiJnNsVbc6CwgKOfJRNyeelcC9d/iz1Q0reF/1tBUIuSvjX1GhJy0ZUc/fBFV8MC7MEA+2OwjLWZGzmnbSsi2rakVkgwQ/r35vNl353U7rX3FhN7RU+ahZb/B8K3q9cT0bYlYa1b+DvkGskYM9YYk+r2M7Zsk3IeVvZAOh2431pb5Ku4vB5gGmMuNMbcaIwZ/cuPr4LwVr2wMA5uOTEIP+R0Uj/M+4OvcTi4Pi2N0Tt38vOnn7Jz1Sp/hCkVUDcsjMNufXvE6aTuafSttZZ+n3zCNampdLjjDn+EeMYah4Wx1y3HvU4njcvkGFqmzT6nk1BXG2stSZ98wpTUVPqUk2OHK67gwI4d7MrO9lMGFdQ4DPa5/fG8z1myrawLh8OUDTBmIbx524ntxlEydf7nnZD1KWwO7PdtSJswCraeyLdgm5OQNp735SY3j+HAkpOnDkMizqHuhdEcXh3A1VpKjsuH3PbZw6d5XO49fTqrpkzBFhf7IzyfcrQIo3jniVyLdzkJauE519pDx3BsRUnfOtqei923i/rTXqLx3NXUv//fEOAVzB27c2ndstnx261aNGXH7r2l2+zK5bOvU0kYNsDj/7NwyQqGXn2Z3+KsUlU9PV5ciLV2trW2h9vP7DJROoEIt9vhwNYybXoAycaYH4GRwHPGmPKnHLzk1QDTGPMQ8C/Xz1XAE8CwX2l/fDQ9e3bZPCvOmHIG4adRhbTFxbwTHc1/wsNpERNDkwsu8FlscmbOtG8/69OHTy65hC/j4jhv3DhaXHGFD6PzDa9yLKeNdbV5pk8fHr/kEp6Li+OKcePoUCbHHomJpAZa9RIo94/n8vp2/fySafGXh0Pso25ti+GZaHg0HCJioHWAv29PY1+u36cfTRPHsO2x0qe5OOrV55w577D1wYkUHzzgjyh951f22VOJGDKE/J072bN6ta+j8o/TyDU4uh+1h4zh8POuvg0KJqhjd47Of56827pj8w9R97ceF/MGhPJSK3sc+8vM17j3zgSCgsofThwrKGTJ8u8Y1LdXufdLpUgBoowx7Y0xtYAEoNQJtdba9tbaSGttJPA2cJe1dv6ZPKm3FcyRwNXAdmvtrcBFQG1Pjd1H02PHlq3UVtwhp5MGEScG4fXDwzm0tewg/NSO5eWx7YsviBg0yGexyZk57HRSz61v64aHc+Q0+jZ/2zagZBr95/feo2lMjM9jPFP7nE6auOXYJDycvDI5lm0T6tYmz5XjwV27WPvee0S65egICuKiESNY/d//+jOFislzQgilHDMAACAASURBVKjbH8+h4bD/V/p209fQvAPUa1Z6e34ebPwCOgX2+7Zgq5OQtifyDWkTTsH2k/Ot07kr4U/N4cdb4inam3vijuBgznnxHfa9+zr7F71XGSGfkcNOJ/Xd9tl64eEc9vK926pPH9oNG8aNOTlclZxM2/796fvaa/4K9YwV73TiaHkiV0eLcIp3n5xrUIeuNHhgDgemxmP3l/Rt8S4nxbucFGaUVOCPLX2b4I7dKyfwCmrdoinbd54453vHrlxaNgst1Wb99zlMeuRZ+idMYPGXq3h4+st89k3q8fu/WrmGCzpG0rzp2XE6V3VkrS0EkihZHb4BeNNa+z9jzO+NMb/31/N6O8A8Yq0tBgqNMY0oWWF0rr+C8mRnSgqNo6JoGBmJIySE8xIS+GmB51Vt7uo0b04t1/mKQXXqEDZgAPsyM/0ZrpyG3JQUGkZFUd/Vt+0SEvjZy74NqleP4AYNjv/e+ppryFu/3p/hVshPKSm0iIqiWWQkQSEhdE9IYG2ZHNctWEDM6JKzTyJ79eJIXh77t2+nVr161HblWKtePc6/5hq2uuXYacAAdmRmsu/nnysvIW9tSYHmUdA0suQ8yosTTizo+UWzDid+D4uGoFpweA/Ubw51XB9MwXUgagDsDOz37eE1KdQ6N4qQdpGYkBBChyew/5PS+YaERXDO3HfZkjSKY5uySt0X8cyL5GdtYPesZyoz7ArblZJCo6goGrjeu+cmJLDZy/du6rRpJEdE8Gb79ixNSGDrkiV8OWqUnyOuuMLMFIIionC0iYTgEGoPSKBgWelcHa0iaPiXdzn46CiKt5zoW5u7g+KdW3BEdAQgpMfVFP2YUZnhn7au55/Ljz9vZ8u2nRwrKGThkhX0v+ySUm2WzJvOkuQZLEmeQWzfGB6aeAsD3BbzLFzyLUP6n6XT41Dl0+PeXgfTWrvIWtvRWtvBWvsX17YXrLUvlNP2Fmvt22f60ni7ijzVGBMK/Bv4DjgIVPqJULaoiG+Skhi8eDEmKIjv585lb0YGne+8E4ANs2ZRt1UrRqSmUqtRI2xxMV0nTuTNLl2o16YNV73yCiYoCONwsPHNN9m8cGFlp+BTkyZNYtWqVezdu5crr7ySu+++mxtuuKGqw6oQW1TEd0lJ9F28GEdQEJvmzmV/RgYdXH27cdYs6rRqxTWpqYS4+rbTxIks6tKF2s2bc/l7JZUeR3AwP73xBtsX++QyXj5VXFTEm0lJjHPtvyvmzmV7RgaXu3L8ZtYs/rdoERcMHsxD2dkUHD7Mf269FYCGrVpxhyvHoOBgUt94gw1uOV6SkBB4i3t+UVwE7yXBHYvBBEHKXNiRAZeW5M23s6Db9XDJ6JJFQAVH4LWbSu5r1AYSXil5nMMB6W/ChgB/3xYVsXVaEufOWwxBQeydN5ej32fQdHRJvrmvzqLVpAcJatKMsL8/B4AtKiQ7tif1YvrQ5IbRHMlYS9RnJYt9tv9tGgc+D9zLu9iiIr5NSmKQa7/+Ye5c9mVkcL5rv850HZfj3d67F06cyDtdulBwIMCn/8sqKuLQ00k0enoxOII4unAuRTkZ1I4vyfXo+7Ooe8uDmMbNqD/5OddjCsm7vWRR7qFn7qbhQ69DcC2Kt27i4N9urapMvBIcFMSD42/h9imPU1RczPVxfYlqH868BZ8BkPgr510CHMk/yvLv1vPIpDGVEa4EGOPtuTLHH2BMJNDIWrvWy4fYWeWdk3QWurOar0qviOQa0rcJ1pJUQ3IFeNZauLeG5PukZW3rGpIr0G275cUasi+PsZY9l9eMXAGafWNha+qpG54N2vaA8ldHV67k4VX/wZ8wv+pfh3J4fR1MY0w3IPKXxxhjzrPWvuunuERERESkmvJqgGmMmQt0A/4H/HItCQtogCkiIiIipXhbwextrT3peytFREREaiwvF9nURN6uIv+2vC9GFxEREREpy9sK5iuUDDK3A0cpObHWWmu7/frDRERERM5SqmB65O0Acy4wCljHiXMwRURERERO4u0Ac7O11rsr54qIiIhIjebtADPTGPMG8AElU+QA6DJFIiIiUmNpitwjbweYdSkZWF7jtk2XKRIRERGRk3g1wLTWBvb3WYmIiIhUNlUwPfLqMkXGmCeMMY2MMSHGmM+NMbuNMb/1d3AiIiIiUv14ex3Ma6y1+4GhgBPoCNznt6hEREREpNry9hzMENe/g4F51tpcYwLyu9VFREREKoemyD3ydoD5gTEmEzgC3GWMaQHk+y8sEREREamuvF3k84Ax5nFgv7W2yBhzCIj3b2giIiIiAUwVTI+8rWAChAEDjTF13La96uN4RERERKSa82qAaYx5COgHdAEWAXHAN2iAKSIiIiJleFvBHAlcBKRZa281xrQC5vgvLBEREZEApylyj7y9TNERa20xUGiMaQTsBM71X1giIiIiUl15W8FMNcaEAv8GvgMOAqv8FpWIiIhIoFMF0yNvV5Hf5fr1BWPMx0Aja+1a/4UlIiIiItXVrw4wjTHdf+0+a+1q34ckIiIiItXZqSqYT7n9bt1+N67b/X0ekYiIiEh1oClyj351gGmtvQrAGFMXuAu4nJKB5dfA836PTkRERESqHW8X+bwC7Af+6bqdSMk1MG/0R1AiIiIiUn15O8DsZK29yO32UmNMuj8CEhEREakWNEXukbfXwUwzxvT+5YYxphewzD8hiYiIiEh15m0Fsxcw2hiz2XW7HbDBGLMOsNbabn6JTkRERCRQqYLpkbcDzEF+jUJEREREzhreXmj9J38HIiIiIiJnB28rmCIiIiLiTlPkHhlr7albnRm/P4GIiIjUOKaqA2B6ZNWPcSb+WPWvQzkqpYL5sgnI3H3uFmtJriG5AiT4/4+TgLKyQc3p214HLQ/VkH35YWs5OrRm5ApQ+0PLrTWkb1+ylo3n14xcATpkWibWkL6dHiifP6pgeuTtZYpERERERLyiAaaIiIiI+JQW+YiIiIhUhKbIPVIFU0RERER8ShVMERERkYpQBdMjVTBFRERExKc0wBQRERERn9IUuYiIiEhFaIrcI1UwRURERMSnVMEUERERqQhVMD1SBVNEREREfEoDTBERERHxKU2Ri4iIiFSEpsg9UgVTRERERHxKA0wRERER8SlNkYuIiIhUhKbIPVIFU0RERER8ShVMERERkYooLqrqCAKWKpgiIiIi4lMaYIqIiIiIT2mKXERERKQiiqs6gMClCqaIiIiI+JQqmCIiIiIVoQqmR6pgioiIiIhPaYApIiIiIj6lKXIRERGRitAUuUeqYIqIiIiIT6mCKSIiIlIRqmB6pAqmiIiIiPiUBpgiIiIi4lPVboAZFhvLdZmZjMjKouv99590f+NOnRi8fDmj8vO5YPLkk+43DgfXrl7N1R98UBnhnrHWsbEMzsxkSFYWncvJt2GnTgxYvpwb8vPpVCbfa3NyGLR2LbFpaVyTklJZIfvN1KlTufTSSxk6dGhVh+ITjQfE0m11JhelZ9Fm0sl92+zGm+m6Ip2uK9Lp8tky6l3Y7fh97Z97ke45O+i6al1lhnxazouN5e7MTMZnZXF5OfsuQNyMGYzPyuIP6em0iY4+vv3SiRMZt349d61bx8g33iC4dm0AWnXrxu3Ll3PX2rXcvGABtRs2rJRcTpfpHkvIC5nUmp1F0MiTc3f0u5mQf6WX/PxjGab9ib4Nip9IyMz1hMxcR/B9b0BI7UqM3DsXxsby18xM/p6VxWAPfXvzjBn8PSuLR9LTOcetb6HkOPzn1auZ4HYc7jFyJI+tX8+LRUVEXnKJX+M/E3UvjyXio0zaLc4i9I6Tc28w9GbC308n/P10wuYto1anbqUbOByEv7ua1i8E5mfQ+bGxTMvM5I9ZWVztoW9HzJjBH7OymJKeTrhb39Zt3Jhb3nqLqRs2MDUjg8jevQEY9NBD/Nnp5L60NO5LS6NzXFyl5FIpigPgJ0BVqwGmcTjoNXMmn8bFMb9LF9onJtK4c+dSbY7m5rJy/HjWP/lkuf9H5wkTyNuwoTLCPWPG4aDHzJl8GRfHR1260C4xkUZl8j2Wm8vq8ePJ9JDvkquuYnF0NJ/07FkZIfvViBEjmDNnTlWH4RsOB5FPz+T7EXGs7dGFZjckUvf8MvvyTzlkDOrLut4X8fPjj9L+X7OP37f79ZfJHD6okoP2nnE4GDJzJv+Ji2Nmly50TUykRZl9NyoujmZRUfwzKooPxo5l6PPPA9CwbVt6jR/PrB49eK5rV0xQEBcmJAAQP2cOnz7wAM9168aG996jz333VXpup+RwEPKHmRQ8FMexu7rg6JuIiSidu92eQ8EDfSm4+yKKkh8lOMnVt83aEnTteAru6UHBuK7gCMJxZUIVJOGZcTgYNXMmz8TF8ccuXeiVmEjbMn3bLS6OVlFRPBAVxctjxzLK1be/GDhhAtvKHId/Xr+eZ0eM4IevvvJ7DhXmcNDiwZlsuyOOzUO70GBIIiEdSude8HMOW0f1xRl/EXufe5QWj8wudX/j0RM4tikwP4OMw8HImTOZFRfH37t0oXtiIq3K9G3nuDhaREXxl6go/jt2LDe49e11M2aQ+fHH/K1zZ5646CJ2uPXxl888wz+io/lHdDQbPvqo0nKSqlOtBpjNY2I4kJ3NwZwcigsKyElOpl18fKk2+bt2sSc1FVtQcNLj64WFET5kCD9Uk0FKU1e+h1z5bk5OJqxMvkd37SLXQ75nm549e9K4ceOqDsMnGvSIIX9TNkd/zMEWFJD7djJNhpTu24Mrv6Vo376S31NWUCss/Ph9B5Z9TeHe3EqN+XSExcSQm53N3pwcigoKWJ+czPll9t3z4+NZ8+qrADhXrqROaCgNWrcGwBEcTEjdujiCggipV48DW7cC0KxTJ35yDUA2fvopna+/vhKz8o7pGIPdlg07cqCwgOKvknH0Lp27zfwWDpX0bXHmCkzzE31LUDDUqguOIKhdD5u7tTLDP6VzY2LYmZ3NLlffrkpOJrpM30bHx7Pc1bebVq6kXmgojV192yQsjIuGDOGrMsfhbZmZbP/hh8pJooJqd4uhYHM2hc4cKCjg4KJk6l9d5pic9i3F+0v6Nj99BcGtT/RtUKsw6vUdwoG3AvMz6JyYGHZnZ7PH1bdpycl0LdO3XePjSXH17U8rV1I3NJRGrVtTu2FDOlx5JStefBGAooICjuTlVXoOla6qq5eqYPpGvbAwDm3Zcvz2IaeTemFhXj8+Zvp0vpsyBYoDuEfc1A0L47BbvkecTuqeRr7WWvp98gnXpKbS4Y47/BGiVFCttmEcc57o22M/Owlp67lvW4wew75Pqs9f/Y3Cwshz23fznE4altl3G4aFsd+tzX6nk0ZhYRzYupXlTz7JPZs3c++2bRzNy2Pjp58CsHP9ejoNGwbABTfcQOOIiErI5vSYZmHYXSfysrudmGae+zbomjEUp7r6ds9Wit57klovbabWa9vgcB427VN/h3xamoSFkevWb7lOJ03K9G1omTZ73dokTp/Om1OmUFxNjsPugluFUbjtRF6F250Et/Lctw1HjuHwVyfet82nTWfPk1OwNjBzbxwWxl63ftvndNK4TN96atP83HM5uGsXN7/0EveuXs1N//43terVO97uiqQkpqSnk/jii9QNDfV/MlLlvBpgmhK/NcY86LrdzhgT49/Qyg3k5G3WevXQ8CFDyN+5kz2rV/s4KP8xZ5AvwGd9+vDJJZfwZVwc540bR4srrvBhdHJGTqNvG13Zj5a/G8OWB8s/HyogeZFfefu3tZY6oaF0io9nevv2PNm2LSH169PtN78B4P3bbiNm3DjuTE2ldsOGFB075pfwz4z3fWu69sNxzRgKX3b1bf1QHL3iOTamPcdGt4Xa9XH0+43/Qq0ID/1Wukn5bS4aMoQDO3fyUzU6Dpfmfd/W6dWPRtePYc9TJX1br98Qivbs5Nj/Ajh3L/rWUxtHcDDh3buz7PnnebJ7d44dOsTVDzwAwDfPP8+jHTrwj4svJm/bNoY/9ZRfwpfA4m0F8zngUiDRdfsAMNNTY2PMWGNMqjEmdfbs2Z6anbbDTif13SoW9cPDObzVu+mjln36EDFsGCNzcuibnEyb/v254rXXfBabPxx2Oqnnlm/d8HCOeJkvQP62bUDJNPrP771H05jK/5tAynfsZye1wk/0ba2wcAq2ndy3dS/oSvtn5/DDTfEU5gbulHhZ+53OUtXFxuHhx6e53ds0cmvTyNXm3AED2JeTw+HduykuLGTDu+8ScdllAOz+/ntei41lVo8erJs3j9yNGysnodNg9zgxLU7kZZqHlzvNbSK7EjJ+DoWPxsOBkr51XDwAuyMH9u+GokKKv30XR+fLKit0r+x1Omnq1m9Nw8PZV6Zvy7Zp4moT1acPFw8bxj9ycvhDcjKd+/dnbIAfh90V7nAS3OZEXsGtwynceXLf1urYlZaPzmH7uHiK95X0bZ3ufajffxjtPs+h1VPJ1O3Vn5ZPBFbueU4nTdz6LTQ8nP1l+tZTm31OJ3lOJz+tWgVA+ttvE969OwAHd+7EFhdjrWXFv/9Nu7Pps6iqp8cDsxgOeD/A7GWtHQfkA1hr9wK1PDW21s621vaw1vYYO3asD8IssTslhUZRUTSIjMQREkL7hAS2LFjg1WNXT5vGWxERvN2+PV8mJLBtyRK+HjXKZ7H5Q25KCg2joqjvyrddQgI/e5lvUL16BDdocPz31tdcQ9769f4MV07Dwe9SqNMhitrnRGJCQmg6MoG9i0r3ba3wCDq+8S4b7xhFfnZWFUVaMVtTUmgaFUVoZCRBISFcmJBAZpl9N3PBAi4ePRqA8F69yM/L4+D27eRt3kx4796E1K0LwLlXX81u12KB+i1aACUVsiv/9CdSX3ihErPyjv0hBdM2ClpFQnAIjisTKF5Z5n3bIoKQae9S8NQo7NYTfWt3bcZ06g21S3J3XHQ1xVsCa0FITkoKLaOiaO7q25iEBNLK9G3aggVc5urbc3v14kheHnnbt/P2tGlMjojgvvbteT4hgQ1LljA7wI/D7o6uSyHknCiCwyIhJIQGgxM4tKR07sFtImj9r3fZcf8oCn480be5T0/jp34RbL66PTsmJ3Bk5RJ2Tgms3DenpNA8Koqmrr6NTkhgfZm+Xb9gAT1dfXuOq2/3b9/OgR072LtlCy07dgSg49VXsyMjA4BGrvNvAbpedx3b9FlUI3j7TT4FxpggwAIYY1pQBeNmW1TEiqQkBi5ejAkKInvuXPZlZNDpzjsB+H7WLOq2asXQ1FRCGjWC4mK6TJzI/C5dKDhwoLLDPWO2qIjvkpLou3gxjqAgNs2dy/6MDDq48t04axZ1WrXiGle+triYThMnsqhLF2o3b87l770HlCyY+OmNN9i+eHFVpnPGJk2axKpVq9i7dy9XXnkld999NzfccENVh1UxRUX8ODmJTvNL9uVdr83lyIYMWo4p6dudL84i7IEHCW7ajMhnngPAFhbyvytLrgbQ4aU3aHRFP4KbNSf6+y04//IQu16dW2XplFVcVMSipCRGufbdtLlz2ZWRQQ/Xvps6axZZixbRcfBgJmRnU3D4MPNvvRWAn1etIuPtt7lz9WqKCwvZnpZGqmsmpGtiIj3HjQNgw7vvkvbSS1WT4K8pLqLwhSRCHlmMcQRR9Olc7OYMHHEluRd/NIvghAehUTOC7yrpW4oKKbinJ/aHVRQve5uQ6auhuBC7MY3ij303C+QLxUVFvJ6UxGRX3349dy5bMzLo5+rbL2bNYu2iRXQbPJjHs7M5dvgwL7r69td0Hz6c3/zrXzRs0YKJCxeyZc0anhoUYFdKKCpi96NJtHmxpG/3vzOXguwMGt1Ukvv+/86iyV0P4ghtRosHXe/bokJ+Hlk9ruJRXFTEO0lJ/N7VtyvnzmV7RgaXufp2+axZZCxaROfBg/mTq2/nufXtu3ffzW9ff53gWrXYs2kTb7juu/aJJwi7+GKwltwff+RN1/93VgjgCmJVMyedX1FeI2N+A9wEdAdeAUYCf7LWvuXFc9iXyzsf6yx0i7Uk15BcARJO43zQs8HKBjWnb3sdtDxUQ/blh63l6NCakStA7Q8tt9aQvn3JWjaeXzNyBeiQaZlYQ/p2esnnT9UnO9FU/QfhdFv1r0M5TlnBNMY4gBxgCnA1JR063FobWPM2IiIiIhIQTjnAtNYWG2OestZeCmRWQkwiIiIigU9T5B55u8jnE2PM9abc6+aIiIiIiJzg7SKfSUB9oNAYk0/JNLm11jbyW2QiIiIiUi15NcC01jb0dyAiIiIi1YqmyD3yaoBpjLmyvO3W2q98G46IiIiIVHfeTpHf5/Z7HSAG+A7o7/OIRERERKoDVTA98naK/Fr328aYCOAJv0QkIiIiItWat6vIy3ICF/oyEBERERE5O3h7Dua/cH1NJCWD0ouBdH8FJSIiIhLwNEXukbfnYKa6/V4IzLPWLvNDPCIiIiJSzXl7DuYrv/xujGkCRPgtIhEREZHqQBVMj7w6B9MY84UxppExpiklU+MvGWOe9m9oIiIiIlIdebvIp7G1dj8wAnjJWnsJMMB/YYmIiIhIdeXtOZjBxpg2wI3AH/0Yj4iIiEj1oClyj7ytYD4CLAayrbUpxphzgSz/hSUiIiIi1ZW3i3zeAt5yu70JuN5fQYmIiIgEPFUwPfJ2kc8TrkU+IcaYz40xu40xv/V3cCIiIiJS/Xg7RX6Na5HPUEq+xacjpb+fXEREREQE8H6RT4jr38GUXGQ91xjjp5BEREREqgFNkXvk7QDzA2NMJnAEuMsY0wLI919YIiIiIlJdebvI5wFjzOPAfmttkTHmMBDv39BEREREApgqmB55u8inHjAOeN61qS3Qw19BiYiIiEj15e0in5eAY8BlrttO4DG/RCQiIiIi1Zq3A8wO1tongAIAa+0RQKt8REREpOYqDoAfLxhjBhljvjfGZBtjHijn/nhjzFpjzBpjTKox5vLTfSnK8naRzzFjTF3AugLpABw90ycXEREREf8xxgQBM4GBlMxApxhjFlhrM9yafQ4ssNZaY0w34E3g/DN5Xm8HmA8BHwMRxpjXgT7ALWfyxCIiIiLVWvVY5BNDyVd9bwIwxiRTslD7+ADTWnvQrX19XAXFM3HKAaYxxgE0AUYAvSmZGp9grd19pk8uIiIiIhVnjBkLjHXbNNtaO9vtdhiwxe22E+hVzv9zHfA3oCUw5EzjOuUA01pbbIxJsta+CSw80ycUEREREd9wDSZn/0qT8tbMnFShtNa+B7xnjLkSeBQYcCZxeTtF/qkx5l7gv8Aht2Byz+TJRURERKqt6jFF7gQi3G6HA1s9NbbWfmWM6WCMaX4ms9XeDjBvo2S0e1eZ7edW9IlFRERExO9SgChjTHvgZyABuNm9gTHmPGCja5FPd6AWsOdMntRYe+rzOF0ryO8CLqdkoPk18ILrckWncsYnioqIiIiUUfWXS0wwVT/GSbanfB2MMYOB6UAQMNda+xdjzO8BrLUvGGPuB0ZTcjnKI8B91tpvziQsbweYbwL7gdddmxKBUGvtjV48h21hqn4fqAy7rCWphuQK8Ky1rGxQM/LtdbDqjyGVLvWFqo6gcvT4PSQPr+ooKk/CfD6tIcepgdZiakiuANZaptSQfJ8oGbtUfbI3BsAA881TDzCrgrdT5J2stRe53V5qjEn3R0AiIiIiUr15O8BMM8b0ttauADDG9AKW+S8sERERkcBmA2CRT0CWL/F+gNkLGG2M2ey63Q7YYIxZB1hrbTe/RCciIiIi1Y63A8xBfo1CRERERM4aXg0wrbU/+TsQERERkeqkOACmyIOqOgAPHFUdgIiIiIicXbydIhcRERERN4GwyCdQqYIpIiIiIj6lAaaIiIiI+JSmyEVEREQqIBAW+QQqVTBFRERExKdUwRQRERGpAC3y8UwVTBERERHxKQ0wRURERMSnNEUuIiIiUgFa5OOZKpgiIiIi4lOqYIqIiIhUgCqYnqmCKSIiIiI+pQGmiIiIiPiUpshFREREKkDXwfRMFUwRERER8SkNMEVERETEpzRFLiIiIlIBmiL3TBVMEREREfEpVTBFREREKkDXwfRMFUwRERER8SkNMEVERETEpzRFLiIiIlIBWuTjmSqYIiIiIuJTqmCKiIiIVIAW+XimCqaIiIiI+FS1GWD+dcYMVmVl8UV6Ot2io8tt0y4yko9XrGDlDz/w7+RkQkJCAGjYqBH/WbCApWvW8PX69STecgsAbcPDeW/JEpZlZPD1+vWMHT++stL5VZ1jY/m/zEweyspi4P33l9tm5IwZPJSVxdT0dMLdXo+Hc3KYtnYtD6SlMSUl5fj2W5OTeSAtjQfS0ng4J4cH0tL8nsfpajwglm6rM7koPYs2k07Ou9mNN9N1RTpdV6TT5bNl1Luw2/H72j/3It1zdtB11brKDNlvpk6dyqWXXsrQoUOrOhSf+Cr9R2LvfZmBk+Yye8Eqj+3WbtxO599O5+OVP5TaXlRczPBp/+HOf8z3d6g+8VXWQWL/uZGBM7KZ/fXuk+7/LPMA1z63ifjnNzFiVg6pPx0+ft8r3+YydOYmhjy7kZe/za3MsCusWWwsl2Vm0icri8hyjln1OnWi5/LlXJ2fzzmTJ5e6r93EiVy6fj2XrltH1zfewFG7dmWFXWEzZswgKyuL9PR0oj18Ho0bN46srCystTRr1uz49k6dOrF8+XLy8/OZXOa1CAQdY2O5LzOTKVlZ9PPw+TNsxgymZGVxT3o6Ya78W3TsyMS0tOM/j+TlcfmECQAMfOgh/uh0Hr/v/Li4SstHqk61GGAOiIvj3KgoYqKimDx2LE88/3y57R58/HFe+H/27j0uyjL///jrGkA8pJJ4IIHUFE3MA6lo2dE0RU3MzV3YttrWtK1M7XzY/dW2Hb7Z2qrfTUu/Zqet2EozS8vc7GwqpKKkJBimk+IJxAMqh1oPrgAAIABJREFUp+v3B5PCADrgDAz6fj4e84C55xrm85l77vu++Fz3dc+0afTr3Jn9ubncOHYsAGPvuosfN27k6l69GHXVVTzx/PMEBQVRXFTE4/fdx4DoaIb278+f7rqLzl271mZqFRiHg9/OnMmsuDieio6md2IiYW4xRcfF0Soqiieionh7/HgS3N6PGVdfzbMxMTzXt+/xZa8kJPBsTAzPxsSwbv581i1YUCv5eMzhoP0/Z/Lj6DjW94kmdEwijS4sn/exn7PYOPRKNvTvyS9TnqTDv+Ycf2zvm6+SPmpoLQftO6NHj2bu3Ll1HYZXFJeU8PdXlzP3wVEsfu4WPvruRzKd+yptNzXpGy7r0a7CY69/spaObVvURrinrbjE8vfF2cz9QySL7+rIRxsOkLn7WLk2l3RowqI7OvDBHRfwTPx5/HXRTgA27zrKu2v28+649nxwxwV8sfkgW/cV1EUannM4uHDmTNbGxbEiOpqwxESauO2zCnNy+HHiRLZOnVpueXDbtpw/cSKr+vThu+7dISCANgkJtRl9tcXFxREVFUVUVBTjx4/nxSqOR99++y2DBg1i69at5Zbn5OQwceJEprq9F/7AOBxcP3MmL8fF8Xx0NL0SE2ntti4vjIujZVQUz0VFMX/8eK535b9n82amx8QwPSaGGb17U5ifT9r77x9/3tfTph1/PP3jj2s1L1+yJXV/81f1ooM5ND6e/7z+OgDfr1pF85AQ2oSFVWh32cCBfPjeewD857XXGDZqFADWWs5p2hSAJuecw/6cHIqKitiVnc16VyXv8KFDbN60ifPCw2sjpSq1j41lb2Ym+7KyKC4sZE1SEj3i48u16REfz2rX+7F11SoahYTQrJL3oyoX//a3fP/2216N+3Sd0yeWoz9lcmxrFrawkJz3kjh3ePm8D636juL9+0t/T15Jg/CI448d/PZrinLrR7XHE3379qV58+Z1HYZXrN+STbs2IUS2DqFBYADD+3fhs++3VGj3xtJ1DOnbidBmjcstz953kC/WZXHD1RfVVsinZf0vR2jXogGRLRrQINAw/KJmfJZ+sFybJsEOjDEAHCkswbiWb9lbQM+IhjRq4CAwwNC3XWOWbTqIP2seG0t+ZiZHskq33eykJFq57bMK9+zhQEoKtrCwwvNNYCCORo0wAQEENG7MsR07aiv0GomPj+d11/531apVhISEEFbJ/nfdunX8/PPPFZbv2bOHlJQUCit5L+papOv4k+M6/qQmJdHNbV1Gx8ezxpX/Ntfxp6lb/p2uuYZ9W7awf9u2Wotd/M8pO5jGmEnGmGam1MvGmDXGmGtrI7hfnRcezo7t24/f3+F0EubWEWwRGsqB/fspLi6u0GbuCy/QuWtX0nbs4KsNG/jLpElYa8s9P7JdO7rHxPD9qlU+zubkmoeHk1sm11ynk+ZuuYa4tdnvdBLiamOtZcKnn/JgSgoDxo2r8Pc7Xn45B3ftYk9mpo8yqJkGbcMpcJ7IqeAXJ0Ftq+7st7p5LPs/PXP+Cz6T7co5RFho0+P327Q4h125hyq0+W9KJgmDerg/nWfe+IIHEi/HYUyFx/zRrgNFhDU/MX+yTfMgdh0sqtBu2aYDDP3XFm5/czvPjDoPgM6tg0n5+Qi5+UUcKSjhq4zDZOf5X0ekrODwcI6V2R8dczoJ9vAf9WM7drB16lQu37aNK3bupCgvj5xly3wVqleEh4ezvUy+TqeT8DouTHhL8/Bw8srklud00swtt+bh4ex3O/64H6N6JSSwzq2IcemECdyTmsqYl1+mUUiID6KvGyUldX/zV55UMP9krT0AXAu0Am4Fnj3ZE4wx440xKcaYlDlz5pysqUdMJQcW9w7iydoMHDKEtHXruKhtW67u1Yv/eeGF4xVNgCZNmvDK/Pn8dfJkDh2s22pBZXnglisnyXXagAFM6d2bWXFxXH7XXXS8/PJy7fokJpLiZ9VLoNKcKuTt0uyKq2h9y1i2P1b5+UHiXypbi+6f86ff+IL7Ey4nwFF+l/T5mp9o0bwxF3Vo48MIvavSfCtZNrhrMz65uyMzEyKZsXwPAB1bBXPbgFD+9Po2bvv3NrqEBRPg8POOdTW2XXeBISG0jo/nmw4d+KptWwKaNCHsxhu9HKB3eXI8qrdO8/gDEBAURPTIkax/993jy7578UWmdOzI9F69OLBzJyOef95rIYv/8uQyRb9+moYBr1hrU02lvaATrLVzgF97lvYvt99e7cD+dOed3OSqwK1NTqZtZOTxx9pGRLDLbRhl3969NAsJISAggOLi4nJtEm+9lf99trRPnLVlC9uysoi68ELWJicTGBjIK/Pn896bb7K4zPkidWW/08m5ZXI9NyKCPLdc3duElGmTt7P0XK5De/aw/v33aR8by5avvwbAERBAz9Gjea53b1+nUW0FvzhpEHEipwbhERTurDhU1qhbdzq8MJcfR8dRlHPmDImfycJanEP2vhP/uO3KOUTrkCbl2qRl7eLeF5YAkHvwCF+mZhEY4CA1M5vl3//EV+u2cqywiENHCrh/1sdMvdN/JwmENQskO+9ExXJXXiGtm1a9q+3bvjHb3i8k53ARLZoEMqZ3CGN6l1Z4/vnf3bRp5t9XkzvmdBJcZn8UHBHh8TB3i0GDOJKVReHe0olQuxcsIOTSS8l+802fxFpTd955J+Ncx6Pk5GQiy+QbERHBDj8f1vdUntNJ8zK5NY+I4IBbbnlOJyFux5+ybbrExfHLmjUc2r37+LKyv6/+v//j1o8+8kX44mc8qWB+b4z5lNIO5lJjTFPA50XZebNmcXVMDFfHxPDxwoX87uabAejdrx8H8vLYlZ1d4Tnffv45191wAwC/u+UWPv7gAwCc27Zx+TXXANCqdWs6denCzz/9BMD0l19m86ZNvDRtmq9T8sjPycm0iooitH17AoKCuDghgfWLFpVrs2HRImJd70f7fv04kpfHgexsGjRuTPA55wDQoHFjLrz2WnakpR1/XpdBg9iVns7+X36pvYQ8dOj7ZBp2jCK4XXtMUBAtbkggd0n5vBtERNL5rQVsGXcTRzMz6ihSqa7uF4SxNTuX7bvzKCgqZvHKHxnY+4JybZZPH8vyGaW3IbFRPP7HgQzq04n7Ei7jqxfGsXzGWP45YRj9oyP9unMJ0L1tI7bmFLA9t4CCIsvitAMMvLBpuTY/7ys4XvX5YccRCost5zYOAGDfodLO6Y79hXy66SAjuvv3ubgHkpNpHBVFw/al225YQgJ73PZZVTm6bRvN+/fH0agRAC2uuYbDmzb5MtwamTVrFjExMcTExLBw4UJudu1/+/XrR15eHtmVHI/qI2dyMi2jojjXdfzpmZDARrd1uXHRIi525X++6/hzsEz+vRITKwyPlz1H86Lrrye7zHGpvqvr4XF/HiL35F/jsUAv4Cdrbb4xpgWlw+S1ZtmSJQwaNozVmZkcyc9n4q0nXv7txYuZfNtt7Nq5k78/9BBzkpJ49Kmn2LB2LW++/DIAzz/5JP969VW+XL8eYwx/f+ghcvbto9+AAfzu5pv5Yf16PndN9nn60Uf5bx3OcCspLuadCRO4a+lSTEAAK+fNI3vjRi5zVYG/mT2bH5YsoduwYTyemUlhfj7/dr0fTdu0YZyrChsQGEjKW2+xaenS43+7d0KC303uOa64mK33TaDLwtK897wxjyObNtJ6bGneu1+eTfjDjxHYIpT202YBYIuK+OGK0pnyHV95i2aXX0VgaEtiftyO8+nH2fP6vDpL53Tde++9rF69mtzcXK644gruvvtuxowZU9dh1UhggIPH/jiQ26YsoLjE8psruxEV0ZK3/5sKQOKgnnUcoXcFBhgeGxbGbW9sL803JoSo1sG8nZwLQGLfc1m68QAfpOYRGGBoGOhg2pjw40Ovd//Hyf4jxQQ6DI8PD6N5o4C6TOeUbHExP06YwMWufdaOefM4vHEjEa59lnP2bBq0aUO/lBQCmzXDlpRw/uTJrIiO5sDq1ex67z36r1mDLSriwNq1OL1wWpUvLVmyhGHDhpGZmUl+fj63ljkeLV68mNtuu42dO3dy99138+CDDxIWFsb69etZsmQJ48aNo02bNqSkpNCsWTNKSkqYPHky0dHRHKzj07Og9PjzwYQJ3LZ0KY6AAJLnzWPXxo30d63LlbNnk75kCRcOG8ZDmZkU5Ofzbpn8gxo1ImrwYBa4jVoOe+452vbqBdaSu3Ur82swqin1jznVuSPGmAHAOmvtYWPMH4CLgRnW2orT4ypnW9WTk/NP1x5rmXCW5ArwgrWsOufsyLffoTPkHKvqSHmpriOoHX3+DEmj6jqK2pOwkGVnyX5qsLWVn9d+hrLW8uBZku9zpX2XOk82O9bU+cEhbLWt8/ehMp4Mkb8I5BtjegIPAj8Dr/s0KhERERGptzzpYBbZ0jJnPKWVyxlA01M8R0RERETOUp6cg3nQGPMIcBNwuTEmAAjybVgiIiIi/s2fJ9nUNU8qmL8DjlF6PcxsIBz4h0+jEhEREZF665QVTGtttjFmPhDlWrQXqPsLRoqIiIjUIX/+LvC65slXRY4D3gNmuxaFAwt9GZSIiIiI1F+eDJHfBQwADgBYazOA1r4MSkRERETqL08m+Ryz1hb8ei0xY0wglX/droiIiMhZQ0PkVfOkgvmlMeZRoJExZjDwLvChb8MSERERkfrKkw7mw8AeYANwO7AE+KsvgxIRERGR+suTWeQlwP+5biIiIiKCroN5MqfsYLq+i/xvQDtXewNYa+0Fvg1NREREROojTyb5vAzcA3wPFPs2HBEREZH6QZN8quZJBzPPWvuxzyMRERERkTOCJx3Mz40x/wAWUPqVkQBYa9f4LCoRERERqbc86WD2c/3sU2aZBQZ6PxwRERGR+kGTfKrmSQczzlp7tOwCY0yoj+IRERERkXrOk+tgznd9ew8Axpgw4FPfhSQiIiLi/0pK6v7mrzzpYC4E3jPGBBhj2lPauXzEl0GJiIiISP3lyYXW/88Y04DSjmZ74HZr7QpfByYiIiIi9VOVHUxjzL1l7wKRwDqgvzGmv7X2n74OTkRERMRf6TqYVTtZBbOp2/33q1guIiIiInJclR1Ma+0TtRmIiIiISH2iCmbVTjnJxxizzBgTUub+ucaYpb4NS0RERETqK09mkbey1u7/9Y61Nhdo7buQRERERKQ+8+RC68XGmPOttdsAjDHtKP0mHxEREZGzlj9fh7KuedLB/AvwjTHmS9f9K4DxvgtJREREROozT66D+Ykx5mKgP6WXK7rHWrvX55GJiIiI+DFN8qlaledgGmMudP28GDgf2AH8ApzvWiYiIiIiUsHJKpj3UjoU/nwlj1lgoE8iEhEREZF67WTXwRzv+nl17YUjIiIiUj9okk/VjLWnnhBujLmU0u8hP94htda+7uFraMa5iIiIeJup6wA2nm/qvI8Tvc3W+ftQmVNO8jHGvAF0pPR7yItdiy3gaQeT84xf5u51O62F+8+OXAGYann8LFm3T1gLKS/VdRi1p8+f6zqCWvVNg7PjcwxwWYFl2Vmy3Q62lu5nSa4AG6xl9lmS7+0eFMdqgyb5VM2TyxT1AaKtJ6VOERERETnrefJNPmlAmK8DEREREZEzQ5UVTGPMh5QOhTcFNhpjVgPHfn3cWjvS9+GJiIiI+CdN8qnayYbIp1J6Au0UYFSZ5b8uExERERGp4GSXKfoSwBgT9OvvvzLGNPJ1YCIiIiJSP51siPwO4E7gAmPM+jIPNQW+9XVgIiIiIv5Ms8irdrIh8reAj4H/AR4us/ygtTbHp1GJiIiISL11siHyPCAPSKy9cERERETqB03yqZonlykSEREREfGYOpgiIiIi4lWefJOPiIiIiLjRJJ+qqYIpIiIiIl6lCqaIiIhIDWiST9VUwRQRERERr1IHU0RERES8SkPkIiIiIjWgST5VUwVTRERERLxKFUwRERGRGtAkn6qpgikiIiIiXqUOpoiIiIh4lYbIRURERGpAk3yqpgqmiIiIiHiVKpgiIiIiNaBJPlVTBVNEREREvEodTBEREZEzmDFmqDHmR2NMpjHm4Uoev9EYs951W2GM6Xm6r6khchEREZEaqA9D5MaYAGAmMBhwAsnGmEXW2o1lmmUBV1prc40xccAcoN/pvK4qmCIiIiJnrlgg01r7k7W2AEgC4ss2sNausNbmuu6uBCJO90VVwRQRERGpAX+4TJExZjwwvsyiOdbaOWXuhwPby9x3cvLq5Fjg49ONSx1MERERkXrK1Zmcc5ImprKnVdrQmKsp7WBedrpxqYMpIiIicuZyApFl7kcAO9wbGWN6AHOBOGvtvtN90XpzDuaTM2awIiODz1JT6R4TU2mbyPbtWbxyJd9u3sxLSUkEBQUBcMf997Ns7VqWrV3L5xs24CwqIuTcc48/z+Fw8OmaNbz+4Ye1kku1dBkCD6bDwxlw9UMVH+82Eu5NhXvWwqRkaD+gdHlgMExcBfeug/vT4Nq/1WrYnuo0ZAh3p6czMSODyx6qJD8gbsYMJmZkcEdqKueVWfeXTJ7MXWlp3LlhAze89RaBwcEAtOnRg9tWrODO9ev5/aJFBDdtWiu5VNdXqVsZcv+rDL53HnMWra6y3fot2XT9w3Q+WbW53PLikhJGPfpvbv/HQl+H6nOPPPIIl1xyCSNGjKjrULwu5NohXJyWTu+NGUQ8UPEz3irx98R8n0rM96n0+PJbmvToUQdRnp7QIUO4ND2dARkZtK9kO27cpQt9V6zgmqNHaXfffeUei5w4kUs2bOCStDTOnzSptkKutodnzGBxRgbzU1PpWsUxKLx9e95cuZKPNm/mH0lJBLqOQb/q1qcP64qKGPyb3wDQJiKCl5cv54ONG3k/LY0bJ070eR7VFTlkCL9LTychI4NelazbkC5dGLViBbcdPUqPMus2IDiY61et4oZ16xiTlkafv/2tFqOuPbak7m8eSAaijDEdjDENgARgUdkGxpjzgQXATdbazZX8jWqrFx3MgXFxXBAVxaVRUTwwfjzPvvhipe3+OmUKc6ZNY0DnzuTl5pI4diwAL06dyuCYGAbHxPDMI4/w3Zdfsj839/jzxk2aRMamTbWSS7UYB1w/E+bGwT+iISYR2nQt3ybjM/hnT5gWA+/8CX47t3R50TF4aSD8s1fp7cKhcP5pTQjzOuNwMHzmTP4dF8fM6Gi6JybSqmv5/KLi4giNiuJ/o6L4cPx4RrjWfdO2bek3cSKz+/RhVvfumIAALkpIACB+7lyWPfwws3r0YNP77zPggQdqPbdTKS4p4e+vLmfug6NY/NwtfPTdj2Q6K/7DWFxSwtSkb7isR7sKj73+yVo6tm1RG+H63OjRo5k7d25dh+F9DgcdZ8zkh+viWNMzmla/S6SR22f8aFYW66+5krW9e7L9mSfpNOtkI11+yOHgwpkzWRsXx4roaMISE2nilmNhTg4/TpzI1qlTyy1v0q0bEePGsSo2lpU9e9JyxAgad+pUm9F75PK4ONpFRTE8Koonxo/nr1Ucg+6ZMoU3pk1jROfOHMjNZbTrGASlhYx7pkxhxdKlx5cVFxUx9b77iI+O5sb+/Um46y4ucHvv6pJxOBgwcyZL4uJ4JzqaTomJhLh/fnNy+HbiRFLd1m3xsWN8OHAg7/XqxfxevYgYOpTW/fzrGHS2sNYWAROApcAm4B1r7Q/GmD8bY/7savYYEArMMsasM8aknO7r1osO5tD4eN59/XUA1qxaRbOQEFqHhVVod9nAgXz03nsAvPPaa8SNGlWhzajERBa+/fbx++eFh3PN8OG85Y8Ht/NjYV8m5GRBcSGsS4Ju8eXbFBw+8XuDJmBtxccCgsARRBWnXNSZ8NhYcjIzyc3KoriwkLSkJC6ML5/fhfHxrHOte+eqVTQMCeEc17p3BAYS1KgRjoAAgho35uCO0op/aJcu/PzVVwBsWbaMrq5qgT9ZvyWbdm1CiGwdQoPAAIb378Jn32+p0O6NpesY0rcToc0al1ueve8gX6zL4oarL6qtkH2qb9++NG/evK7D8LqmfWM5uiWTY1lZ2MJC9ryTROh15T/jB1d+R/H+/QAcWLWSBuGnPXmzVjWPjSU/M5Mjrhyzk5Jo5bYdF+7Zw4GUFGxhYbnlTbp2JW/lSkqOHMEWF5P75Ze0uv762gzfI1fHx7PItR9av2oVTUNCaFnJMSh24ECWuY5Bi157jYFljkG/v/tu/jt/Pjm7dx9ftjc7m01r1wKQf+gQWZs20SY83JepVEvr2FgOZGZyMCuLksJCMpOSaO+2bo/u2cOelBRK3NYtQNHh0mOQIygIR1BQ+eOT1Cpr7RJrbWdrbUdr7dOuZS9Za19y/X6btfZca20v163P6b6mxx1MY0yAMaatMeb8X2+n++KeCgsPZ8f2ExOgdjqdnOe2EbYIDSVv/36Ki4uPtwlza9OoUSOuHjqUxfPnH1/29+nTeerBBynxx4tZNQ+H/WUmfu13li5zd9EoeHATjF1cWsX8lXGUDp3/bTdkLINtVQ/D1oVm4eHklVmveU4nTd3WWdPwcA6UaXPA6aRZeDgHd+xgxdSp3LNtG/fv3MmxvDy2LFsGwO60NLqMHAlAtzFjaB4Zib/ZlXOIsNATQ/dtWpzDrtxDFdr8NyWThEEVh0yfeeMLHki8HIep7Nxt8RcNwsM55jzx+T32i5MGbavuQITdOpbcpac9ebNWBYeHc6zMNnrM6STYw07S4bQ0Qq64gqAWLXA0akTLYcNo6Ifba+vwcLLL5LjL6aS1W44hoaEcLHMMyi7TpnXbtlxz/fW889JLVb5G23btuDAmhvWrVvkgg5ppHB7OoTJ5H3Y6aVKNDrBxOPjN2rXcvHs3vyxbxu7V/nUM8oaSkrq/+SuPOpjGmLuBXcAyYLHr9pEP43J//QrLrNt/Qp60GXzddSR/++3x4fFBw4ezd/du1q9Z48VovamSzkNl/wGmLYTnusKro2DIk2XalpQOnT8ZAZGxENbNd6HWRGWdIw/Xa8OQELrExzO9Qwemtm1LUJMm9LjxRgA++NOfiL3rLm5PSSG4aVOKCwp8Ev7pqOz/ePdcn37jC+5PuJwAR/nN9PM1P9GieWMu6tDGhxGKV3jwGf9V8yuvos2tY9n6aOXnIvutauTo7nB6OlunTOHiZcu4+JNPOJSaii0q8nKAp6+y/ZAn+6pf2zw0fTrTHnqoykJGoyZNmDZ/PlMmT+bwwYOnHa+3eJL3ydiSEubHxPDviAhaxcZybjc/OwaJT3k6i3wS0MXTWUVlr8k0e/bsGgX2xzvv5MZx4wBITU6mbZn/as+LiCB7R/kJUPv27qV5SAgBAQEUFxdzXkQEu9zajEpIKDc8HjtgANeOHMk1w4YR3LAhTZs144U33mDCTTfVKGavy3NCSJn/5kMi4ECFiV8n/PQ1tOwIjUMhv8yqOpoHW76ALkMh+wefhVtdB5zOctXF5hERx4e5y7ZpVqZNM1ebCwYNYn9WFvl79wKwacECIi+9lPVvvsneH3/kjSFDAAiNiiJq+PBayKZ6wlqcQ/a+EweSXTmHaB3SpFybtKxd3PvCEgByDx7hy9QsAgMcpGZms/z7n/hq3VaOFRZx6EgB98/6mKl3xtVqDnJqBU4nwREnPr/B4REU7Ky4DTfu3p1OL83lh5FxFOXk1GaIp+2Y00lwmW00OCKCYztOsp9ys2PePHbMmwdAp6ef5qjT6fUYayLhzjv5jesYlJacTFiZHNtERLDbLcfcvXtpWuYYFFamTXSfPjyXlATAuS1bctmwYRQXFbH8gw8IDAxk2vz5LH7zTT57//1ays4zh51OzimTd5OICA5XY93+qiAvj51ffEHk0KHk/uA/xyBv0Kh/1TwdIt8O5Hn6R621c6y1fay1fcaPH3/qJ1Ti1Vmzjk/M+XjhQsbcfDMAF/frx8G8PHZnZ1d4zreff86IG24A4Le33MInH3xw/LGmzZrR/8oryy175tFH6R0ZSWyHDvw5IYFvli/3n84lwPZkaBkFLdqXnkfZKwF+WFS+TWjHE7+Hx0BAg9LOZZOW0NB1TltgQ4gaBLvTay10T+xITqZFVBQh7dsTEBTERQkJpC8qn1/6okX0cq37iH79OJqXx6HsbPK2bSOif3+CGjUC4IJrrmGva6JWk1atgNL/vq/4619JOcmwVF3pfkEYW7Nz2b47j4KiYhav/JGBvS8o12b59LEsn1F6GxIbxeN/HMigPp24L+EyvnphHMtnjOWfE4bRPzpSnUs/dTAlmUadoghu3x4TFESr3yaQ81H5z3hwZCRd/7OAzbfexNGMjDqKtOYOJCfTOCqKhq4cwxIS2OO2HZ9MkGt7bRgZSevRo8kuUwSoS0mzZjEmJoYxMTEsX7iQka79UI9+/TiUl8feSo5ByZ9/zmDXMWjkLbfwuet4E3fBBQzt0IGhHTqw7L33ePrOO1nueuyJl1/mp02beH3atFrKzHO7k5NpHhVF0/btcQQF0SkhgZ89XLcNW7akgeu86oCGDQkfNIj96f51DBLf8rSC+RPwhTFmMXDs14XW2n/6JCo3ny1ZwjXDhvFdZiZH8vO559Zbjz/278WLue+229i1cydPPfQQLyUl8dBTT5G2di1vv/zy8XZx11/Pl59+ypH8/NoI2TtKiuH9CTBuKZgASJ4HuzbCJbeXPv7dbOjxG+h9c+kkoMIj8MbvSh9rdh4kvFb6PIcDUt+BTYvrLpdKlBQXs2TCBG5auhRHQABr581jz8aN9Lm9NL+U2bPJWLKEzsOGMSkzk8L8fBa61v0vq1ez8b33uH3NGkqKisheu5aUOaWzb7snJtL3rruA0srm2ldeqZsETyIwwMFjfxzIbVMWUFxi+c2V3YiKaMnb/00FIHFQzzqOsHbde++9rF69mtzcXK644gruvvtuxowZU9dhnb7iYrZMnsBFi5eCI4Bdr80jf+NGwsbyKA/6AAAgAElEQVSVfsaz/282kX95jKDQUDr+axYAtqiI1Ev61mXU1WKLi/lxwgQuXroUExDAjnnzOLxxIxGu7dg5ezYN2rShX0oKgc2aYUtKOH/yZFZER1N88CA9588nKDQUW1hI+l13UeSa8ORPvl6yhCuGDWNJZiZH8/P5a5lj0KzFi3n8ttvYs3Mn0x56iOeSkrj7qadIX7uWBWWOQZWJGTCAkTffzOb163nXNdnnfx99lK8/9o/zcG1xMd9MmMAw17r9cd48cjdupKtr3W6aPZtGbdowOiWFBq51233yZN6Jjqbxeedx9WuvYQICMA4HW955h22L/esYJL5l3M9TrLSRMY9Xttxa+4QHr2HPO0smIuy0Fu4/O3IFYKrl8bNk3T5hLaT4XyXUZ/r8+dRtziDfNDg7PscAlxVYlp0l2+1ga+l+luQKsMFaZp8l+d5e2nep82SXG1Png+QDra3z96EyHlUwPexIioiIiIicvINpjJlurZ1sjPmQSia+WmtH+iwyERERET/mx1cJqnOnqmC+4fo59aStRERERERcTtrBtNZ+7/r5Ze2EIyIiIiL13amGyDdwku8XtNZW/IoRERERkbNAnc/w8WOnGiIfUStRiIiIiMgZ41RD5D/XViAiIiIi9YkqmFXz6DJFxpiDnHgfGwBBwGFrbTNfBSYiIiIi9ZOn18FsWva+MWYUEOuTiERERESkXvP0qyLLsdYuNMY87O1gREREROoLXQezap4OkY8uc9cB9EGnHoiIiIhIJTytYF5X5vciYCsQ7/VoREREROoJVTCr5uk5mLf6OhAREREROTM4PGlkjHnOGNPMGBNkjPnMGLPXGPMHXwcnIiIiIvWPRx1M4Fpr7QFKL7zuBDoDD/gsKhERERE/Z/3g5q887WAGuX4OA9621ub4KB4RERERqec8neTzoTEmHTgC3GmMaQUc9V1YIiIiIlJfeTrJ52FjzBTggLW22BhzGM0iFxERkbOYPw9R17XqXGi9K9DeGFP2Oa97OR4RERERqec8vdD6G0BHYB1Q7FpsUQdTREREzlK6DmbVPK1g9gGirbWqBouIiIjISXk6izwNCPNlICIiIiJyZvC0gtkS2GiMWQ0c+3WhtXakT6ISERER8XMa1q2apx3Mv/kyCBERERE5c3h6maIvfR2IiIiISH2iST5VO2kH0xjzjbX2MmPMQcpXgg1grbXNfBqdiIiIiNQ7J+1gWmsvc/1sWjvhiIiIiEh9V50LrYuIiIiIiyb5VM3TyxSJiIiIiHhEFUwRERGRGtAkn6qpgikiIiIiXmVq4dsfdYqCiIiIeJup6wDeM6bO+zg3WFvn70NlamWIfLTxy9y9boG1rA87O3IF6JFtOTbi7Mg3+CMLSaPqOozak7CQbxqcHev2soI6Pz7UulfPkn3yH63l5rMkV4DXrcXecHbka97zj+3WP6LwTxoiFxERERGv0iQfERERkRrQJJ+qqYIpIiIiIl6lDqaIiIiIeJWGyEVERERqQJN8qqYKpoiIiIh4lSqYIiIiIjWgST5VUwVTRERERLxKHUwRERER8SoNkYuIiIjUgIbIq6YKpoiIiIh4lTqYIiIiIuJVGiIXERERqQFdB7NqqmCKiIiIiFepgikiIiJSA6pgVk0VTBERERHxKnUwRURERMSrNEQuIiIiUgO6DmbVVMEUEREREa9SBVNERESkBjTJp2qqYIqIiIiIV6mDKSIiIiJepSFyERERkRrQJJ+qqYIpIiIiIl6lCqaIiIhIDWiST9VUwRQRERERr1IHU0RERES8SkPkIiIiIjWgST5VUwVTRERERLxKFUwRERGRGtAkn6qpgikiIiIiXlUvOpgxQ4bwr/R0ZmZkcP1DD1XaZuyMGczMyOCfqalcEBNzfPldL7/MK7t2MX3DhnLt2/fsybPffcfza9fyXHIynfr29WkONXXO1UPo8k06Xb7LoNWEirmHjP49UctTiVqeSscPv6VhdA8AgtpGcMH85XT+aiOdv0wj9LaJtR16tZmLhxD0UjoN5mQQcEPFXB1X/Z6gf6WW3v7xLaZDj+OPBcRPJmhmGkEzNxD4wFsQFFyLkdfMVxmHGPK/Wxg8I5M5X++t8Ph/0w9y3ayfiH/xJ0bPziLl5/zjj732XQ4jZv7E8Be28Op3ObUZtleEXDuEi9PS6b0xg4gHKq7rVom/J+b7VGK+T6XHl9/SpEePSv5K/fTII49wySWXMGLEiLoOxWvChwzh+vR0Rmdk0L2SfXTzLl0YtmIFNx09Srf77qvwuHE4uG7NGq758MPaCLfaug8ZwpT0dP6RkcGIKo5Bf5gxg39kZPBUairtXMegoOBgHl+1iqfWreOZtDSu/9vfyj1n8IQJTElP55m0NH43ZYqv06iZXkNgRjr8KwNGVZL75b+H51NLb09/C+3KbKvDJsI/N8C0NBg+qfZiFr/g9x1Mh8PBuJkzeSoujknR0VyemEhE167l2lwcF8d5UVHcFRXFS+PHM/7FF48/9vmrr/Lk0KEV/u7Nzz3Hf554gvtiYkh67DFufu45n+dSbQ4H4f8zk6zfx7H5imhCrk8kuHP53Au2ZfHT9VeSMbAnu6c9ScTUOQDYoiJ2/u0+Nl8RTeaw/rS89a4Kz/UrDgdBd8yk8PE4Cu6MxnFlIiayfLw2O4vCh6+k8O6eFCc9SeCE0lwJbUvAdRMpvKcPhXd1B0cAjisS6iAJzxWXWP6+OJu5f4hk8V0d+WjDATJ3HyvX5pIOTVh0Rwc+uOMCnok/j78u2gnA5l1HeXfNft4d154P7riALzYfZOu+grpIo2YcDjrOmMkP18Wxpmc0rX6XSCO3bfpoVhbrr7mStb17sv2ZJ+k0a04dBet9o0ePZu7cuXUdhtcYh4N+M2eyLC6OhdHRdEhMpLnb+jyWk8OqiRNJmzq10r/RddIk8jZtqo1wq804HNw8cyZT4+J4ODqa/omJtHXLr0dcHG2ionggKopXxo/nj65jUOGxYzw7cCB/7dWL/9erFz2GDqVjv34AdL3qKi6Oj+cvPXrw6EUXsaSK96ZOORxw20x4Og7uiYbLEiHC7TiyOwseuxLu6wnvPQl/dm2rkd1g0Dh4OLb0sd4jIKxT7efgYyV+cPNXft/B7BQby87MTHZlZVFUWMg3SUnExseXaxMbH88Xr78OwOZVq2gSEsK5YWEAbPz6aw7mVKzwWGtp3KwZAI2bNydnxw4fZ1J9jWNiKcjKpGBbFrawkP0Lk2g2pHzu+SnfUZy3v/T371cSdF4EAEW7szmyYS0AJYcPcTRjE0Fh4bWbQDWYzrHYnZmwKwuKCin5KglH//K52vTv4HBpriXpKzEtI048GBAIDRqBIwCCG2Nz/G99lrX+lyO0a9GAyBYNaBBoGH5RMz5LP1iuTZNgB8YYAI4UlmBcy7fsLaBnREMaNXAQGGDo264xyzYdpL5o2jeWo1syOZZV+rne804SodeVX9cHV35H8f7SdX1g1UoahEdU9qfqpb59+9K8efO6DsNrWsbGcjAzk0NZWZQUFpKVlMT5bvvoo3v2sC8lBVtYWOH5jcPDiRg+nM1+2unuGBvL7sxM9mRlUVxYyMqkJC52y+/i+Hi+dR2DtqxaReOQEJq7jkHHDh8GICAoiICgIKwtPWtv4B138NGzz1JUUPrP4cE9e2orJc91ioXszNJOZFEhfJsEfcvnzo8n9stsXgktXNtqRNfS+wVHoKQYNn4J/a6v3filTp10ko8x5t6TPW6t/ad3w6koNDycfdu3H7+/z+kkyvUf4K9ahIez161Ni/BwcrOzq/y78yZP5rGlS7ll6lSMw8Gjl17q/eBPU9B54RTuOJFX4U4njS/uV2X7c38/loPLP674dyLb0eiiGPLXrPJJnN5gQsOxe07kavc6cXSpOteAa8dSkuLKdd8Oit+fSoNXtkHBEUrWfopdu8zXIZ+WXQeKCGt+YvNr0zyI9c4jFdot23SA5/+7h5zDRcy+MRKAzq2Dmf7ZHnLzi2gY6OCrjMNc1LZhrcV+uhqEh3PMeWJdH/vFSdO+Va/rsFvHkru04uda/EPj8HAOl9n/HnY6adWv6vXpLnb6dL5/8EGCmjb1RXin7Vy3Y1CO03m8CvmrFuHh5Li1aREeTl52Nsbh4O/ff0+bTp3478yZ/LR6NQBhnTvT+fLLueHppyk8epS377+frJSU2knKUy3CYe+JvNjnhKiTrNtrxsJa17a6LQ0Sn4ZzWpR2MmOGwRY/y88LNMmnaqeqYDY9xa1SxpjxxpgUY0zKnDmnObRlTMVl1ro1qdjG2pOv9qF33MEr99zD+PPP55V77uHOl18+rTB9woPcf9VkwFW0SBzLzqfKnyPjaNyEdnPns+OxyZQc8ucql+e5mu5X4bh2LEWvunJtEoKjXzwFYztQcHNbCG6C46obfReqF1SWWSXvAIO7NuOTuzsyMyGSGctLKxwdWwVz24BQ/vT6Nm779za6hAUT4Kjs2X6qGp/r5ldeRZtbx7L10crPexM/UI316S5i+HCO7t7NvjVrvByUF3mS30mOQbakhP8XE8PkiAguiI0lvFs3AAICA2ly7rk80b8/SQ88wIR33vF66KetOuu221UwcCz827Wt/pIOC6fAY8vgr5/Az6lQUuSzUMX/nLSCaa19oiZ/1Fo7B/i1Z2k/uf32mvwZoLQaGRoZefx+aEREheHsfU4nLd3a5J5iyPuqW27h5UmlJx2vePdd7vTD4ZnCHU6C2p7IK+i8CAqzK+bVsGt3Ip6fS9bv4yjOLXM6QGAg7V6ez/4Fb3Jgyfu1EXKN2X1OTKsTuZqWEZUOc5v23QmaOJfCx+PgYGmujl6DsLuy4EDpRJmS7xbg6HopJV+8WSux10RYs0Cy807sbHflFdK6adWbY9/2jdn2fiE5h4to0SSQMb1DGNM7BIB//nc3bZrVnyuOFTidBEecWNfB4REU7Ky4rht3706nl+byw8g4iio5zUX8Q77TSZMy+98mERHke3jKUesBA4gcOZKIYcMIaNiQoGbNuPyNN/j6ppt8FW615bodg1pUcnzJcTppcYo2+Xl5pH/xBT2GDuWXH34gx+kkZcECAH5KTqakpISmLVtycG/FCX91Zp8TWp7Ii9AIyK1k3bbrDnfMLT1X81CZbXX5vNIbwO+fLv17ctY4aQXTGPO/J7vVRoCZycmcFxVF6/btCQwK4rKEBJIXLSrXJnnRIq66+WYAOvfrR35e3kmHxwFyd+yg25VXAtB94EB2ZmT4JoHTkL8umQYXRBF0fntMUBAhoxI48Gn53IPCI2k3bwHbJ9xEwU/lc4ic9jJHMzaxd/a02gy7RuzmZEzbKGjTHgKDcFyRQMmq8rnSKpKgRxdQ+PxN2B0ncrV7tmG69IfgRgA4el5DyXb/nDDwq+5tG7E1p4DtuQUUFFkWpx1g4IXlBwV+3ldwvAryw44jFBZbzm0cAMC+Q6Wd0x37C/l000FGdK8/5/QdTEmmUacogtuXfq5b/TaBnI/Kr+vgyEi6/mcBm2+9iaN+uG3KCXuTk2kWFcU57dvjCAqiQ0IC29320VVZ8+ijvBsZyXsdOvBlQgI7ly/3q84llHb+2kRF0bJ9ewKCguifkMBat/zWLlrEANcxqKPrGJSXnU3Tli1p7DrfNqhhQ7oNGsTO9HQAvl+4kOiBAwEIi4oisEED/+pcAmQmw3lR0Lo9BAbBgARIdlu3LSPh/gXwr5tgp9u22qzViTb9RsM3b9dK2LWprif4+PMkn1OVPf4MpAHvADuofBTPp0qKi5k7YQKPLV2KIyCAz+bNY/vGjVzrqop+Ons23y9ZwsXDhjErM5Nj+fm8cOutx59/z1tvcdFVV9G0ZUv+b/t2kh5/nM/mzWPWuHGMnTGDgMBACo4e5cXx42s7tVMrLmbHoxO44O2lEBBA7tvzOPbjRlrcXJp7zuuzaXPvYwScG0r4s7MAsMVFZA7pS+PYAZw75maObFxP1H9LJ/tk/8+jHPzMT89lKymm6KUJBP19KcYRQPGyedhtG3HEleZa8vFsAhMeg2ahBN5ZmivFRRTe0xe7eTUl375H0PQ1UFKE3bKWkk/8e9ZxYIDhsWFh3PbGdopLLL+JCSGqdTBvJ+cCkNj3XJZuPMAHqXkEBhgaBjqYNib8+Okgd//Hyf4jxQQ6DI8PD6N5o4C6TKd6iovZMnkCFy1eCo4Adr02j/yNGwkbV7qus/9vNpF/eYyg0FA6/sv1uS4qIvUS/7yUWHXde++9rF69mtzcXK644gruvvtuxowZU9dh1ZgtLmblhAkMXroUExBA5rx57N+4kS6uffSPs2fTqE0bRqSkENSsGZSUED15Mgujoyk86M+n7ZQqKS7m9QkTeNCV31fz5vHLxo1c7crv89mzSV2yhJ7DhvGPzEwK8vOZ6zoGhZx3HuNfew0TEIDD4WDVO++wbvFiAL6aN4/b5s3jmQ0bKCooYM4tt9RZjlUqKYa5E+Cvpdsqy+eBcyNc6xqV/HQ23PAYNA2F21z75ZIieMi1rT4wH84JheJCmHvXiclAclYwJztX0RgTCowBfgcUAf8B5ltrc6vxGnZ0ZedxnIEWWMv6sLMjV4Ae2ZZjI86OfIM/spA0qq7DqD0JC/mmwdmxbi8rOPtO03/1LNkn/9Fabj5LcgV43VrsDWdHvuY9C3VQ9HL3gjF1vgOZYG2dvw+VOekQubV2n7X2JWvt1cAfgRDgB2OMf41hiIiIiNQy6wc3f+XRzABjzMVAIjAY+Bj43pdBiYiIiEj9darrYD4BjAA2AUnAI9ZaXWdAREREznr+PMmmrp2qgvn/gJ+Anq7bM65JBgaw1toz5wuCRURERMQrTtXB7FArUYiIiIjIGeNUF1r/2X2ZMaYlsM+e6qtyRERERM5g6ghV7VQXWu9vjPnCGLPAGBNjjEmj9LqYu4wxQ2snRBERERGpT041RP4C8CjQHFgOxFlrVxpjLgTeBj7xcXwiIiIifkmTfKp20gomEGit/dRa+y6Qba1dCWCtTfd9aCIiIiJSH52qg1m2c37E7TGdeiAiIiIiFZxqiLynMeYApZclauT6Hdf9hj6NTERERMSPaYi8aqeaRR5QW4GIiIiIyJnBo6+KFBEREZHydK5g1U51DqaIiIiISLWogykiIiIiXqUhchEREZEa0BB51VTBFBERERGvUgVTREREpAZ0maKqqYIpIiIicgYzxgw1xvxojMk0xjxcyeMXGmO+M8YcM8bc743XVAVTRERE5AxljAkAZgKDASeQbIxZZK3dWKZZDjARGOWt11UFU0RERKQGSvzg5oFYINNa+5O1tgBIAuLLNrDW7rbWJgOF1X0PqqIOpoiIiEg9ZYwZb4xJKXMb79YkHNhe5r7TtcynNEQuIiIiUk9Za+cAc07SxFT2NB+Fc5w6mCIiIiI1UE+ug+kEIsvcjwB2+PpFNUQuIiIicuZKBqKMMR2MMQ2ABGCRr19UFUwRERGRGqgPFUxrbZExZgKwFAgA5llrfzDG/Nn1+EvGmDAgBWgGlBhjJgPR1toDNX1ddTBFREREzmDW2iXAErdlL5X5PZvSoXOv0RC5iIiIiHiVKpgiIiIiNaCviqyaKpgiIiIi4lWqYIqIiIjUQH2Y5FNXjLU+f3v0/ouIiIi3VXYB8Vr1hDF13sd53No6fx8qUysVzIuNX+budWus5eWzJFeAsdZy61mS7yvWsuwsyRVg8FmU72BrefUsyRXgj74vKviVP5xF6/bf1rL4LMl3+Fn2Oa6PNEQuIiIiUgOa5FM1TfIREREREa9SBVNERESkBjRQXzVVMEVERETEq9TBFBERERGv0hC5iIiISA1okk/VVMEUEREREa9SBVNERESkBjTJp2qqYIqIiIiIV6mDKSIiIiJepSFyERERkRrQJJ+qqYIpIiIiIl6lCqaIiIhIDWiST9VUwRQRERERr1IHU0RERES8SkPkIiIiIjWgST5VUwVTRERERLxKHUwRERER8SoNkYuIiIjUgIbIq6YKpoiIiIh4lSqYIiIiIjWg62BWTRVMEREREfEqdTBFRERExKs0RC4iIiJSAxoir5oqmCIiIiLiVapgioiIiNSALlNUNVUwRURERMSr1MEUEREREa/SELmIiIhIDWiST9VUwRQRERERr6o3HcwHZszgg4wM/pOayoUxMZW2adu+Pa+tXMnCzZt5NimJwKAgAK4cOZL/pKby9tq1/Ds5mV4DBpR7nsPh4K01a5jx4Yc+z6O6wocM4Tfp6YzJyKDHQw9VeLx5ly5ct2IFfzx6lIvuu6/C48bhYNSaNQz2w9wALhoyhGfS03k2I4NhleQH8PsZM3g2I4O/p6bSzm3dG4eDv61Zw6Qy+fW54QaeSkvj5eJi2vfu7dP4T0fokCFcmp7OgIwM2leSe+MuXei7YgXXHD1KO7d1e/7kyVySlsYlGzbQ/a23cAQH11bYNXI6uUZOnMglGzZwSVoa50+aVFshn5bwIUO4Pj2d0RkZdK9iux22YgU3HT1Ktyq22+vWrOEaP91uq+ORRx7hkksuYcSIEXUdSo31GDKEf6Sn83xGBtdVsZ+6acYMns/I4JnUVNq79lNBwcE8sWoVT69bx7NpaYz+298qPG/Yfffxb2s5JzTUlynUWKshQ7gyPZ2rMjLoWEnuTbp04dIVKxh69CgXlPksN+ncmcvWrj1+uzYvj/b1ZPutjhI/uPmretHBHBAXx/lRUcRHRfHU+PE88uKLlbabOGUKb06bxqjOnTmQm8uosWMBWP3ZZ/yuZ08SY2J44k9/4v/NnVvueYmTJpG1aZPP86gu43Bw6cyZfBoXx/zoaC5ITCSka9dybY7l5PDdxIlsmDq10r/RbdIk9vthblCa300zZzItLo6/REfTLzGRtm759YiLo01UFA9HRfHq+PHc5LbuB0+axE63/H5JS+OF0aPZ/NVXPs+hxhwOLpw5k7VxcayIjiYsMZEmbrkX5uTw48SJbHVbt8Ft23L+xIms6tOH77p3h4AA2iQk1Gb01XMauTbp1o2IceNYFRvLyp49aTliBI07darN6KvNOBz0mzmTZXFxLIyOpkNiIs0r2W5XTZxIWhXbbddJk8jz0+22ukaPHs1ct31ufWIcDm6ZOZPn4uJ4MDqa/pXsp3rGxREWFcV9UVG8PH48f3TtpwqPHeOZgQP5S69e/KVXL3oMHUrHfv2OP69FRAQXDR7M3p9/rtWcPOZw0G3mTFbHxfFldDRtExM5p5Jt94eJE8ly+ywf3ryZb2JiSm+9e1Ocn8+u99+vzeiljtWLDuZV8fF89PrrAGxYtYqmISG0DAur0K7vwIF89t57AHz02mtcPWoUAEcOHz7eplGTJmBPnDXROjycy4cPZ6Ef7gBbxcZyIDOTg1lZlBQW8lNSEufHx5drc3TPHvampFBSWFjh+Y3Dw4kcPpwf/TA3gAtiY9mdmcmerCyKCwtZnZREjFt+MfHxrHCt+59WraJxSAjNXev+3PBweg4fzldu+e1MTyd78+baSaKGmsfGkp+ZyZGsLGxhIdlJSbRyy71wzx4OpKRgK1m3JjAQR6NGmIAAAho35tiOHbUVerWdTq5NunYlb+VKSo4cwRYXk/vll7S6/vraDL/aWsbGcjAzk0Ou7Tariu12XxXrtnF4OBHDh7PZT7fb6urbty/Nmzev6zBqrGNsLLvK7KdWJiXR22199o6P5xvXfmrLqlU0CQkhxLWfOuY6/gQEBZWOqpU5/vxh2jSSHnwQa/3zTL4Qt213R1ISbdxyL9izh7wqjkG/annNNeRv2cKRbdt8HbL4EY86mKbUH4wxj7nun2+MifVtaCe0Dg9n1/btx+/vdjppFR5erk1IaCiH9u+nuLgYgF1uba4eNYr5mzYxY/FinvjTn44vv3/6dGY8+CAlJf5XaG4cHs7hMnnnO500ccv7ZPpPn87qBx/E+mFuUNpBzCmTX47Tybnu69WtTW6ZNonTp/OOn667UwkOD+dYmbyOOZ0Ee7huj+3YwdapU7l82zau2LmTorw8cpYt81Wop+10cj2clkbIFVcQ1KIFjkaNaDlsGA0jI30Vqle4b7eHnU4aV2O7jZ0+ne8ffBDq4ef6TOTJfurc8HD2VdHGOBw8vXYts3bvZsOyZWxZvRqAi6+7jtxffmHb+vW1kEXNNAwP50iZvI46nTSsxmf5V20TEtjx9tveDM1vWD+4+StPK5izgEuARNf9g8BMn0RUGWMqLnP/j6+SNmX/K/x84UJ+07Ur940axR1PPgnA5cOHk7N7N5vWrPFquF5zipxOJnL4cI7u3s0+f80NPMrPVNGm5/DhHNy9m5/9Ob+T8eQzXYXAkBBax8fzTYcOfNW2LQFNmhB2441eDtCLTiPXw+npbJ0yhYuXLePiTz7hUGoqtqjIywF62WnkG1EfttuzTGX7IPf1WdV+CsCWlPCXmBgmRkTQMTaWiG7daNCoESP/8hfee+wxn8TsNafxWT7+J4KCaDNyJDvffddLQUl94WkHs5+19i7gKIC1NhdoUFVjY8x4Y0yKMSZlzpw5NQrst3feydtr1/L22rXs2bGDNmWqFq0jItjjNiS4f+9ezgkJISAgAIA2ERHsrWTYcM3XXxPRsSMhoaH0HDCAK0eO5KOsLP4nKYk+Awfy1Btv1CheX8h3OmlSJu/GERHkezgU2mbAAM4fOZLfZmVxdVISbQcO5Eo/yg1Kq5EtyuTXIiKC/W75ubc519UmasAAeo0cyT+ysrgjKYmuAwcy3s/yO5ljTifBZfIKjojweJi7xaBBHMnKonDvXmxREbsXLCDk0kt9FeppO51cAXbMm8eq3r1JufJKCnNyyM/I8EWYXuO+3TapxnbbesAAIkeO5IasLK5MSuK8gQO5vB59rs9EOZXsp3Ld1meO00noKfZl+Xl5bPriC3oMHUrrjh1p1aEDz6SmMi0rixYRETy1Zg3N25Dp/k4AACAASURBVLTxbTLVdNTppFGZvBpGRHC0mqfjtI6LI2/NGgp27/Z2eH6hrif4+PM4h6cdzEJjTACuaqwxphUnyctaO8da+//bu/P4qKr7/+OvTxZ2IawBkiiIQQVBQQTckIKUzYoL1Ngq1oLabwXFfa1bq627tiK/oODWVqpiNRWUWhGpKBgEAhhSg4Iysm9hE0gm5/fHXGASMmEIM5kJeT8fjzwyc++ZO5/PPffeOXPuuXN7OOd6XHvttVUK7I3nn+fybt24vFs3Zr3zDheMHAlAl1692FFUxMa1aw96zfyPP6b/8OEAXHDVVcx6910AMjp02F/mpG7dSK5Th62bNvHc3XczOCODC9q3566sLObPnMm9V15ZpXijYUNuLo0zM2nUrh0Jyckcn5XF9zk5Yb12/t13MyUjgzfat+fjrCxWz5zJJ3GUG8CK3FxaZWbSol07EpOT6ZmVxcJy+S3MyeEsr+6P79WLH4uKKFq7lrfuvptbMjK4rX17JmRlsWzmTCbGWX6V2ZabS4PMTOq1a4clJ9M6K4sNYdbt7u+/p0nv3iTUrw9As/792RnHF4QcSa4AyS1bAlAvI4NWl1zC2jg/1bax3H7bPiuLVWHmu+Duu3kzI4O32rfnk6ws1sycyX9r0HZ9NPo2N5fWmZm09I5TvbOyWFCuPhfk5HCOd5zq0KsXu4qK2Lp2Lce0aEEDb/xpcr16nHL++awuKMC3dCnXp6ZyU/v23NS+PZt9Pu7t3p2ideuqPb/KFOXm0jAzk/revts2K4t1h7HvArS9/PKj9vS4VC7cH1r/M/BPINXMHgaGA/dGLapyPp0+nXOGDOHd5cvZvWsXD1x99YHApk3jodGj2bhmDX++4w7+OGUK1//hDxQsXMg7kyYB0O/SS7lg5EhKiovZ8+OP3HnZZdUV+hFxfj+fjxnDoBkzsMREvp48ma35+Zx03XUAFGRnUz81lWHz55PcuDGutJRTxo1jaqdOFG/fHuPoD63U7+dvY8Zwy4wZJCQm8t/Jk1mdn09fL79Z2dksnj6drkOG8Ojy5ezdtYtJQXUfSveLLuKXf/kLx7Rsybhp01i1aBFPDhoU7XQOi/P7+d+YMXT36nb15MnszM8n3cvdl51NndRUes2fT5JXt8eOG8dnnTqx7YsvWPfWW/ResABXUsK2hQvxVfFMQXU4klz927dz6tSpJDdvjisupuD66ynZujXGGVXO+f3MHTOGAV6+y7399kQv3/95++0F3n5LaSmdxo3jnRqy3x6um2++mS+++IItW7bQp08fxo4dy4gRI2IdVthK/X5eGTOG273j1CeTJ/NDfj79vPqcmZ3NounTOXXIEJ70jlMTveNUSps2XPfKKyQkJmIJCcx74w0WTZsWy3QOi/P7WTpmDD29bdk3eTI78vM51sv9++xs6qamcra371JaSrtx45jdqRMl27cHxk0PGMASr7zULhbumD4zOwnoDxjwkXMu3C4T172icRxHoQXOMamW5AowyjmuriX5vuQcH9aSXAEG1KJ8BzjHy7UkV4BfxekVy9FyRS2q2786x7Raku/QwHYc82T/zyzmO9QE52K+HipyOD9T1ALY5Zx7DthoZu2jFJOIiIiI1GBhnSI3s/uBHsCJwEtAMvBX4OzKXiciIiJytIrni2xiLdwezIuBC4GdAM651cAx0QpKRERERGqucBuYe11gsOa+q8gbRi8kEREREanJwr2K/A0zywZSzOwa4NfAC9ELS0RERCS+xfwKnzh2yAamBW5R8A/gJGAbgXGY9znn4vfedCIiIiISM4dsYDrnnJm945w7HVCjUkREREQqFe4p8rlmdoZzLjeq0YiIiIjUELqKPLRwG5g/Aa4zs+8IXEluBDo3u0YtMhERERGpkcJtYA6OahQiIiIiNYwu8gkt3AZmRTfIPfpumisiIiIiRyzc38FcAGwAvgYKvccrzGyBmZ0ereBEREREpOYJtwfzA+CfzrkZAGb2U2AQ8AbwPNArOuGJiIiIxCdd5BNauD2YPfY1LgGcc/8G+jjn5gJ1oxKZiIiIiNRI4fZgbjazO4Ap3vPLgC1mloga8CIiIlIL6SKf0MLtwfwFkA68A7wLHOtNSwR+Hp3QRERERKQmCqsH0zm3ERgbYvbyyIUjIiIiIjVdpQ1MM3vGOTfOzP5FBT3BzrkLoxaZiIiISBzTGMHQDtWD+Zr3/4loByIiIiIiR4dKG5jOuS+9/59UTzgiIiIiNYN6MEM71CnyJVRykZTuRS4iIiIi5R3qFPkF3v/rvf/7Tpn/EtgVlYhEREREpEY71Cny7wDM7Gzn3NlBs+40sznAQ9EMTkRERCRe6XcwQwv3dzAbmtk5+56Y2VlAw+iEJCIiIiI1Wbh38hkFTDazJgQa7EXAr6MWlYiIiEicUw9maOH+0PqXwKlm1hgw51xRdMMSERERkZoqrFPkZpZqZpOAfzjnisysk5mNinJsIiIiIlIDhTsG82VgBtDWe/41MC4aAYmIiIjUBKVx8Bevwm1gtnDOvYGXi3OuBPBHLSoRERERqbHCbWDuNLPmeONZzaw3gQt9RERERETKCPcq8puBHOB47/cvWwLDoxaViIiISJzTVeShmXOHXj1mVg8YAwwEtgOfA39xzu0O4z20/kVERCTSLNYBXGYW8zbOP5yL+XqoSLg9mK8C24BHvOeXE7ht5IhoBFWTbTonLus5Kpp/6vjmpNqRb4cCh1ntyBXAOUeXWpLvEucYWUtyBXjVOa6oJfn+NYwOlKPN8o61o25P+Do+6jaeL7KJtXAbmCc6504Nev6xmeVFIyARERERqdnCvchnoXdhDwBm1guYE52QRERERKQmC7cHsxcw0sy+954fCywzsyWAc851jUp0IiIiInEqPk7Ux6dwG5iDohqFiIiIiBw1wr0X+XfRDkRERESkJtFFPqGFOwZTRERERCQsamCKiIiISESFOwZTRERERILoIp/Q1IMpIiIiIhGlHkwRERGRKtBFPqGpB1NEREREIkoNTBERERGJKJ0iFxEREakCXeQTmnowRURERCSi1IMpIiIiUgW6yCc09WCKiIiISESpgSkiIiIiEaVT5CIiIiJVoIt8QlMPpoiIiIhElBqYIiIiIlVQGgd/4TCzQWb2PzNbbmZ3VjDfzOzP3vzFZtb9MFfFQdTAFBERETlKmVkiMB4YDHQCLjezTuWKDQYyvb9rgQlH+r5qYIqIiIgcvXoCy51z3zrn9gJTgGHlygwDXnUBc4EUM2tzJG+qBqaIiIhIFbg4+AtDGrAq6LnPm3a4ZQ6LGpgiIiIiNZSZXWtm84P+ri1fpIKXlW+bhlPmsOhnikRERERqKOfcRGBiJUV8QEbQ83RgdRXKHBb1YIqIiIhUQayvIA/zKvJcINPM2ptZHSALyClXJgcY6V1N3hsocs6tOZx1UZ56MEVERESOUs65EjMbA8wAEoHJzrmvzOw33vz/B0wHhgDLgV3A1Uf6vmpgioiIiFRBuL9DGWvOuekEGpHB0/5f0GMHXB/J99QpchERERGJKDUwRURERCSidIpcREREpAqO6Hd8jnI1rgdz9uzZDBw4kAEDBjBx4sFX5c+bN4/TTz+dYcOGMWzYMJ577rky8/1+PxdddBHXXXdddYV8RJJ7DSTl7wWkTCmk3hV3HDS/zoBf0OTlPJq8nEfjCXNIPKHr/nnWqAmNfv8mKX9bRpO/5pPUuXd1hn7Y6p8zkIz3Czh2RiEp1xyca6MLfkH6u3mkv5tH2utzqHNi17IFEhJIf3sBrf/fv6op4iP37LPPUlhYSF5eHt26dauwzPXXX09hYSHOOZo3b75/+oknnshnn33G7t27ueWWW6or5MNy57PPMq2wkKl5eZwcIr+0du3429y5vPf11zw+ZQpJycll5nfu0YNFJSUMuPRSAFLT05k0cybv5ufzz6VL+eUNN0Q9j3B0GTiQRwsKeLywkAvuOHj7Bbji2Wd5vLCQP+TlcZy3PpLr1uX+efP4w6JFPLJ0KRc/8ECZ1wwYM4ZHCwp4ZOlSLnv00WinEZauAwfyeEEBTxYW8rMQuV757LM8WVjII3l5tAvK9cF583h40SL+tHQpl5TLFWDILbfwV+doFLSt1yR33XUXZ555JhdccEGsQ4mIBucO5NgPCjj2w0JSrq3guPyzX5CRk0dGTh5pU+ZQ56SDj8sZ7yygTXbNOS5LZNSoHky/389DDz3ESy+9RGpqKsOHD6dfv36ccMIJZcr16NGD7OzsCpfx6quv0qFDB3bs2FEdIR+ZhAQa3jyebTcNoHS9jyYv5lL8aQ7+lcv2Fylds4JtY8/Dbd9Kcu9BNLx9ItuuDTQkG9z4LMXzPmDH70ZAUjJWr0GsMjm0hARa3jee1b8eQMk6H+lv5rJzZg7F3xzItfiHFay+8jxKt22lwbmDaPnQRH647ECjucnIG9n77TISGjWORQaHbfDgwWRmZpKZmUmvXr2YMGECvXsf/CVgzpw5vPfee8yaNavM9M2bN3PDDTdw0UUXVVPEh+fcwYM5LjOToZmZdO3Vi3snTOCXFeR306OP8trTT/PBP/7B7yZM4JJRo3jj/wXGnickJHDTo4/y2YwZ+8v7S0p44pZbWLZwIQ0aNeIfX37J5x9+yLfLlh207OpiCQmMHD+exwYMYLPPx4O5uSzIyWF1UExdBw8mNTOT2zIz6dCrF7+aMIEHe/emeM8e/tSvH3t27iQxKYl7P/2Uxe+/zzfz5nFy3750HzaMe7p2pWTvXo5p2TJmOe5jCQlcNX48f/JyfSg3ly/L5Xrq4MG0zszklqBcH/ByfSQo1999+il5Xq4AzdLTOWXAADZ+912s0jtil1xyCVdccQV3hGh41ygJCbS8fzw/XD2AkrU+MqbmsvOjssflEt8KfrjCOy73GUSr30/EN+LAfp5y1Y3s/abmHJcPl3owQzusHkwzaxitQMKxePFijjvuODIyMqhTpw5Dhw7lo48+Cvv1a9euZdasWQwfPjyKUUZO0sk98fuWU7p6BZQUs+c/U0g+p+ztQ0uWfo7bvjXw+Ku5JLZMB8AaHEPyqX3Y894kr2AxbkdRtcZ/OOp27Unx98sp8a2A4mJ2TJ9Cw/5lc92z8HNKtwVy3Z03l6TW6fvnJaam0eC8oWx/88VqjftIDBs2jFdffRUI9LynpKTQunXrg8otWrSI7yr4wN2wYQPz58+nuLg46rFWxU+GDSPHy2/xvHkck5JCiwry69mvHx++9RYAOa+8Qr+gBvMvxo7lP1Onsnn9+v3TNq5dy7KFCwHYtWMHK5YtIzXtiO5odsQ69OzJ+uXL2bBiBf7iYuZOmUL3YWW33+7DhjHHWx/fzJtHg5QUmnjrY8/OnQAkJieTmJxM4IJO6Pd//8d7f/oTJXv3ArB9w4bqSimkDj17sq5crqeXy/X0YcP4NCjXhikppFSQa1JyMrgDH9FXPP00U26/fX/+NdEZZ5xBkyZNYh1GRNTr2pPi75ZTsso7Lk+bQqPzy9b17uDj8qIKjst9h7KtBh2XJXLCamCa2Vlmlg8s856fambPRzWyCqxbt67MB3Bqairr1q07qNyiRYu48MILGT16NIWFhfunP/LII9x2220kJNSMkQEJLdMoXX/g1qClG3wktgz9QVr3glHsnft+4LVtj8dt3UDDu1+iyeQFNLzjBYjjHsyk1DRK1hzItWStj6TU0LkeM3wUu2a/v/95i7ufYdMTt+NcTfnRCEhLS2PVqgM5+3w+0mLcUIqkVmlprA3Kb53PR6ty+aU0b872rVvx+/0ArA0q06ptW/pffPH+3syKtD3uOE7q1o3FXg9YrDRNS2NTUK6bfT6alsu1WVoam8uVaeaVsYQEfr9wIc+tX8/SDz/k2y++AKB1x450PPdc7p87l7tnzaJ9jx7VkE3lmlaQR/lcK1sflpDAwwsX8vz69Sz58EO+8XLt/rOfseWHH/h+8eJqyELCkZiaRvHassflxEqOy42Hj2Jn0HG55T3PsOmx26G05hyXJXLCbWk9DQwENgE45/KAPqEKB98Xs6JxklVV0bdas7K3z+zcuTMzZ84kJyeHK6+8kuuvD/ys08cff0yzZs045ZRTIhZP1NnBtwYN9c0+qVtf6g4dxa4J3mmZxCQSO3ZnzzsTKPp1d9zundS/4s5oRnuEKrgNaohc6/XqS+NLR7HpyUCuDfoOxb9pPXu/WhDNACOu/LYLoeu3Jqoov/J1WlmZO555hqfvuIPSEB9O9Rs25OmpU3l03Dh2bt9+xPEekTByrWx/dqWl/K5bN8alp3N8z56kde4MQGJSEg2bNuXB3r2ZctttjHnjjYiHfriqWq/Bud7TrRs3pKfToWdP0jt3pk79+lx4zz28dd99UYlZqiic7dpTv1dfGo8YxabHyx6X99Sw4/LhivVdfOK56R72GEzn3KpyBw1/JWWD74sZsU/M1q1bs3bt2v3P161bR6tWrcqUadSo0f7H5513Hg8++CCbN29mwYIFzJw5k9mzZ7Nnzx527NjBrbfeyhNPPBGp8CKudL2PhFYHbg2a0DKd0o0H3xo0sUMXGt35IttuHYzbtjnw2g0+Sjf4KMkP9A7s/fituG5glqzzkdTmQK5JrdMpWX9wrnU6dqHV719kzbWDKd0ayLVe97Np2O9CGpw3BKtTj4RGjWn12Gusv/3Kaos/XL/97W+55pprAMjNzSUj40DO6enprF59RLd+jbms3/6WS738lubm0joov9T0dNaXy2/Lxo0ck5JCYmIifr+f1kFlOvXowWNTpgDQtEULzhkyBH9JCTPffZekpCSenjqVaX/7Gx/985/VlF1oW3w+mgfl2iw9nS3lct3s89HsEGV2FRVRMGsWXQcN4oevvmKzz8f8t98G4NvcXEpLSzmmRQu2b9wYxWwqF04emytYH1sryHWZl+viGTNo2b49j+Tl7S//hwULuL9nT4oqOEsl1cO/1kdy67LHZX9Fx+UTu9Dq4RdZPfrAcbn+6WfTsL93XK4bOC6nPv4a626Lv+OyREe4PZirzOwswJlZHTO7Fe90eXXq0qULK1euZNWqVezdu5dp06bRr1+/MmU2bNiw/5vy4sWLKS0tpWnTptxyyy3Mnj2bmTNn8tRTT9G7d++4blwClBTkkpiRSUKbdpCUTN3zsyieU/b2oQmpGRzz8Nvs+P2VlK46MBzAbV5H6fpVJGR0BCC5R3/8K/OrM/zDsmdJLsnHZZKU1g6Sk2k0JIudM8vmmtQmg9Z/eZt1d1xJ8coDuW5+6m6+65vB9/3bs+6WLH6cNzMuG5cAzz//PN26daNbt2688847jBw5EoBevXpRVFRU5gtUTTTl+ecZ0a0bI7p1Y+Y773Chl1/XXr3YUVTExgryy/34YwZ446IvvOoqPn73XQAGH388g9q3Z1D79nz41ls8/NvfMtOb9+CkSXy7bBmvPv10NWVWuW9zc0nNzKRFu3YkJifTOyuLhTllt9+FOTmc7a2PDr16sauoiKK1azmmRQsaeGP2kuvVo/P557OmoACAL995h07eMa51ZiZJderEtHEJgVxbZ2bSMijXBeVyXZCTwznlct1aQa6nnH8+qwsK8C1dyvWpqdzUvj03tW/PZp+Pe7t3V+MyxnYvySW5XSZJ6e0Cx+WhWez8qILj8nNvs+62ssflTU/ezco+GXzXrz3rbsrix7kzj8rGZax7L4+GHszfAM8CaYAP+DcRvqVQOJKSkrjvvvsYPXo0fr+fSy+9lMzMTF5//XUALr/8cmbMmMHrr79OYmIi9erV46mnnqr4lE5N4Pez86kxNH5qBiQksmfaZPwr8qk7LPATS3vezab+r+7DmjSn4S3ekFh/CUWjzwBg59NjOeb+v0FSHUpXf8uOPx7xrUWjx+9n4+/H0GbSDCwhkW1TJ1O8PJ/GlwVy3faPbJr+9j4SUprT8r5Ars5fwg/Dz4hl1Edk+vTpDBkyhOXLl7Nr1y6uvvpA/UybNo3Ro0ezZs0axo4dy+23307r1q1ZvHgx06dP55prriE1NZX58+fTuHFjSktLGTduHJ06dWJ7rE8Xe/47fTp9hgxh+vLl7N61i3uD8nt+2jTuHz2aDWvW8PQdd/DYlCmM/cMfKFi4kLcnTap0ud3OPpsLR47k68WLedO72OfPd9/Nf99/v9LXRVOp38+rY8Zw+4wZWGIisydP5of8fH7i/Rzax9nZ5E2fzqlDhvD48uXs3bWLF731kdKmDde+8gqWmEhCQgLz3niDRdOmATB78mRGT57MI0uWULJ3LxOvuipmOe5T6vfzipdrQmIin3i59vNynZmdzSIv1ye9XCcG5XrdK6+QkJiIlcv1aHHzzTfzxRdfsGXLFvr06cPYsWMZMWJErMOqGr+fDQ+Noe2kwHa97a3J7F2eT+Ms77g8JZumY+4jMaU5LR/wjsslJfgurbnHZYkcq4YxX0fPoLIwbDqnhjZmq6D5p45vTqod+XYocDX3i0oVOOfoUkvyXeIcI2tJrgCvOscVtSTfvx5FY5rDtbxj7ajbE752UOHg/erVxyzmG9ls52K+HioSVg+mmf25gslFwHzn3LuRDUlEREQk/sW8dRnHwh2DWQ84DSj0/roCzYBRZvZMlGITERERkRoo3DGYJwD9nHMlAGY2gcA4zAHAkijFJiIiIhK31IMZWrg9mGlA8F18GgJtnXN+YE/EoxIRERGRGivcHszHgEVmNovAoNo+wCPerSP/E6XYRERERKQGCquB6ZybZGbvA1cCBQROj/ucczuB26IYn4iIiEhciuffoYy1cK8iHw3cCKQDi4DewOdAv8peJyIiIiK1T7hjMG8EzgC+c879BOgGbIhaVCIiIiJxLtZ38YnnHtRwG5i7nXO7AcysrnOuADgxemGJiIiISE0V7kU+PjNLAd4BPjSzLcDBd7wXERERkVov3It8LvYePmBmHwNNgA+iFpWIiIhInNPvYIYWbg/mfs65T6IRiIiIiIgcHcIdgykiIiIiEpbD7sEUEREREZ0ir4x6MEVEREQkotSDKSIiIlIF8fw7lLGmHkwRERERiSg1MEVEREQkonSKXERERKQKdIo8NPVgioiIiEhEqQdTREREpAr0M0WhqQdTRERERCJKDUwRERERiSidIhcRERGpAp0iD009mCIiIiISUerBFBEREakC/UxRaOrBFBEREZGIUgNTRERERCJKp8hFREREqkAX+YSmHkwRERERiSj1YIqIiIhUgS7yCc2ci3oHr3qQRUREJNIs1gF0Not5G+cr52K+HipSLT2YS9rGZe4R12W1g9XzYx1G9Wnbg3FWO+r2Gee4vZbkCvCYc2TXknyvcw43vHbkCmBvOabVkrod6hzLO9aOXAFO+DrmbR2R/XSKXERERKQK1KQPTRf5iIiIiEhEqQdTREREpAp0kU9o6sEUERERkYhSA1NEREREIkqnyEVERESqQBf5hKYeTBERERGJKDUwRURERCSidIpcREREpAp0FXlo6sEUERERkYhSD6aIiIhIFegin9DUgykiIiIiEaUGpoiIiIhElE6Ri4iIiFSBLvIJTT2YIiIiIhJR6sEUERERqQJd5BOaejBFREREJKLUwBQRERGRiNIpchEREZEq0EU+oakHU0REREQiSj2YIiIiIlWgHszQ1IMpIiIiIhGlBqaIiIiIRJROkYuIiIhUgX4HMzT1YIqIiIhIRKkHU0RERKQK1IMZmnowRURERCSi1MAUERERkYjSKXIRERGRKtDvYIamHkwRERERiaga18Bs1HcgHf9bQMc5hbQcc8dB81Mu/gUn/CePE/6Tx/E5c6jXqSsAyW3Taf/mTDI/ySfz46U0H3VDdYdeJbO/yGPgyFsZ8Mubmfj3nJDlFhd8w8n9r+CDT+YB8O33qxk2+q79f92HjuLlt96vrrDDdtLAgdxdUMA9hYX0v+Pg+gS45NlnuaewkNvz8kjv1m3/9PpNmvCrN9/krmXLuCs/n3a9ewMw6P77ecDn47aFC7lt4UJOHjy4WnIJR8eBA7mtoIDbCwvpGyLfC599ltsLC7kpL480L9+WHTsybuHC/X8PFRVxzo03AjDg/vu5x+fbP++kOMp3n4yBA7msoICswkJOqyDvlBNP5KLPPmP07t10veWW/dMT69bl4nnzGL5oESOWLqXHAw9UY9RH4LSB8GwB/KUQLqqgns/9BTyZF/h7eA4c1/XAvCE3wFNL4OmlMPTG6ov5CLQcOJDzCgroW1hIhwrqt+GJJ3LWZ58xaPdujg+q34YdO3LOwoX7/35aVES7G+M75wbnDuTYDwo49sNCUq49ONdGP/sFGTl5ZOTkkTZlDnVO6lq2QEICGe8soE32v6op4ui56667OPPMM7ngggtiHYrEoZp1ijwhgbaPjGdF1gBK1vjoMD2XbTNy2FO4bH+RvatW8O2l51FatJVGPxlE2mMT+eaC3riSEtY8dAu7lywkoWEjTvjgS3bM/rDMa+ON31/KQ8++zEuP30Vqy2YM/83v6HdWd05ol35QuScmTuGcMw4cyI4/ti3vvvjH/fP7jBjDgHN6VGv8h2IJCQwfP54JAwaw1efj5txclubksG7ZgTo5efBgWmZm8nBmJsf16sWICRN42mtIXvzssxR88AEvjxhBYnIydRo02P+6T55+mo+ffLLac6qMJSRw8fjxvDBgAEU+H2Nzc8nPyWF9UL4nDR5Mi8xMHsvM5Nhevbh4wgSe692bDV9/zTNeY9MSErj3hx9Y+s9/7n/df59+mtlxlu8+lpDA2ePHM23AAHb6fFySm8vKnBy2BuW9e/Nm5txwA+0uuqjMa/179vCvfv0o2bmThKQkLvz0U75//33Wz5tX3WmELyEBRo+HhwbAZh/8KRfm54Av6FizfgXcdx7s3ArdBsFvJsJdvSGjM5x/DdzZE0r2wr0fwJfTYO3y2OVzKAkJdB4/nnkDBrDb5+OcCazAzAAAGPBJREFU3FzW5eSwI6h+izdv5qsbbqB1ufrd+fXXfLrvS2NCAv1/+IF1Qdt13ElIoOX94/nh6gGUrPWRMTWXnR/lUPzNgVxLfCv44YrzKN22lQZ9BtHq9xPxjei9f37KVTey95tlJDRqHIsMIuqSSy7hiiuu4I4QX5ZrA50iD61G9WA26NaTvSuXU/z9ClxxMUXvTqHxwGFlyuya/zmlRVsDjxfMJblNoDFWsn4tu5csBKB05w72LF9Gcpu06k3gMC0u+Ibj2qaS0bYVdZKTGNqvNx/N+fKgcq/9cwYDzz2D5ikVH7A+X7CUjLatSGvdMtohH5bjevZk4/LlbFqxAn9xMQunTKHLsLL12WXYMHJffRWA7+bNo35KCo1bt6buMcfQoU8f5k6aBIC/uJgfi4qqPYfDkeHlu9nLN2/KFDqXy7fTsGEs8PL93sv3mNaty5Q5oX9/Nn3zDVu//77aYj8SrXr2ZNvy5WxfsYLS4mKWT5lCu3J5796wgQ3z51NaXHzQ60t27gQgITmZhORkcHH+wyAn9Aw0CNevgJJimDMFziibL//7PNC4BPh6LjTzvjSmnxx4vvdHKPVD/ifQ6+Lqjf8wpfTsya7ly/lxReC4vHrKFFLL1e/eDRsoClG/+7To359d33zDj3G8Xdfr2pPi75ZTsmoFFBezY9oUGp1fblte+Dml2wJ1u3vRXJJaH+gQSExNo0HfoWx788VqjTtazjjjDJo0aRLrMCROhdXANLMOZlbXe9zXzG4ws5TohnawpNZpFK9etf958RpfpY3EZpePYvvHB58WTk4/jnqndGPXgjjuBQHWbdxM61bN9z9PbdmMdRu3lC2zYTP/+e98si48P+Ryps2cywX9z4panFXVJC2NLasO1OdWn48maWlhlWlx/PHs2LCBX7z0ErcuWMBlL7xQpgfz3DFjuD0vj8snTaJ+SrVvqhVqkpZGUVAuRT4fjSvId+sh1slpWVksev31MtPOGjOGm/LyGBFH+e7TIC2NHUE57fT5aJgW/pc7S0jg0oULGbl+PT98+CHrv/giGmFGTrM02HggXzb5AtNC6T8KFnrHqe+XQqc+0KgZ1KkP3YZA84zoxnuE6qWl8WNQ/e72+ah3GPW7T9usLFaX267jTWJqGsVrD+RastZHYmroXBsPH8XO2Qc+g1re8wybHrsdStXvdbRwcfAXr8LtwZwK+M3sBGAS0B74e9SiCsXsoEkuRG9Gw7P60vTyUax9uGzXfUKDhhz34lTW3DeO0h3boxJmpFSUmpVbBw+Pf41br8siMbHiqtxbXMLMz75k0Hm9ohHikQmnPkOUSUhKIr17d+ZMmMAT3buzd+dO+t95JwCfTpjA7zt04PHTTqNozRouipdTxxXkclAlH2KdJCYn0+nCC1n85pv7p30+YQKPdujAM6edxrY1a7ggXvL1lN9mgcPqhXSlpUzt1o2/pqfTsmdPmnbuHMHoouBw8u3cF/qNgr96x6kfCuCdR+G+DwOnx7/Lg9KSqIUaEUdYvwCWnEzqhReyJmi7jkuHkWv9Xn1pPGIUmx4P1G2DvkPxb1rPnq8WRDNCkbgR7hjMUudciZldDDzjnPuLmS0MVdjMrgWuBcjOzubMCAQKULLGR3LbA9/mk9ukU7J29UHl6p3chbQnXmTlFYPxb9l8YEZSEse+OJWtb/+Nbe/H8TgfT+uWzVi7ftP+5+s2bKZV87K9U0v/t4KbH3oOgC1F2/lkXh5JiYmc7423nD1vEZ07tqNFs/g7jVHk89E040B9pqSns2316grLrChXxjlHkc/Hd15vVt5bb+1vYO5Yv37/6+e+8ALXvPdedBMJU5HPR5OgfJuEyDelknVy4uDB/LBgQZkcgx9/8cILXB0n+e6z0+ejUVBODdPT2bn64P32UPYWFbFm1iwyBg1iy1dfRTLEyNrkgxZBvY7N02FLBfke1wX+70V4eDDsCDpOzZwc+AP4xcOB5cWx3T4f9YPqt156OrsPs35bDR5M0YIF7A3aluORf62P5NYHck1qnY5//cG51jmxC60efpHVowdTujVQt/VPP5uG/S+kwXlDsLr1SGjUmNTHX2PdbVdWW/wi1SncHsxiM7scuArY9+mVHKqwc26ic66Hc67Htddee6Qx7rdrUS5122eSnNEOS06mybAstv277JXVyWkZHPvi2/huuJK93xaWmZf+5CT2FC5j48SnIxZTNHU56XhW/rCWVWvWs7e4hGkz59LvrNPLlJn5+jPMnPIsM6c8y8DzenL/uF/tb1wCTJv5OUP7xd/pcYDvc3NpkZlJs3btSExOpltWFktzytbn0pwczhg5EoDjevXix6Iitq1dy/Z169iyahWtOnYEoGP//qzLzwegcdCYxS4XX8yapUurKaPK+bx8m3r5npqVRX65fPNzcuju5Xusl+/2tWv3zz/t8ssPOj0ePEbzlIsvZm2c5LvP+txcmmRmcky7diQkJ3NCVhbf5YT+RYRg9Vq0oI43xiuxXj3Szj+frQUF0Qz3yC3PhTaZ0KodJCXD2VmQWy7fFhlw69vwlythTdnjFI1bHijT6xL4NL5PGxfl5tIwM5P67QLH5bZZWawLs373aXv55XF/ehxg95JckttlkpTeDpKTaTQ0i50flc01qU0GrZ97m3W3XUnxygN1u+nJu1nZJ4Pv+rVn3U1Z/Dh3phqXR4FYnx6P51Pk4fZgXg38BnjYObfCzNoDf41eWCH4/ay+Zwzt/z4DEhPZMmUye77Op9mV1wGw+bVsWt10H0lNm9P2j88D4EpK+GbwGTToeTZNR4zkx/zFnPBhoPN13R/vZvvM+Pvpnn2SEhO574ZfMfr2R/GXlnLp4PPIbJ/O6zn/AeDySsZdAvy4ew+ffbmUh24eVR3hHrZSv5+pY8bwmxkzSEhMZN7kyazNz+es6wL1+Vl2NvnTp3PykCHcu3w5e3ft4vWrr97/+rfHjuWKv/2NpDp12PTtt/zdm/ezxx4j7bTTwDk2r1zJG97yYq3U7+fdMWMY7eWbO3ky6/Lz6e3FNzc7m4Lp0zlpyBDu8PJ9Myjf5Pr1yRwwgLfL5TPkscdo6+W7ZeVKpsZJvvs4v59Px4xhyIwZWGIi/5s8mS35+ZzsxbksO5v6qalcMn8+dRo3xpWW0mXcON7o1IkGbdrwk1dewRITsYQEvnnjDb6fNi3GGR1CqR9eHAP3zoCExEBvpC8ffurVy7+zYfh9cExzGP2895oSuOOMwOPbpkKj5uAvhhevP3AxUJxyfj9Lx4yhp1e/vsmT2ZGfz7Fe/X6fnU3d1FTOnj+fpMaNobSUduPGMbtTJ0q2byehfn1aDBjAkjjbbivk97PhoTG0nRTIddtbk9m7PJ/GWYHYt03JpumY+0hMaU7LBw58BvkuPSOWUUfNzTffzBdffMGWLVvo06cPY8eOZcSIEbEOS+KEhRrDGPIFZk2BDOfc4jBf4pa0rWDcylGoy2oHq+fHOozq07YH4yoak3QUesY5bq8luQI85hzZtSTf65zDDa8duQLYW45ptaRuhzrH8o61I1eAE76O5/6sqIh55TY3i/lK3+RczNdDRcK9inyWmTU2s2ZAHvCSmT0V3dBEREREpCYKdwxmE+fcNuAS4CXn3OlA5ednRURERKRWCncMZpKZtQF+DtwTxXhEREREagT9omlo4fZgPgTMAJY753LN7Hig8BCvEREREZFaKKweTOfcm8CbQc+/BS6NVlAiIiIi8S7mV/jEsbAamGZWDxgFdAbq7ZvunPt1lOISERERkRoq3FPkrwGtgYHAJ0A6EN/3WRQRERGRmAi3gXmCc+53wE7n3CvAUKBL9MISERERiW+xvotPPJ+iD/tWkd7/rWZ2CtAEaBeViERERESkRgv3Z4omenfw+R2QAzQC7otaVCIiIiJxTj9TFFq4V5G/6D38BDg+euGIiIiISE1XaQPTzG6ubL5zTreLFBEREZEyDtWDeYz333HwTeXjeWypiIiISFSpIRRapQ1M59yDAGb2CnCjc26r97wp8GT0wxMRERGRmibcq8i77mtcAjjntgDdohOSiIiISPwrjYO/I2FmzczsQzMr9P43DVFuspmtN7Ol4S473AZmQvCbmlkzwr8CXURERETiz53AR865TOAj73lFXgYGHc6Cw20kPgl8ZmZvERhy8HPg4cN5IxERERGJK8OAvt7jV4BZwB3lCznnZptZu8NZcLg/U/Sqmc0H+hG42OcS51z+4byRiIiIyNEkHi7yMbNrgWuDJk10zk0M8+Wpzrk1AM65NWbWKlJxhX2a22tQqlEpIiIiEie8xmTIBqWZ/QdoXcGse6IWFBpHKSIiInLUcs6dH2qema0zszZe72UbYH2k3jfci3xEREREJEisryCPwK0qc4CrvMdXAe8e+SID1MAUERERqZ3+BAwws0JggPccM2trZtP3FTKz14HPgRPNzGdmow61YJ0iFxEREamCeLjI50g45zYB/SuYvhoYEvT88sNdtnowRURERCSi1MAUERERkYjSKXIRERGRKojARTZHLfVgioiIiEhEqQdTREREpApq+kU+0aQeTBERERGJKDUwRURERCSidIpcREREpAp0kU9o5lzURxBoiIKIiIhEmsU8ALOYt3GcczFfDxWpjlPkFos/M7suVu+tXJWv8lWuyrf25lrb8o1hrjHnnLNY/8V6HYRyNI/BvDbWAVSj2pQrKN+jWW3KFWpXvrUpV6hd+damXCVMR3MDU0RERERiQA1MEREREYmoo7mBOTHWAVSj2pQrKN+jWW3KFWpXvrUpV6hd+damXCVM1XEVuYiIiIjUIkdzD6aIiIiIxIAamCIiIiISUWpghsHMLjKzTtX8nrPMrEd1vqdUjZmlmNlvvcd9zey9EOVerGw7MrMHzOzWaMVZXczsswgvr52ZLfUe9zCzP0dy+dFiZn4zW2RmeWa2wMzO8qa3MzNnZr8PKtvCzIrN7DnveY3dFmpqfUnlavI2KbFRIxqYZpYY4xAuAqq1gVmbVGf9Rum9UoDfHqqQc260cy4/Cu8fV5xzZ0Vx2fOdczdEa/kR9qNz7jTn3KnAXcAfg+Z9C1wQ9HwE8FV1BlcdDre+LKBGfC6JSOViviN733YLzOwVM1tsZm+ZWQMzW2lm95nZp8AIM/upmX3u9QS8aWaNvNcP8V7/qZn9eV/vkfdta7LXE/itmd0Q9J7vmNmXZvaVmV0bNH2HmT3s9TjMNbNUr9fhQuBxrzeiQ3XkX67MBDOb78X7YND0P5lZvve6J7xpL3vlP/byPs9bD8vM7OVDLTPSIlC/FeU4wsyWevU025v2q329P97z98ysr/d4h5k9ZGbzgDPN7Aoz+8Krz+wINDr/BHQws0XA40AjL88CM/ubmZkXx/5eaTMb5OWaZ2YfVbDerjGz982svve6R72Yvzazc70yiWb2uJnleuvnOm96GzOb7eW31MzO9cq+7D1fYmY3HWHOIZnZDu9/Xy/2itZFqG13ePnllFv2/h5iq2Qfj0ONgS1Bz38EltmBsxSXAW9Ue1QhVLLfnm5mn1jg+DnDzNp45U/3tuXPgeuDlhNcXy3N7ENvu882s+8s0HPbzjs+PQ8sADLM7Lag7Tr4mBfpfbfKrILPETMb5e2js8zsBTvQI93SzKZ6OeWa2dmxijtcZjbSW/95ZvZauXnXeHnkeXk18KZXdGzuHFRni80sMxb5SAw452L6B7QjcL/ys73nk4FbgZXA7d60FsBsoKH3/A7gPqAesApo701/HXjPe/wA8BlQ13v9JiDZm9fM+18fWAo095474Gfe48eAe73HLwPDqzn/WUCPcvEmetO7As2A/3HglwBSgmKdQuA2WsOAbUAXAl8mvgROC7XMOKzfUDkuAdLKTfsV8FzQ+74H9A2q1597j08G/hW0LTwPjIxAjku9x32BIiDdW+efA+d482YBPYCWlN1u99XFA966GQPkAHWDXvek93gI8B/v8bVB22hdYD7QHrgFuCeofo8BTgc+DIo5JYr79I7K1kUl9foyQftZ0HLKr99D7uPx8Af4gUVAgbceTg/Oh8AX1ye89fNR8Da8b1uIYeztOHi/vc1b3y29aZcBk73Hi4HzvMePh6iv54C7vMeDvOW38N6rFOjtzfspgZ+9MW+7eQ/oQxT23SNcR+U/R9IIHNeaAcnAf4Pq8+8cOA4cCyyL9fZ5iNw6e/toi325Bm+TeJ+Z3uM/AGO9xxUdm/8C/NJ7XAeoH+v89Fc9f0nEh1XOuTne478C+3oi/uH9703gFPUcrwOkDoEPq5OAb51zK7xyr1P2llXTnHN7gD1mth5IBXzADWZ2sVcmA8gk8OG0l8DBDAKNsQERy7ByofLf5+feN+QkoA2BdZEP7AZeNLNpHIgb4F/OOWdmS4B1zrklAGb2FYGD+aIQy1wcjeSoev1uo+Ic5wAvm9kbwNthvL8fmOo97k+gsZXrvVd9YH3V0grpC+ecD8ACvZrtgE+D5vcGZu/bbp1zm4PmXUlgG73IOVccNH1fnl96y4PAB3HXoF6/JgS25VxgspklA+845xaZ2bfA8Wb2F2Aa8O9IJBqGitbFXEJvu4cr1D4eD350zp0GYGZnAq+a2SlB8z8Afg+s48C+EE/K77d3A6cAH3r7TiKwxsyaEGhMfOKVfQ0YXMHyzgEuBnDOfWBmwT263znn5nqPf+r9LfSeNyKwXXcl+vvu4Sj/OXIl8Mm+/dnM3gQ6evPPBzp5cQM0NrNjnHPbqzPgw9APeMs5txECx6ig2AFOMbM/EBge1AiY4U2v6Nj8OXCPmaUDbzvnCqsjAYm9eGlglv8xzn3Pd3r/jUDvy+XBhcys2yGWuyfosR9IssBp0/OBM51zu8xsFoGeUIBi55wLLh92BkcmVP6YWXsCvVpnOOe2WOA0dz3nXImZ9STQYMoi0OvVz3vZvrxLKbsOSgmsgwqXGdmUKs6n3PNK6xegohydc78xs17AUGCRmZ0GlFB2yEdwPrudc/6g93rFOXfXkSR0CAdtd+XmGwevk32WAqcR6NVaETR93zKDl2cEeg5mUI6Z9SGwfl4zs8edc6+a2anAQAKnMH8O/DrsjKruoHVRyba7vw4t8GlWpyrLj0TQkeac+9zMWhDovd43ba+ZfUmgx7kz8LNYxRdC+W10O/CVc+7M4IlmllJB2YpYJfN2Bj024I/Ouexy7zOW6O+7YQnxOfI/Ar2sFUnwyv5YPREescqOURA423CRcy7PzH5FoKeaio7Nzrm/W2B40lBghpmNds7NjGr0EhdiPgbTc6z3DR/gcsr29kCgx+NsMzsBwBsL1JHAqafjzaydV+6yMN6rCbDFOyicRKA36VC2EzjNGC2V5d+YwMG3yMxS8XoGLDBGsYlzbjowjkCjJFwVLjOKqlS/oXI0sw7OuXnOufuAjQR6D1YCp5lZgpllAD1DxPIRMNzMWnnLamZmxx1hfoe7fXwOnOc19DGzZkHzFgLXATlm1vYQy5kB/J/XU4m3zhp6+ax3zr0ATAK6e42bBOfcVOB3QPfDiDeiKtl2VxLooYLA8I7k6o8uOrxjTSKBMyXBngTucM6Vnx4Pyu+3c4GW+6aZWbKZdXbObSVwLDnHK/vLEMv7lMAXG8zsp0DTEOVmAL+2A+Ow07z9NRr7blVV9DnSgMB+3dTMkoBLg8r/m8AXKQC8L8Xx7CMCZ7maw0HHKAgc79Z4x5799V3RsdnMjidwpvHPBIb+dK2WDCTm4uXb/jLgKjPLBgqBCcDYfTOdcxu8b0mvm1ldb/K9zrmvLfDzMB+Y2UbgizDe6wPgN2a2mMA3zrmHKA+BMY0vWOAiguHOuW/CTSxMFeX/MwDvG+JCAleYfkvgFAQEdvB3zawegW+bYV+0Uckyo6VK9Uug4VZRjo9bYKC4ETgQ5nnTVxAYA7SUwMUCB3HO5ZvZvcC/LXC1ajGBHr3vqpqcc26Tmc2xwE+z/EjglGdl5Td4wxPe9mJYT9BwDOfcpxb4OZBpZlbZMI0XCZxyXuD1+G0g8IsHfYHbzKwY2AGMJDA+7CU7cIVuLHuBQm27L3jTvyBQrztDvL6mqO8NC4BAnlc55/zBpxqdc18Rv1ePl99v/0Kg8fdn77R4EvAMgfivJjAsYxcHTpeW9yCBffwy4BNgDYF9vFFwIefcv83sZOBzb13tAK6Ixr57BCr6HPkBeASYB6wmMIypyCt/AzDeK59EYMz5b6o76HA5574ys4eBT8zMT+CL78qgIr8jkOd3BI65+75gV3RsvhO4wjserQUeqpYkJOZifqtIr/fxPefcKYcoGur1jZxzO7wP2PFAoXPu6QiGGFVHmn+8O9rzEzkaRWO/9b48+r0hEmcCE/aNUT1aBH0eJQH/JHAR1D9jHZdILMRLD+aRuMbMriIwXmshkH2I8iIiUv2OBd7weh/3AtfEOJ5oeMDMzicwBvzfwDsxjkckZmLegykiIiIiR5d4uchHRERERI4SamCKiIiISESpgSkiIiIiEaUGpoiIiIhElBqYIiIiIhJR/x9YYg6gHmhhMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############신경망을 이용한 이진 분류###########################\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 피마 인디언 당뇨병 데이터셋 로드\n",
    "# 각 컬럼에 해당하는 이름을 지정\n",
    "df = pd.read_csv('./dataset/pima-indians-diabetes.csv',\n",
    "               names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
    " \n",
    "print(df.head())\t\t\n",
    "\n",
    "# 데이터의 전반적인 정보를 확인 (컬럼 데이터 타입)\n",
    "print(df.info())\t   \n",
    "\n",
    "#8개의 속성중 heatmap을 이용해서 당뇨병에 상관성이 높은 특성 찾기\n",
    "colormap = plt.cm.gist_heat   #그래프의 색상 구성 \n",
    "plt.figure(figsize=(12,12))   #그래프의 크기 정의\n",
    "\n",
    "# 그래프의 속성-vmax의 값을 0.5로 지정해 0.5에 가까울 수록 밝은 색으로 표시   \n",
    "sns.heatmap(df.corr(),linewidths=0.1,vmax=0.5, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#클래스 0(정상)인 데이터중 plasma값 분포 \n",
    "#클래스 1(당뇨)인 데이터중 plasma값 분포\n",
    "grid = sns.FacetGrid(df, col=\"class\")\n",
    "grid.map(plt.hist, 'plasma', bins=10)\n",
    "plt.show()\n",
    "\n",
    "#텐서플로우 라이브러리의 신경망을 사용하여 학습후 정확도 출력\n",
    "#첫번째 은닉층 출력뉴런수 12 , 활성화 함수 relu\n",
    "#두번째 은닉층 출력뉴런수 8 , 활성화 함수 relu\n",
    "#출력층 출력뉴런수 1 , 활성화 함수 sigmoid\n",
    "#오차계산함수 binary_crossentroy\n",
    "#최적화함수 adam\n",
    "#측정 지표 accuracy\n",
    "#각 데이터 샘플당 200, batch_size=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples\n",
      "Epoch 1/200\n",
      "768/768 [==============================] - 0s 584us/sample - loss: 7.1497 - accuracy: 0.6224\n",
      "Epoch 2/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 2.1107 - accuracy: 0.6393\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 1.3271 - accuracy: 0.6068\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 1.0484 - accuracy: 0.6172\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 182us/sample - loss: 0.8735 - accuracy: 0.6133\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 216us/sample - loss: 0.7920 - accuracy: 0.6198\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.7347 - accuracy: 0.6224\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.6908 - accuracy: 0.6406\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.6772 - accuracy: 0.6549\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 188us/sample - loss: 0.6674 - accuracy: 0.6523\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 197us/sample - loss: 0.6639 - accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 238us/sample - loss: 0.6624 - accuracy: 0.6615\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 230us/sample - loss: 0.6530 - accuracy: 0.6615\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 199us/sample - loss: 0.6563 - accuracy: 0.6680\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 184us/sample - loss: 0.6465 - accuracy: 0.6706\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.6420 - accuracy: 0.6732\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.6487 - accuracy: 0.6771\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.6418 - accuracy: 0.6784\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 184us/sample - loss: 0.6445 - accuracy: 0.6589\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 181us/sample - loss: 0.6283 - accuracy: 0.6706\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 214us/sample - loss: 0.6324 - accuracy: 0.6693\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 217us/sample - loss: 0.6287 - accuracy: 0.6823\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 201us/sample - loss: 0.6217 - accuracy: 0.6771\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.6191 - accuracy: 0.6758\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 190us/sample - loss: 0.6382 - accuracy: 0.6615\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.6253 - accuracy: 0.6680\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.6284 - accuracy: 0.6732\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.6149 - accuracy: 0.6758\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.6311 - accuracy: 0.6693\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.6054 - accuracy: 0.6745\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5986 - accuracy: 0.7005\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.6022 - accuracy: 0.6732\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.5943 - accuracy: 0.6823\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.6001 - accuracy: 0.6758\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.5974 - accuracy: 0.6849\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 221us/sample - loss: 0.5884 - accuracy: 0.6901\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 193us/sample - loss: 0.5883 - accuracy: 0.6901\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5887 - accuracy: 0.6849\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5937 - accuracy: 0.6784\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5990 - accuracy: 0.6706\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5931 - accuracy: 0.6836\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 161us/sample - loss: 0.5943 - accuracy: 0.6810\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5900 - accuracy: 0.6823\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5858 - accuracy: 0.6836\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5858 - accuracy: 0.6888\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5880 - accuracy: 0.6823\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 167us/sample - loss: 0.5893 - accuracy: 0.6901\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5884 - accuracy: 0.6914\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5844 - accuracy: 0.6823\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5844 - accuracy: 0.6940\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 168us/sample - loss: 0.5861 - accuracy: 0.6797\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5844 - accuracy: 0.6823\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.5791 - accuracy: 0.6849\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5849 - accuracy: 0.6927\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.5792 - accuracy: 0.6888\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5826 - accuracy: 0.6901\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5764 - accuracy: 0.6862\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5856 - accuracy: 0.6836\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.6138 - accuracy: 0.6732\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 204us/sample - loss: 0.5779 - accuracy: 0.6966\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 210us/sample - loss: 0.5795 - accuracy: 0.6862\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 179us/sample - loss: 0.5718 - accuracy: 0.6927\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.5840 - accuracy: 0.6914\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5762 - accuracy: 0.6927\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.5709 - accuracy: 0.6914\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.5667 - accuracy: 0.6927\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5700 - accuracy: 0.7005\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.5747 - accuracy: 0.6823\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5722 - accuracy: 0.6966\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 192us/sample - loss: 0.5996 - accuracy: 0.6836\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 182us/sample - loss: 0.5785 - accuracy: 0.6836\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 192us/sample - loss: 0.5723 - accuracy: 0.6836\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 190us/sample - loss: 0.5680 - accuracy: 0.6888\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 181us/sample - loss: 0.5690 - accuracy: 0.6940\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 186us/sample - loss: 0.5787 - accuracy: 0.6888\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 186us/sample - loss: 0.5706 - accuracy: 0.6849\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5727 - accuracy: 0.6784\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5826 - accuracy: 0.6836\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 161us/sample - loss: 0.5702 - accuracy: 0.6979\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5715 - accuracy: 0.6823\n",
      "Epoch 81/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5701 - accuracy: 0.6901\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5683 - accuracy: 0.6888\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5694 - accuracy: 0.6914\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 206us/sample - loss: 0.5680 - accuracy: 0.6836\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 221us/sample - loss: 0.5754 - accuracy: 0.6914\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5668 - accuracy: 0.6979\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 161us/sample - loss: 0.5715 - accuracy: 0.6927\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.5632 - accuracy: 0.6992\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5637 - accuracy: 0.6940\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5768 - accuracy: 0.6927\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 156us/sample - loss: 0.5603 - accuracy: 0.6953\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 167us/sample - loss: 0.5635 - accuracy: 0.6940\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5669 - accuracy: 0.6940\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5722 - accuracy: 0.6797\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5664 - accuracy: 0.6940\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.5707 - accuracy: 0.6979\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5699 - accuracy: 0.7057\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.5622 - accuracy: 0.7018\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5763 - accuracy: 0.6862\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5600 - accuracy: 0.6992\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5603 - accuracy: 0.6979\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5635 - accuracy: 0.6901\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5624 - accuracy: 0.6979\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5623 - accuracy: 0.6836\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5649 - accuracy: 0.6836\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5621 - accuracy: 0.7018\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.5533 - accuracy: 0.6979\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 168us/sample - loss: 0.5560 - accuracy: 0.7018\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 203us/sample - loss: 0.5548 - accuracy: 0.6901\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 206us/sample - loss: 0.5647 - accuracy: 0.6875\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 192us/sample - loss: 0.5611 - accuracy: 0.6849\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5734 - accuracy: 0.6888\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 180us/sample - loss: 0.5594 - accuracy: 0.6966\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 200us/sample - loss: 0.5550 - accuracy: 0.6953\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 188us/sample - loss: 0.5642 - accuracy: 0.6966\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 187us/sample - loss: 0.5527 - accuracy: 0.6992\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 161us/sample - loss: 0.5757 - accuracy: 0.6966\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5652 - accuracy: 0.6992\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 179us/sample - loss: 0.5523 - accuracy: 0.7044\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5534 - accuracy: 0.7018\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5563 - accuracy: 0.7018\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5572 - accuracy: 0.6979\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.5550 - accuracy: 0.7005\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 161us/sample - loss: 0.5530 - accuracy: 0.6927\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.5544 - accuracy: 0.7018\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5821 - accuracy: 0.6836\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5614 - accuracy: 0.6979\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 223us/sample - loss: 0.5596 - accuracy: 0.6940\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 232us/sample - loss: 0.5578 - accuracy: 0.6953\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 190us/sample - loss: 0.5707 - accuracy: 0.6914\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5545 - accuracy: 0.6979\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 167us/sample - loss: 0.5652 - accuracy: 0.6810\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 199us/sample - loss: 0.5619 - accuracy: 0.6914\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 240us/sample - loss: 0.5741 - accuracy: 0.6914\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 203us/sample - loss: 0.5568 - accuracy: 0.7018\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5518 - accuracy: 0.6953\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5537 - accuracy: 0.7018\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5559 - accuracy: 0.7005\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5448 - accuracy: 0.7083\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 199us/sample - loss: 0.5695 - accuracy: 0.6784\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5562 - accuracy: 0.6901\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5536 - accuracy: 0.6953\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.5546 - accuracy: 0.6901\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 187us/sample - loss: 0.5621 - accuracy: 0.6966\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 184us/sample - loss: 0.5575 - accuracy: 0.6888\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5625 - accuracy: 0.6966\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5644 - accuracy: 0.6953\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5683 - accuracy: 0.6784\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5502 - accuracy: 0.7083\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.5502 - accuracy: 0.7005\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 187us/sample - loss: 0.5492 - accuracy: 0.6979\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 184us/sample - loss: 0.5646 - accuracy: 0.6875\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 168us/sample - loss: 0.5528 - accuracy: 0.6966\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 184us/sample - loss: 0.5440 - accuracy: 0.7135\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 182us/sample - loss: 0.5463 - accuracy: 0.6914\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 161us/sample - loss: 0.5471 - accuracy: 0.6940\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 212us/sample - loss: 0.5531 - accuracy: 0.6875\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 213us/sample - loss: 0.5413 - accuracy: 0.7018\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 184us/sample - loss: 0.5563 - accuracy: 0.6836\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5525 - accuracy: 0.6940\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5465 - accuracy: 0.7018\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5496 - accuracy: 0.7057\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 167us/sample - loss: 0.5463 - accuracy: 0.6914\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.5473 - accuracy: 0.7057\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 155us/sample - loss: 0.5429 - accuracy: 0.7031\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5427 - accuracy: 0.6992\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.5475 - accuracy: 0.7018\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5422 - accuracy: 0.7018\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 179us/sample - loss: 0.5445 - accuracy: 0.6953\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5751 - accuracy: 0.7057\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5578 - accuracy: 0.6914\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 178us/sample - loss: 0.5497 - accuracy: 0.6940\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 186us/sample - loss: 0.5451 - accuracy: 0.6979\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5512 - accuracy: 0.6966\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5453 - accuracy: 0.7005\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5636 - accuracy: 0.6888\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 184us/sample - loss: 0.5436 - accuracy: 0.6979\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 197us/sample - loss: 0.5416 - accuracy: 0.6979\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 179us/sample - loss: 0.5469 - accuracy: 0.7018\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 194us/sample - loss: 0.5554 - accuracy: 0.6888\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 212us/sample - loss: 0.5504 - accuracy: 0.6901\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 251us/sample - loss: 0.5484 - accuracy: 0.6979\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 214us/sample - loss: 0.5520 - accuracy: 0.6914\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 206us/sample - loss: 0.5419 - accuracy: 0.7044\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5406 - accuracy: 0.7018\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 195us/sample - loss: 0.5391 - accuracy: 0.7005\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 195us/sample - loss: 0.5458 - accuracy: 0.7018\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 173us/sample - loss: 0.5432 - accuracy: 0.6992\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5502 - accuracy: 0.6966\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.5433 - accuracy: 0.6914\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.5432 - accuracy: 0.7031\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5405 - accuracy: 0.6953\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 181us/sample - loss: 0.5426 - accuracy: 0.7070\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5411 - accuracy: 0.6940\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5375 - accuracy: 0.7044\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5462 - accuracy: 0.6953\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5369 - accuracy: 0.7005\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 175us/sample - loss: 0.5426 - accuracy: 0.7018\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5339 - accuracy: 0.6953\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5393 - accuracy: 0.6966\n",
      "768/768 [==============================] - 0s 126us/sample - loss: 0.5350 - accuracy: 0.7083\n",
      "\n",
      " Accuracy: 0.7083\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "dataset = numpy.loadtxt(\"./dataset/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=200, batch_size=10)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "354/354 [==============================] - 0s 364us/step - loss: 2256.6481\n",
      "Epoch 2/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 115.4973\n",
      "Epoch 3/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 77.7723\n",
      "Epoch 4/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 71.7014\n",
      "Epoch 5/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 70.0138\n",
      "Epoch 6/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 67.9230\n",
      "Epoch 7/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 63.9999\n",
      "Epoch 8/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 62.8963\n",
      "Epoch 9/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 61.1088\n",
      "Epoch 10/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 60.2831\n",
      "Epoch 11/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 57.9598\n",
      "Epoch 12/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 58.9161\n",
      "Epoch 13/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 57.5137\n",
      "Epoch 14/200\n",
      "354/354 [==============================] - 0s 175us/step - loss: 55.7293\n",
      "Epoch 15/200\n",
      "354/354 [==============================] - 0s 149us/step - loss: 55.0871\n",
      "Epoch 16/200\n",
      "354/354 [==============================] - 0s 183us/step - loss: 53.5604\n",
      "Epoch 17/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 53.3372\n",
      "Epoch 18/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 52.8311\n",
      "Epoch 19/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 52.7166\n",
      "Epoch 20/200\n",
      "354/354 [==============================] - 0s 163us/step - loss: 50.4061\n",
      "Epoch 21/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 49.5612\n",
      "Epoch 22/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 49.1816\n",
      "Epoch 23/200\n",
      "354/354 [==============================] - 0s 149us/step - loss: 48.3673\n",
      "Epoch 24/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 46.7019\n",
      "Epoch 25/200\n",
      "354/354 [==============================] - 0s 152us/step - loss: 46.4249\n",
      "Epoch 26/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 45.8327\n",
      "Epoch 27/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 45.1502\n",
      "Epoch 28/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 43.6436\n",
      "Epoch 29/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 42.7048\n",
      "Epoch 30/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.7012\n",
      "Epoch 31/200\n",
      "354/354 [==============================] - 0s 166us/step - loss: 42.7667\n",
      "Epoch 32/200\n",
      "354/354 [==============================] - 0s 192us/step - loss: 43.3946\n",
      "Epoch 33/200\n",
      "354/354 [==============================] - 0s 166us/step - loss: 40.7156\n",
      "Epoch 34/200\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.4610\n",
      "Epoch 35/200\n",
      "354/354 [==============================] - 0s 152us/step - loss: 39.1020\n",
      "Epoch 36/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 38.9086\n",
      "Epoch 37/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 37.9475\n",
      "Epoch 38/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.7140\n",
      "Epoch 39/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 38.1097\n",
      "Epoch 40/200\n",
      "354/354 [==============================] - 0s 183us/step - loss: 38.7022\n",
      "Epoch 41/200\n",
      "354/354 [==============================] - 0s 163us/step - loss: 38.0560\n",
      "Epoch 42/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 35.8656\n",
      "Epoch 43/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 35.4409\n",
      "Epoch 44/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 35.1872\n",
      "Epoch 45/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 35.7884\n",
      "Epoch 46/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 34.5523\n",
      "Epoch 47/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.7206\n",
      "Epoch 48/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 35.1744\n",
      "Epoch 49/200\n",
      "354/354 [==============================] - 0s 144us/step - loss: 34.7427\n",
      "Epoch 50/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 34.7988\n",
      "Epoch 51/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 32.9546\n",
      "Epoch 52/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 33.0171\n",
      "Epoch 53/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 33.8126\n",
      "Epoch 54/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 33.2698\n",
      "Epoch 55/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 32.6107\n",
      "Epoch 56/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 32.6504\n",
      "Epoch 57/200\n",
      "354/354 [==============================] - 0s 172us/step - loss: 33.0237\n",
      "Epoch 58/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 32.0819\n",
      "Epoch 59/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 29.6514\n",
      "Epoch 60/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 29.9299\n",
      "Epoch 61/200\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2773\n",
      "Epoch 62/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 30.5699\n",
      "Epoch 63/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 30.0727\n",
      "Epoch 64/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 29.6075\n",
      "Epoch 65/200\n",
      "354/354 [==============================] - 0s 147us/step - loss: 28.4795\n",
      "Epoch 66/200\n",
      "354/354 [==============================] - 0s 116us/step - loss: 28.8884\n",
      "Epoch 67/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 29.5936\n",
      "Epoch 68/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 27.6113\n",
      "Epoch 69/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 27.3184\n",
      "Epoch 70/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 26.7489\n",
      "Epoch 71/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 27.6658\n",
      "Epoch 72/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 28.2145\n",
      "Epoch 73/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 27.3463\n",
      "Epoch 74/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 26.9732\n",
      "Epoch 75/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 25.5132\n",
      "Epoch 76/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 24.3065\n",
      "Epoch 77/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6669\n",
      "Epoch 78/200\n",
      "354/354 [==============================] - 0s 110us/step - loss: 24.5680\n",
      "Epoch 79/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 25.3107\n",
      "Epoch 80/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 25.5942\n",
      "Epoch 81/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 24.4252\n",
      "Epoch 82/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 23.5695\n",
      "Epoch 83/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 24.6939\n",
      "Epoch 84/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 24.0880\n",
      "Epoch 85/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 23.2209\n",
      "Epoch 86/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 23.4266\n",
      "Epoch 87/200\n",
      "354/354 [==============================] - 0s 107us/step - loss: 23.4141\n",
      "Epoch 88/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 24.3036\n",
      "Epoch 89/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 22.1799\n",
      "Epoch 90/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 22.5896\n",
      "Epoch 91/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 20.2416\n",
      "Epoch 92/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 21.9430\n",
      "Epoch 93/200\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.0737\n",
      "Epoch 94/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 21.3055\n",
      "Epoch 95/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 20.8169\n",
      "Epoch 96/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 21.6025\n",
      "Epoch 97/200\n",
      "354/354 [==============================] - 0s 129us/step - loss: 21.8259\n",
      "Epoch 98/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 21.2467\n",
      "Epoch 99/200\n",
      "354/354 [==============================] - 0s 169us/step - loss: 20.3680\n",
      "Epoch 100/200\n",
      "354/354 [==============================] - 0s 169us/step - loss: 20.0447\n",
      "Epoch 101/200\n",
      "354/354 [==============================] - 0s 163us/step - loss: 26.1865\n",
      "Epoch 102/200\n",
      "354/354 [==============================] - 0s 161us/step - loss: 20.8894\n",
      "Epoch 103/200\n",
      "354/354 [==============================] - 0s 169us/step - loss: 20.9494\n",
      "Epoch 104/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 19.4314\n",
      "Epoch 105/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 21.5710\n",
      "Epoch 106/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 20.0791\n",
      "Epoch 107/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 19.1009\n",
      "Epoch 108/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 18.9971\n",
      "Epoch 109/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 19.0606\n",
      "Epoch 110/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 22.3843\n",
      "Epoch 111/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 18.1621\n",
      "Epoch 112/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 18.2784\n",
      "Epoch 113/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 19.9138\n",
      "Epoch 114/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 17.9113\n",
      "Epoch 115/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 18.6141\n",
      "Epoch 116/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 19.5770\n",
      "Epoch 117/200\n",
      "354/354 [==============================] - 0s 116us/step - loss: 20.3342\n",
      "Epoch 118/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 19.2527\n",
      "Epoch 119/200\n",
      "354/354 [==============================] - 0s 110us/step - loss: 18.8104\n",
      "Epoch 120/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 18.3071\n",
      "Epoch 121/200\n",
      "354/354 [==============================] - 0s 129us/step - loss: 18.1662\n",
      "Epoch 122/200\n",
      "354/354 [==============================] - 0s 141us/step - loss: 19.2423\n",
      "Epoch 123/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 18.0562\n",
      "Epoch 124/200\n",
      "354/354 [==============================] - 0s 144us/step - loss: 18.5191\n",
      "Epoch 125/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 20.5054\n",
      "Epoch 126/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 17.2492\n",
      "Epoch 127/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 18.0108\n",
      "Epoch 128/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 16.7445\n",
      "Epoch 129/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 17.5763\n",
      "Epoch 130/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 16.6961\n",
      "Epoch 131/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 16.7594\n",
      "Epoch 132/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 16.0869\n",
      "Epoch 133/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 16.3349\n",
      "Epoch 134/200\n",
      "354/354 [==============================] - 0s 129us/step - loss: 20.8336\n",
      "Epoch 135/200\n",
      "354/354 [==============================] - 0s 113us/step - loss: 16.9116\n",
      "Epoch 136/200\n",
      "354/354 [==============================] - 0s 129us/step - loss: 16.4996\n",
      "Epoch 137/200\n",
      "354/354 [==============================] - 0s 138us/step - loss: 16.6947\n",
      "Epoch 138/200\n",
      "354/354 [==============================] - 0s 144us/step - loss: 18.2907\n",
      "Epoch 139/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 17.2072\n",
      "Epoch 140/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 15.1556\n",
      "Epoch 141/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 16.8981\n",
      "Epoch 142/200\n",
      "354/354 [==============================] - 0s 116us/step - loss: 16.6665\n",
      "Epoch 143/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 16.2615\n",
      "Epoch 144/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 15.2753\n",
      "Epoch 145/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 16.5395\n",
      "Epoch 146/200\n",
      "354/354 [==============================] - 0s 149us/step - loss: 15.1187\n",
      "Epoch 147/200\n",
      "354/354 [==============================] - 0s 147us/step - loss: 14.7586\n",
      "Epoch 148/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 16.0856\n",
      "Epoch 149/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 15.5220\n",
      "Epoch 150/200\n",
      "354/354 [==============================] - 0s 129us/step - loss: 15.9394\n",
      "Epoch 151/200\n",
      "354/354 [==============================] - 0s 113us/step - loss: 14.7168\n",
      "Epoch 152/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 16.2880\n",
      "Epoch 153/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 15.7615\n",
      "Epoch 154/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 14.8295\n",
      "Epoch 155/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 15.5659\n",
      "Epoch 156/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 15.6292\n",
      "Epoch 157/200\n",
      "354/354 [==============================] - 0s 113us/step - loss: 16.4088\n",
      "Epoch 158/200\n",
      "354/354 [==============================] - 0s 129us/step - loss: 15.2256\n",
      "Epoch 159/200\n",
      "354/354 [==============================] - 0s 127us/step - loss: 14.6390\n",
      "Epoch 160/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 16.0932\n",
      "Epoch 161/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 15.3655\n",
      "Epoch 162/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 14.3738\n",
      "Epoch 163/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 14.9727\n",
      "Epoch 164/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 16.3018\n",
      "Epoch 165/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 16.1683\n",
      "Epoch 166/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 14.9856\n",
      "Epoch 167/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 16.6193\n",
      "Epoch 168/200\n",
      "354/354 [==============================] - 0s 149us/step - loss: 14.2432\n",
      "Epoch 169/200\n",
      "354/354 [==============================] - 0s 169us/step - loss: 14.6596\n",
      "Epoch 170/200\n",
      "354/354 [==============================] - 0s 169us/step - loss: 15.5777\n",
      "Epoch 171/200\n",
      "354/354 [==============================] - 0s 161us/step - loss: 18.5711\n",
      "Epoch 172/200\n",
      "354/354 [==============================] - 0s 166us/step - loss: 16.1284\n",
      "Epoch 173/200\n",
      "354/354 [==============================] - 0s 161us/step - loss: 14.8127\n",
      "Epoch 174/200\n",
      "354/354 [==============================] - 0s 113us/step - loss: 14.5386\n",
      "Epoch 175/200\n",
      "354/354 [==============================] - ETA: 0s - loss: 23.65 - 0s 121us/step - loss: 13.4546\n",
      "Epoch 176/200\n",
      "354/354 [==============================] - 0s 116us/step - loss: 14.7040\n",
      "Epoch 177/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 16.2850\n",
      "Epoch 178/200\n",
      "354/354 [==============================] - 0s 110us/step - loss: 15.6103\n",
      "Epoch 179/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 15.0656\n",
      "Epoch 180/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 14.2287\n",
      "Epoch 181/200\n",
      "354/354 [==============================] - 0s 118us/step - loss: 14.4810\n",
      "Epoch 182/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 13.9604\n",
      "Epoch 183/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 13.4342\n",
      "Epoch 184/200\n",
      "354/354 [==============================] - 0s 115us/step - loss: 13.0221\n",
      "Epoch 185/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 13.5375\n",
      "Epoch 186/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 13.5091\n",
      "Epoch 187/200\n",
      "354/354 [==============================] - 0s 116us/step - loss: 14.7365\n",
      "Epoch 188/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 13.7121\n",
      "Epoch 189/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 12.8621\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 124us/step - loss: 15.5717\n",
      "Epoch 191/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 14.6626\n",
      "Epoch 192/200\n",
      "354/354 [==============================] - 0s 132us/step - loss: 13.7611\n",
      "Epoch 193/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 19.8366\n",
      "Epoch 194/200\n",
      "354/354 [==============================] - 0s 124us/step - loss: 14.4209\n",
      "Epoch 195/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 13.3344\n",
      "Epoch 196/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 13.5104\n",
      "Epoch 197/200\n",
      "354/354 [==============================] - 0s 130us/step - loss: 14.3503\n",
      "Epoch 198/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 14.1032\n",
      "Epoch 199/200\n",
      "354/354 [==============================] - 0s 121us/step - loss: 13.3000\n",
      "Epoch 200/200\n",
      "354/354 [==============================] - 0s 135us/step - loss: 15.9098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b6c5b06e88>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########신경망으로 회귀분석 ######################\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./dataset/housing.csv\", delim_whitespace=True, header=None)\n",
    "\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 22.600, 예상가격: 20.644\n",
      "실제가격: 50.000, 예상가격: 26.160\n",
      "실제가격: 23.000, 예상가격: 21.862\n",
      "실제가격: 8.300, 예상가격: 12.438\n",
      "실제가격: 21.200, 예상가격: 18.469\n",
      "실제가격: 19.900, 예상가격: 21.916\n",
      "실제가격: 20.600, 예상가격: 19.160\n",
      "실제가격: 18.700, 예상가격: 24.081\n",
      "실제가격: 16.100, 예상가격: 18.952\n",
      "실제가격: 18.600, 예상가격: 13.862\n"
     ]
    }
   ],
   "source": [
    "# 예측 값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 14s 1us/step\n",
      "학습셋 이미지 수 : 60000 개 \n",
      "테스트셋 이미지 수: 10000 개 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "################# 신경망으로 이미지 인식 ################\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "#MNIST데이터셋 로드\n",
    "(X_train, Y_class_train),(X_test, Y_class_test) = mnist.load_data()\n",
    "print(\"학습셋 이미지 수 : %d 개 \"% (X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수: %d 개 \" %(X_test.shape[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0],cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d5b271195c36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 코드로 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d\\t'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# 코드로 확인\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%d\\t' % i)\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "#28*28 의 2차원 배열 => 784개의 1차원 배열 변환 reshape(총샘플수, 1차원 속성의 수)\n",
    "# X_train.reshpae(X_train[0].shape,784)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],784)\n",
    "X_train = X_train.astype('float64')\n",
    "\n",
    "X_train = X_train/255 # 정규화\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0],784).astype('float64') / 255\n",
    "\n",
    "print(X_train[0])  #정규화확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y 클래스 값 확인\n",
    "print(\"class: %d\"%(Y_class_train[0]))\n",
    "\n",
    "# Y클래스 값 one-hot-encoder 변환\n",
    "Y_train = np_utils.to_categorical(Y_class_train,10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test,10)\n",
    "\n",
    "print(Y_train[0])  #one-hot encoder 변환 확인\n",
    "\n",
    "# 모델 정의\n",
    "# 첫번째 은닉층 (출력뉴런수 512, 활성화함수 relu)\n",
    "# 출력층 (출력뉴런수 10, 활성화함수 softmax)\n",
    "# 오차함수 : categorial_crossentroy\n",
    "# 최적화 함수\n",
    "# 다중 분류 평가 측정 지표 accuracy\n",
    "\n",
    "# 모델 시행 결과 model폴더에 파일로 저장\n",
    "# 학습 중단\n",
    "\n",
    "# 학습 정확도와 테스트셋 오차를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers.core import Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    " \n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 데이터 로드\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#정규화\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# 정답 label one-hot enconding\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <class 'keras.layers.core.Flatten'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a6b911499c88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    131\u001b[0m             raise TypeError('The added layer must be '\n\u001b[0;32m    132\u001b[0m                             \u001b[1;34m'an instance of class Layer. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                             'Found: ' + str(layer))\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <class 'keras.layers.core.Flatten'>"
     ]
    }
   ],
   "source": [
    "#모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                input_shape=(28,28,1), activation='relu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 구축 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#모델 실행 결과 model 폴더에 파일로 저장\n",
    "#학습 중단 설정\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0,\n",
    "                    callbacks=[early_stopping_callback,checkpointer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-dea918e231a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#정확도 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Test Accuracy: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#학습셋 오차와 테스트 셋 오차를 시각화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#테스트 셋의 오차\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1350\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    509\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "#정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" %(model.evaluate(X_test,Y_test)[1]))\n",
    "\n",
    "#학습셋 오차와 테스트 셋 오차를 시각화\n",
    "#테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss,\"o\",c=\"red\",markersize=3)\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 10, 'epochs': 5, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "##############신경망 하이퍼파라미터 찾기 : GridSearchDV ####\n",
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "number_of_features = 100\n",
    "\n",
    "features, target = make_classification(n_samples=10000, n_features=number_of_features, n_classes=2, n_informative=3, n_redundant=0, weights=[.5,.5],\n",
    "                   random_state=0)\n",
    "\n",
    "def create_network(optimizer='rmsprop') :\n",
    "    network = Sequential();\n",
    "    network.add(Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "    network.add(Dense(units=16, activation='relu'))\n",
    "    network.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    network.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return network\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=0)\n",
    "\n",
    "epochs=[5, 10]\n",
    "batchs =[5, 10, 100]\n",
    "optimizers =['rmsprop', 'adam']\n",
    "\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batchs)\n",
    "\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\n",
    "\n",
    "grid_result = grid.fit(features, target)\n",
    "print(grid_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2\n",
      "['The Matrix is everywhere its all around us, here even in this room.\\\\ You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n",
      "<class 'list'> 15\n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\손은주\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######## 텍스트 전처리: 문장 토큰화, 단어 토큰화 ###########\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room.\\ You can see it out your window or on your television.\\\n",
    "                You feel it when you go to work, or go to church or pay your taxes.'\n",
    "sentences = sent_tokenize(text_sample)\n",
    "print(type(sentences),len(sentences))\n",
    "print(sentences)\n",
    "\n",
    "sentence = 'The Matrix is everywhere its all around us, here even in this room.'\n",
    "words = word_tokenize(sentence)\n",
    "print(type(words),len(words))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 개수: 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\손은주\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#### 텍스트 전처리 2: stopword 제거 ######\n",
    "nltk.download('stopwords')\n",
    "print('영어 stop words 개수:', len(nltk.corpus.stopwords.words('english')))\n",
    "print(nltk.corpus.stopwords.words('english')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
     ]
    }
   ],
   "source": [
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "               You can see it out your window or on your television. \\\n",
    "               You feel it when you go to work, or go to church or pay your taxes.'\n",
    "\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "all_tokens = []\n",
    "\n",
    "def tokenize_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    return word_tokens\n",
    "\n",
    "word_tokens = tokenize_text(text_sample)\n",
    "\n",
    "for sentence in word_tokens :\n",
    "    filtered_words=[]\n",
    "    for word in sentence :\n",
    "        word = word.lower()\n",
    "        if word not in stopwords :\n",
    "            filtered_words.append(word)\n",
    "    all_tokens.append(filtered_words)\n",
    "\n",
    "    \n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work work work\n"
     ]
    }
   ],
   "source": [
    "##### 텍스트 전처리 3: 어근 추출 ######\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\손은주\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work work work\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize('working','v'),lemma.lemmatize('works','v'),lemma.lemmatize('worked','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [0, 2, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 텍스트 전처리 4 : 수치 데이터 벡터화 ####\n",
    "# 희소 행렬 COO 형식\n",
    "dense = np.array([[3,0,1],[0,2,0]])\n",
    "\n",
    "from scipy import sparse\n",
    "data = np.array([3,1,2])\n",
    "row_pos = np.array([0,0,1])\n",
    "col_pos = np.array([0,2,1])\n",
    "\n",
    "sparse_coo = sparse.coo_matrix((data,(row_pos, col_pos)))\n",
    "sparse_coo.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 5],\n",
       "       [2, 4, 0, 3, 2, 5],\n",
       "       [0, 6, 0, 3, 0, 0],\n",
       "       [2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 8]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 희소 행렬 CSR 형식\n",
    "dense2 = np.array([[0,0,1,0,0,5],\n",
    "                  [1,4,0,3,2,5],\n",
    "                  [0,6,0,3,0,0],\n",
    "                  [2,0,0,0,0,0],\n",
    "                  [0,0,0,7,0,8],\n",
    "                  [1,0,0,0,0,0]])\n",
    "\n",
    "\n",
    "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
    "row_pos = np.array([0, 0,1,1,1,1,1, 2, 2, 3, 4, 4, 1])\n",
    "col_pos = np.array([2, 5, 0, 1,3,4,5, 1, 3, 0, 3, 5, 0])\n",
    "\n",
    "sparse_csr=sparse.csr_matrix((data2, (row_pos, col_pos)))\n",
    "sparse_csr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "target 클래스의 값과 분포도\n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "target 클래스의 이름을 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 뉴스 기사 ####\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data = fetch_20newsgroups(subset='all',random_state=156)\n",
    "\n",
    "print(news_data.keys())\n",
    "\n",
    "print('target 클래스의 값과 분포도\\n',pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름을 \\n',news_data.target_names)\n",
    "\n",
    "#첫번째 기사 내용 확인\n",
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "학습 데이터 크기 11314 , 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용(Train) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "print(type(X_train))\n",
    "\n",
    "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape : (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "# 카운트 기반으로 벡터화\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print('학습 데이터 Text의 CountVectorizer Shape :', X_train_cnt_vect.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer LogisticRegression 예측 정확도 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression를 이용하여 학습데이터에 대한 예측 평가 수행\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorizer LogisticRegression 예측 정확도 {0:.3f}'.format(accuracy_score(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer LogisticRegression 예측 정확도 0.674\n"
     ]
    }
   ],
   "source": [
    "#Tf-Idf Vectorizer 기반 벡터화\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TfidfVectorizer LogisticRegression 예측 정확도 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 LogisticRegression 예측 정확도 0.701\n"
     ]
    }
   ],
   "source": [
    "#pipeline을 사용해서 GridSearchCV 실행\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2),max_df=300)),('lr_clf',LogisticRegression(C=10))])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "print('Pipeline을 통한 LogisticRegression 예측 정확도 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ada76cc36e76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid_cv_pipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgrid_cv_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_cv_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_cv_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1417\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    758\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m                 \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"iprint\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gtol\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"maxiter\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m             )\n\u001b[0;32m    762\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 618\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfun_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36marray_equal\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36marray_equal\u001b[1;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[0;32m   2376\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2379\u001b[0m     \u001b[1;31m# Handling NaN values if equal_nan is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m     \u001b[0ma1nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2nan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### 하이퍼 파라미터 찾기 ####\n",
    "\n",
    "pipeline = Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2) )),\n",
    "('lr_clf', LogisticRegression())])\n",
    "\n",
    "params = {'tfidf_vect__ngram_range' : [(1, 1), (1, 2), (1, 3)], 'tfidf_vect__max_df' : [100, 300, 700], 'lr_clf__C' :[1, 5, 10]}\n",
    "\n",
    "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_pipe.fit(X_train, y_train)\n",
    "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 LogisticRegression 예측 정확도 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['데이터', '분석을', '위한', '베이지안', '모델링']\n"
     ]
    }
   ],
   "source": [
    "#######케라스의 텍스트 처리 함수 ########################\n",
    "#text 모듈의 text_to_word_sequence()\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "text = \"데이터 분석을 위한 베이지안 모델링\"\n",
    "result = text_to_word_sequence(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해서', 1), ('수치', 1), ('데이터', 1), ('벡터로', 1), ('변환해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화된', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n",
      "3\n",
      "defaultdict(<class 'int'>, {'단어를': 1, '각': 1, '텍스트의': 2, '나누어': 1, '토큰화합니다': 1, '토큰화해서': 1, '인식됩니다': 1, '변환해야': 1, '벡터로': 1, '단어로': 1, '딥러닝에서': 2, '데이터': 1, '수치': 1, '사용할': 1, '있습니다': 1, '결과는': 1, '수': 1, '토큰화된': 1})\n",
      "{'텍스트의': 1, '딥러닝에서': 2, '각': 3, '단어를': 4, '나누어': 5, '토큰화합니다': 6, '단어로': 7, '토큰화해서': 8, '수치': 9, '데이터': 10, '벡터로': 11, '변환해야': 12, '인식됩니다': 13, '토큰화된': 14, '결과는': 15, '사용할': 16, '수': 17, '있습니다': 18}\n"
     ]
    }
   ],
   "source": [
    "# 케라스에서 제공하는 BOW를 수행 함수 Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "docs = ['텍스트의 각 단어를 나누어 토큰화합니다','텍스트의 단어로 토큰화해서 수치 데이터 벡터로 변환해야 딥러닝에서 인식됩니다.',\n",
    "       '토큰화된 결과는 딥러닝에서 사용할 수 있습니다.']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(docs)\n",
    "print(tokenizer.word_counts) #단어 빈도수 계산 결과 출력됨\n",
    "print(tokenizer.document_count) #문장 개수 출력\n",
    "print(tokenizer.word_docs) #각 단어가 몇개의 문장에 출현하는지 출력\n",
    "print(tokenizer.word_index) #각 단어에 부여된 인덱스 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'텍스트의': 1, '각': 2, '단어를': 3, '나누어': 4, '토큰화합니다': 5}\n"
     ]
    }
   ],
   "source": [
    "#### 케라스에서 제공하는 텍스트를 원핫인코딩 변환 함수: to_categorical ######\n",
    "\n",
    "text = ['텍스트의 각 단어를 나누어 토큰화합니다']\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "print(token.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_to_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-4971249eeddc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_to_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 토큰의 인덱스로 채운 배열 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_to_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "x = text_to_sequence(text) # 토큰의 인덱스로 채운 배열 생성 \n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '텍스트의'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0f538ab11f60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '텍스트의'"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "word_size = len(token.word_index) + 1\n",
    "x = to_categorical(x, num_classes=word_size)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 텍스트의 원핫인코딩 변환은 그대로 사용하기에는 벡터의 길이가 너무 길어진다.\n",
    "## 공간적 낭비를 줄이기위해 단어 임베딩 방법을 적용한다.\n",
    "## 각 단어간의 유사도를 계산하여 배열을 새로운 수치값으로 변환한다.(embedding())\n",
    "\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(입력단어수, 출력될 벡터 크기, input_length))\n",
    "#model.add(Embedding(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'텍스트의': 1, '각': 2, '단어를': 3, '나누어': 4, '토큰화합니다': 5}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'text_to_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-7a911217f78d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_to_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 토큰의 인덱스로 채운 배열 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_to_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "# 텍스트 긍정, 부정 예측\n",
    "import numpy as np\n",
    "docs = [\"너무 재밌어요\",\"최고예요\",\"킬링타임으로 좋아요\",\"참 잘 만든 영화예요\", \"추천하고 싶은 영화입니다.\",\"글쎄요\",\"별로예요\",\"생각보다 지루합니다.\",\"재미없었어요\",\"그냥그래요\"]\n",
    "classes = np.array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "print(token.word_index)\n",
    "x = text_to_sequence(text) # 토큰의 인덱스로 채운 배열 생성 \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequence' from 'tensorflow.keras.preprocessing.sequence' (C:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\preprocessing\\sequence\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-232c8192bdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 서로 다른 길이의 데이터를 패딩으로 맞춰줍니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpadded_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'패딩 결과:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadded_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pad_sequence' from 'tensorflow.keras.preprocessing.sequence' (C:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\preprocessing\\sequence\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# 서로 다른 길이의 데이터를 패딩으로 맞춰줍니다.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequence\n",
    "\n",
    "padded_x = pad_sequences(x,4)\n",
    "print('패딩 결과:',padded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-fb1241d35a75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Flatten' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "word_size = len(token.word_index) +1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size,8,input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(padded_x, classes, epochs=20)\n",
    "print('Accuracy: %.4f' % (model.evaluate(padded_x,classes)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
